{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Hack the Planet","text":""},{"location":"#programming-and-data-science-for-biologists","title":"(Programming and Data Science for Biologists)","text":"<p>Welcome to the landing page for EEEB G4050, Programming and Data  Science for Biologists. This site will serve as a resource for the class,  with links to the syllabus, tutorials, videos, readings, and assignments.  You can access most of these categories from the navbar at the top,  including a link to Canvas, which we will use only for grades and zoom links.</p>"},{"location":"#course-design","title":"Course design","text":"<p>As the course name suggests, this class is designed to focus on  programming and data science skills. In this way it may be  quite different from other classes you have taken that introduced programming languages for domain-specific applications, such as  statistics or bioinformatics. Here we will focus more generally on  learning skills that are useful for any type of data science. This includes an improved understanding of your operating system, of  where software resides, of how it is designed, of how programmers write software, and of the community and resources that are available to you to learn programming and data science skills on your own.  By learning best practices for designing software tools you will  learn that a lot of scientific software is not actually very  well written or designed. By learning a framework for writing good software you will find that you can contribute greatly to the  community of biologists by developing simple and efficient software tools.</p>"},{"location":"#inspiration","title":"Inspiration","text":"<p>The alternative name and design of this site (\"hack the planet\") is inspired by the 1995 movie Hackers  (YouTube trailer link). Although you will not learn to \"hack\" in this class, in the strict sense, we will follow a general ethos of this statement from the film, which is that \"hacking\" involves the use of creative solutions to solve complex  problems; often involves computational methods; and should be applied  for the greater good. Borrowing another fun phrase from the film, our goal is that the programs we develop will not \"crash-and-burn\". </p>"},{"location":"#learning-to-learn-to-code","title":"Learning to Learn to Code","text":"<p>Although you can learn a lot of coding skills through tutorials,  much of programming comes from learning efficient routines, practices,  and even muscle memory, all of which comes through practice.  When you get stuck, try, try, and try again to come up with solutions. This mental work of thinking about alternative ways to achieve a goal requires practice. In addition, you can learn by example. Use google. See how others have solved this type of problem. Use ChatGPT, see how AI solves different types of problems. Treat this course like a hackathon, chat with your colleagues, discuss and work on assignments together, and brainstorm project  ideas. It should be fun. Drop in and say 'hello world' to the course  chatroom,  and ask any coding questions you might have.</p>"},{"location":"#programming-for-biology","title":"Programming for Biology","text":"<p>Finally, our theme of \"hack the planet\", relates well to a focus of many students in this class, which is an interest in biology and the environment.  We will learn about finding, parsing, and analyzing large biological  data sets, such as those used in genomics or biodiversity research. And we will learn best practices for working with such data.  Keep this theme in mind as you work through the course, thinking  of the type of data you want to analyze, and how you could develop a useful new tool around this type of data.</p>"},{"location":"#learning-objectives","title":"Learning objectives","text":"<p>The learning objectives of this course are summarized in the following:</p> <ul> <li>You will learn to code on your computer (mac, windows, linux, etc.)</li> <li>You will learn to install, remove, and update scientific software.</li> <li>You will learn to use software development tools (text editors, linting, testing).</li> <li>You will learn to plan and design a software tool to achieve some goal.</li> <li>You will learn to develop, document, and publish a software program.</li> </ul>"},{"location":"lectures/2.0/notes/","title":"Notes","text":"<ul> <li>review the poll</li> <li>review Markdown</li> <li>review bash tutorial &amp; sys utils<ul> <li>full path</li> <li>relative path (requires knowing where you are)</li> <li>. and ..</li> <li>lack of tab-completion</li> <li>\"Can you verify that the directory changed?\"</li> <li>change directories and then list / or list dir without changing directories.</li> </ul> </li> <li>hotkey commands in the jupyter terminal<ul> <li>ctrl-a</li> <li>ctrl-e</li> <li>ctrl-k</li> <li>ctrl-r</li> <li>up</li> <li>down</li> </ul> </li> <li>program design<ul> <li>effective strategies</li> <li>Cathedral vs. The Bazaar</li> </ul> </li> <li>types of software &amp; examples:<ul> <li>called script: ...</li> <li>executable: ...</li> <li>wrapper/pipeline: ...</li> <li>pipeline+: ...</li> <li>library: ...</li> <li>atomic: ...</li> <li>toolkit: ...</li> <li>framework: ...</li> <li>language: revbayes, SLiM</li> </ul> </li> </ul>"},{"location":"lectures/revealjs/css/theme/","title":"Index","text":""},{"location":"lectures/revealjs/css/theme/#dependencies","title":"Dependencies","text":"<p>Themes are written using Sass to keep things modular and reduce the need for repeated selectors across files. Make sure that you have the reveal.js development environment installed before proceeding: https://revealjs.com/installation/#full-setup</p>"},{"location":"lectures/revealjs/css/theme/#creating-a-theme","title":"Creating a Theme","text":"<p>To create your own theme, start by duplicating a <code>.scss</code> file in /css/theme/source. It will be automatically compiled from Sass to CSS (see the gulpfile) when you run <code>npm run build -- css-themes</code>.</p> <p>Each theme file does four things in the following order:</p> <ol> <li> <p>Include /css/theme/template/mixins.scss Shared utility functions.</p> </li> <li> <p>Include /css/theme/template/settings.scss Declares a set of custom variables that the template file (step 4) expects. Can be overridden in step 3.</p> </li> <li> <p>Override This is where you override the default theme. Either by specifying variables (see settings.scss for reference) or by adding any selectors and styles you please.</p> </li> <li> <p>Include /css/theme/template/theme.scss The template theme file which will generate final CSS output based on the currently defined variables.</p> </li> </ol>"},{"location":"lectures/revealjs/examples/markdown/","title":"Markdown Demo","text":""},{"location":"lectures/revealjs/examples/markdown/#external-11","title":"External 1.1","text":"<p>Content 1.1</p> <p>Note: This will only appear in the speaker notes window.</p>"},{"location":"lectures/revealjs/examples/markdown/#external-12","title":"External 1.2","text":"<p>Content 1.2</p>"},{"location":"lectures/revealjs/examples/markdown/#external-2","title":"External 2","text":"<p>Content 2.1</p>"},{"location":"lectures/revealjs/examples/markdown/#external-31","title":"External 3.1","text":"<p>Content 3.1</p>"},{"location":"lectures/revealjs/examples/markdown/#external-32","title":"External 3.2","text":"<p>Content 3.2</p>"},{"location":"lectures/revealjs/examples/markdown/#external-33-image","title":"External 3.3 (Image)","text":""},{"location":"lectures/revealjs/examples/markdown/#external-34-math","title":"External 3.4 (Math)","text":"<p><code>\\[ J(\\theta_0,\\theta_1) = \\sum_{i=0} \\]</code></p>"},{"location":"lectures/revealjs/test/simple/","title":"Simple","text":""},{"location":"lectures/revealjs/test/simple/#slide-11","title":"Slide 1.1","text":"<pre><code>var a = 1;\n</code></pre>"},{"location":"lectures/revealjs/test/simple/#slide-12","title":"Slide 1.2","text":""},{"location":"lectures/revealjs/test/simple/#slide-2","title":"Slide 2","text":""},{"location":"pages/devnotes/","title":"Course website dev notes","text":""},{"location":"pages/devnotes/#building-this-website","title":"Building this website","text":"<p>Clone the repo with recursive option to ensure cloning of the revealjs submodule within, or if the repo is already cloned, then just init the submodules <pre><code># clone w/ submodules\ngit clone --recurse-submodules git@github.com:eaton-lab/hack-the-planet.git\n\n# or, init the submodules\n#git submodule update --init --recursive\n</code></pre></p> <p>Install mkdocs-material into your current environment. <pre><code>conda install mkdocs-material -c conda-forge\n</code></pre></p> <p>Move into the repo directory alongside mkdocs.yml and build locally with <code>mkdocs</code>.  Changes to the repo will now automatically update in the website being served to localhost:8000.  <pre><code>mkdocs serve\n</code></pre></p>"},{"location":"pages/devnotes/#editing-the-site","title":"Editing the site","text":"<p>Currently the old class structure is still present in the <code>old-docs</code> directory. Parts of this can be updated and moved to the new <code>docs/</code> directory to be integrated into the new site. </p>"},{"location":"pages/devnotes/#other-useful-programming-for-biologists-courses","title":"Other useful programming for biologists courses","text":"<ul> <li>Computing Skills for Biologists (Allesina &amp; Wilmes; the most up-to-date and nice)</li> <li>Python for Biologists</li> <li>Programming for Biologists (Ethan White)</li> <li>Data Science for Biologists (UW)</li> </ul>"},{"location":"pages/presentations/","title":"presentations","text":""},{"location":"pages/presentations/#project-presentations","title":"Project Presentations","text":"<p>Project presentations will take place in class on 5/1 and 5/6.  Each presentation should be approximately 7 minutes in length, followed by 2-3 minutes of questions. You will need to share your screen during  the presentation, which can include showing and demonstrating your  program using a terminal, notebook, browser, and/or other windows as necessary. Your presentation should include the following details:</p> <p>1. Project organization:  In a browser show your github repository page. Organize this ahead of time. Ensure your README file clearly states the name of your project, its intended use, and how to install it.  While showing this page describe your project goal, and why you chose  this for your project.</p> <p>2. Demonstration: Next, demonstrate the current capabilities of your program, even if it is not yet finished. Your goal is to have a minimal working example that can accomplish steps 1-n, even if there are many more than n steps in the final product. (Example, open your terminal and call the command line interface of your program. Show the options that a user can toggle. And demonstrate a single run of the program with an example set of input options). In this section, your goal is to demonstrate what you have accomplished, and not  to focus on what hasn't worked, or what remains to be done. </p> <p>3. Describe basis of code: Now that you've demonstrated your code, describe how you went about  accomplishing this. Start by describing the main dependencies you used. Have a web browser tab open to the documentation for these libraries,  and inform your audience very briefly about what this package does,  and why you chose it. (Example, \"I wanted to create a  graphical user interface, and I selected the Python package Kivy to  accomplish this. Kivy creates GUIs through a combination of Python code and code blocks describing the visual layout. It is great because it  can be used for creating GUIs that work on computer screens as well as on mobile devices. It was difficult to learn because it involved learning more than just Python code. An example graphical layout file looks like this, and means this. I'll show you my example next...\")</p> <p>4. Code details: In a text editor open your repository directory. Briefly describe the layout of your code, for example you created three modules that accomplish tasks x, y, and z. There is not enough time to describe it all, so instead focus on a few details. This is meant to be technical. Pick a particular part out of the code to describe, such as a custom class object you defined, or an  interesting calculation on a pandas dataframe that you wrote.  Here your goal is describe an interesting component of your Python code  that you spent a lot of time learning, and how it works. </p> <p>5. Future goals: Describe your remaining goals for the project. What steps remain, and how difficult do you think they will be? Finally, reflect on this project development experience, including in the context of learning more  about your peers' projects. What have you learned through this project  that will make planning or developing your next project easier?</p> <p>6. Take questions:</p>"},{"location":"pages/presentations/#schedule","title":"Schedule","text":"<p>Monday 5/1</p> <p>Wednesday 5/6</p>"},{"location":"pages/project-submit/","title":"Final Project Submission","text":"<p>Your final project submission is due on 5/13/2025 at 1pm EST. We will begin grading projects based on commits made by this time, but you are of  course welcome to continue working on your projects for as long as you would like after class. </p> <p>The final project is worth 20% of your total grade. Projects will be graded on the following criteria:</p> <ul> <li>Commit history/effort (40%)</li> <li>Python Code (15%)</li> <li>Minimal working example (15%)</li> <li>GitHub repository organization (10%)</li> <li>README.md install and demo instructions or other docs (10%)</li> <li>Paired programming commits or comments (10%)</li> </ul>"},{"location":"pages/project-submit/#commit-history","title":"Commit history","text":"<p>By the project submission date you will have worked on your project for over six weeks. Kind of amazing. Over this time you've probably changed the code dramatically, and hopefully developed something that is approaching your  proposed goal. The git commits that you made along the way provide a  record and timestamp of your progress. We will review your commit history to get a snapshot of your contributions. It's OK if you committed very little one week, and much more another week. </p>"},{"location":"pages/project-submit/#python-code","title":"Python code","text":"<p>We spent a fair bit of time in class discussing the proper way to organize Python code. This involves following conventions that make it easier for  others to read your code and understand what it is doing. You should place imports at the top of modules, and use proper indentation, and try to split your code among multiple separate modules if it becomes too long and  complicated. These conventions can take a while to learn, and that is why I repeatedly, relentlessly, tried to get everyone to implement a working  linter in your code editor to provide hints about how to improve the style of your code. We will examine your code organization to see that you have  followed good coding styles. This doesn't mean you need to have fixed or  accepted every single warning from your linter, but it will be very apparent if you have ignored all of them.</p>"},{"location":"pages/project-submit/#minimal-working-example","title":"Minimal working example","text":"<p>I should be able to install and run a minimal working example of your code as described in your README file. As discussed previously, this does not  mean that your program needs to be able to completely accomplish your proposed goal at the time of submission. But it does need to be able to do something  that shows it is on the way towards its goal.</p>"},{"location":"pages/project-submit/#github-repo-organization","title":"GitHub repo organization","text":"<p>I will examine your GitHub repo to check that you have organized files into  folders, that it looks well maintained and updated, and that you have  removed any files that are not meant to be synced, like .egg folders,  or .DStore files (files that are not part of your code or demos).</p>"},{"location":"pages/project-submit/#readme-instructions-andor-documentation","title":"README instructions and/or documentation","text":"<p>Your README file should contain the name of your program, and short  description, and instructions for how to install and run the minimal working example. It should be nicely formatted using Markdown. Spend some time making the formatting look nice. This should be a freebie, since you were required to make most of this during your proposal.</p>"},{"location":"pages/project-submit/#paired-programming-commits-or-comments","title":"Paired programming commits or comments","text":"<p>I will look for commits and comments you've made to other students code.  For your first paired-programming exercises I asked for you to try to contribute to  other projects even if you do not have a ton to contribute. But I didn't  make this a requirement for later paired-programming meetings, so it is OK if you only discussed the projects in your in person meetings. If you have  not made any commits to anyone elses repo then you should do so before the  project submission date. This is essentially a form of participation points.</p>"},{"location":"pages/proposals/","title":"Proposals","text":""},{"location":"pages/proposals/#project-proposaloutline","title":"Project Proposal/Outline","text":"<p>Guidelines:</p> <ul> <li>Your project must be written (primarily) in Python.</li> <li>The project proposal must be approved by the Instructors</li> </ul> <p>Due date and expectations: - Your proposal will be graded on all of the components based on their state by the end of the day on 3/27/2021.  Your expected progress on the project code/pseudocode at this point will vary among students depending on your prior experience.</p>"},{"location":"pages/proposals/#getting-started","title":"Getting started","text":"<p>Assuming that your mini-project will be the springboard for your final project you can begin to create you can begin by changing the name of  your <code>mini-project</code> repo to a new name representing what you want your  project to be called (if you haven't already done so). This can be done  from the settings page of the repo on GitHub.</p> <p>Once you have changed the name of your repo you can now clone it to your laptop, or if you have already done so, you can continue to use your existing clone (it can handle keeping up with the name change). If you have not already done so, you can now add the following files and folders to create your starting project file structure, with all files and folders renamed as you would like. </p> <pre><code>project/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2514\u2500\u2500 module.py\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 setup.py\n</code></pre>"},{"location":"pages/proposals/#proposal","title":"Proposal","text":"<p>Your project repo currently has your mini-project proposal written in the  README.md file. Create a copy of this file called <code>proposal.md</code>, as a starting point for your official project proposal. The <code>proposal.md</code> file in the root of your project repo will be the file we will reference for evaluating your proposal.</p> <p>In this proposal you should expand upon the contents in your mini-project proposal to incorporate any feedback that we provided previously, and to update it with any new ideas or progress you have made in designing your project. Using markdown, you should create nicely formatted headings and paragraphs to list the following topics and your answers:</p> <ul> <li>What task/goal will the project accomplish and why is this useful?</li> </ul> <p>This should be a concise statement that would convince a user that your program is worth their time to read more about and try using.</p> <ul> <li>What type of data/input will a user provide to the program?</li> </ul> <p>This will vary depending on the strutcure of your program. If it is a game the user may only provide keystrokes or screentouches; if you made a CLI program the user may only provide options to toggle; if you made a webapp the user may use their mouse and keyboard to toggle input options in a web page; if you made a program that takes data as input then the user may  need to enter a CSV or JSON or other type of data file as an option.</p> <ul> <li>Where will the data come from?</li> </ul> <p>Almost every program will involve some type of data. This data may be  provided as input by the user, or it may be generated by your program in  response to the user inputs, or it may be accessed from a database that your distribute inside of your program (e.g., CSV file) or from an online database that is access using a REST API. Describe it and show an example of the format, like below.</p> <p><pre><code>species    latitude    longitude    color\nA    30.0    100.0    red\nA    31.0    101.0    blue\nB    29.0    105.2    red\nB    29.5    101.2    red\n...\n</code></pre> And if it is from a REST API then describe the API options, provide a link,  explain which paths of the API you will access, and any rules or limits you've found about how it can be accessed.</p> <ul> <li>How will a user interact with the program?</li> </ul> <p>If you are developing a CLI or API then write a mock example like below. If you are writing any other kind of input, describe which options a user might be able to toggle. </p> <pre><code># mock example of command line options to a program\nmyprogram --latitude-min 90 --latitude-max 110 --avg-color\n</code></pre> <ul> <li>What type of output will the program produce (e.g., text, plots)? </li> </ul> <p>Describe the format of these outputs, show an example of what you have  in mind, even if you have to draw it by hand. Think about it, is this the most useful way for the user to get the output? Would it be more convenient to return the result to STDOUT, or to a file, or to a webpage?</p> <ul> <li>What other tools currently exist to do this task, or something similar?</li> </ul> <p>Do some research. Do some google searching. What other programs currently exist to do this thing. Provide links to them. Describe how your program will be different. </p>"},{"location":"pages/proposals/#psuedo-code-andor-code","title":"Psuedo-code and/or code","text":"<p>You should begin to write properly formatted psuedo-code to layout the  design of your program within your text editor. This means that you should organize code properly in the module (e.g., shebang, imports, docstrings, classes) and write classes or functions with docstrings and comments.  Begin to describe the major tasks using code. This can be  contained in one or more modules. Once you have these major classes defined you can begin to work on the first one, and work towards creating a minimal working example. Once you have this minimal working example it will be easier for others to collaborate on your code with you.</p>"},{"location":"pages/proposals/#update-your-readmemd","title":"Update your README.md","text":"<ul> <li>Write the name of your program as a level-1 header</li> <li>Copy your answer about what task/goal your project is intended to accomplish and enter it below the header as a text.</li> <li>Write a level-3 header called \"in development\"</li> <li>Write a paragraph below this describing how developers can install the  program locally to help work on the code. This should include instructions like the following:</li> </ul> <pre><code>conda install [list dependencies here...] -c conda-forge ...\n\ngit clone [myproject-link]\ncd ./myproject-name\npip install -e .\n</code></pre> <p>Test to make sure your code is installable, even if the Python  modules are mostly empty for now.</p>"},{"location":"pages/proposals/#goal","title":"Goal","text":"<p>In the following weeks we will begin to engage in collaborative coding,  where you will fork each others' repos, try out the code, and try to contribute to it by making edits. This will be greatly facilitated by a well-written  proposal that describes the goal of the software, and the intended design of it. As you progress and the code becomes more complex, it may become useful to develop further details/descriptions of the code to aid other developers in understanding the structure of your code. We will talk more about this  in a later session.</p>"},{"location":"pages/proposals/#make-your-project-known","title":"Make your project known","text":"<p>Navigate to the following page on GitHub   https://github.com/eaton-lab/hack-the-planet/blob/master/docs/data/usernames.csv where the course website is hosted and click on the 'pen' icon to fork and edit the file. Next to your username where it currently says TBD enter the new name of your project repository (be sure to enter the correct lower vs upper case letters). Commit your change and make a pull request. Once we accept the pull request a link to your repo will appear on the course website under the repos link.</p>"},{"location":"pages/schedule/","title":"Schedule","text":"<p>Note: we will send an email notification if any changes are made to the schedule.</p>"},{"location":"pages/syllabus/","title":"Syllabus","text":"<ul> <li>Title: Programming and Data Science for Biology (EEEB G4050)</li> <li>Term: Spring 2025</li> <li>Department: Ecology, Evolution, and Environmental Biology (E3B)</li> <li>Instructors: <ul> <li>Deren Eaton (de2356@columbia.edu, he/him) </li> <li>Isaac Overcast (iao2122@columbia.edu, he/him)</li> </ul> </li> <li>Location: 329 Uris Hall</li> <li>Day/Time: Tu/Th 10:10-11:25am</li> <li>Course level: 4000 (graduate but open to advanced undergraduates)</li> <li>Credits: 3</li> <li>Office hours: TBD.</li> </ul> <p>Bulletin: Programming and Data Science for Biologists (PDSB) will introduce students to fundamental computational skills and concepts for working with large biological data sets. The core learning objectives include general skills like data formatting and using git/github, as well as learning advanced usage of Python for writing and designing new software. Exercises and assignments will introduce students to empirical datasets used in the biological sciences, from genomics to biodiversity. The latter half of the class is organized around individual projects, in which students will design a command-line program and/or API relevant to their research. Computer programs are ubiquitous in biology, but few biologists receive formal training in designing and writing software. This course offers a deeper introduction to computational techniques and algorithms commonly applied to biological datasets.</p> <p>Organization: Each meeting will be a mix of lecture, in-class \"active\" learning, and group activities. In addition a lot of work is assigned outside of class, including assignments, reading, and watching video tutorials. An example session would include a lecture to introduce a general concept with examples from biological research, followed by a group active-learning exercise in which students implement the method applied to real datasets.</p> <p>Equipment: All software and materials for the course are open access (available online for free) including assigned readings and videos. Students will learn to code on their own computers, no matter if they are running Linux, Mac, Windows, or Chrome OS. This will require student to install free software on their computers.</p> <p>Assessment/Grades: Grades will not be curved. However, your grade will be assigned relative to the performance of your peers. The maximum grade will earn an A, and grades that are less than one-half of that maximum grade will be assigned an F. Between these values (max and \u00bd max) intervals equating to letter grades are divided equally. Grades are based on participation (attendance and discussions), assignments, projects proposals, and project presentations, and the final project. - 25% Participation - 35% Assignments - 10% Project proposal - 10% Project presentation - 20% Project final  </p> <p>Participation: In addition to attendance you are expected to contribute to discussions in class by asking questions, and to interact with your peers through breakout session code reviews. Participating in the Gitter chatroom also 'counts' as participation.</p> <p>Assignments: Code-based assignments are used to assess comprehension of new concepts learned in class. These are graded on effort, accuracy, and style. </p> <p>Projects: A course project will be developed by each student. We will begin planning these very early in the class, well before you will have learned the skills to develop them. As we progress through class we will revisit and revise project proposals, while also discussing how the concepts we learn may be usefully applied to aspects of the projects. A formal project proposal is due halfways through class. Near the end of class students will give presentations on the status of their projects. The final projects will be published as open source code on github and evaluated on the basis of documentation, style, and a working example.</p> <p>Attendance policy: This course relies upon student participation and, thus, attendance is expected. Absences will incur a grade penalty unless excused. Students who are unable to attend class for health or other personal reasons should reach out to the instructors. We understand that there are many legitimate reasons for absences, so do please reach out.</p> <p>Statement on policy for students with disabilities: If you are a student with a disability and have a Disability Services-certified \u2018Accommodation Letter\u2019 please contact the instructors before the course starts to confirm your accommodation needs. If you believe that you might have a disability that requires accommodation, you should contact Disability Services at 212-854-2388 and disability@columbia.edu.</p> <p>Statement on use of generative AI in coursework: Students are not discouraged from using AI tools, such as ChatGPT or similar technologies, to support their learning and assignments. However, the use of AI must be acknowledged clearly in your submissions. For example, you can include a brief note stating, \"This analysis was generated with the assistance of [AI tool name].\"</p> <p>While AI can be a powerful resource, it is not infallible. These tools can occasionally produce incorrect or misleading information, and relying on them exclusively may hinder your ability to critically evaluate data, methods, and results. Therefore, you are expected to: - Verify Information: Cross-check AI-generated outputs against authoritative sources or class materials. - Develop Independent Skills: Engage with the concepts and tools independently to ensure you can identify when AI outputs are inaccurate or suboptimal. - Take Responsibility: Ultimately, you are accountable for the content and quality of your work, regardless of whether it was AI-assisted.</p> <p>By using AI judiciously and critically, you will enhance your ability to evaluate the reliability of data and tools, which is a vital skill in data science. This statement on the use of generative AI was generated with the assistance of ChatGPT.</p> <p>Statement of academic integrity: Academic dishonesty is a serious offense and will not be tolerated in the class. Students are expected to reference sources appropriately in any work. Students are allowed to discuss homework assignments but should respond to questions and tasks on their own, not using a group answer. Violation of the rules of academic integrity (e.g., plagiarizing materials) from Columbia College or the Graduate School of Arts and Sciences, will result in automatic failure of the course. Rules and consequences are outlined in Columbia College\u2019s Faculty Statement on Academic Integrity: http://www.college.columbia.edu/faculty/resourcesforinstructors/academicintegrity/ statement</p>"},{"location":"sessions/BLANK-session-skel/","title":"Session 9","text":""},{"location":"sessions/BLANK-session-skel/#icebreaker-question","title":"Icebreaker question","text":"<ul> <li>TODO</li> </ul>"},{"location":"sessions/BLANK-session-skel/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will learn about.... By the end of this session you will  be more familiar with the following topics:</p> <ul> <li>XXX</li> <li>XXX</li> </ul>"},{"location":"sessions/BLANK-session-skel/#review-and-discussion","title":"Review and Discussion","text":"<ul> <li>Review homework assignments</li> </ul>"},{"location":"sessions/BLANK-session-skel/#in-class-exercises","title":"In class exercises","text":"<ul> <li>TODO Link to Lecture XX slides </li> </ul>"},{"location":"sessions/BLANK-session-skel/#assignments","title":"Assignments","text":"<ul> <li>TODO Readings</li> <li>TODO Tutorials </li> </ul>"},{"location":"sessions/session-1/","title":"Session 1","text":""},{"location":"sessions/session-1/#learning-objectives","title":"Learning objectives","text":"<p>In this first session of class we will review the syllabus, discuss the course  objectives, and begin the first interactive lesson introducing programming in  a command line terminal.  By the end of this session you will be more familiar with the following topics:</p> <ul> <li>The structure and goals of this class.</li> <li>A unix shell/terminal.</li> <li>Command line programs, including core system utilities.</li> <li>File system paths.</li> <li>Markdown.</li> </ul>"},{"location":"sessions/session-1/#in-class-exercises","title":"In class exercises","text":"<ul> <li>Introduce the course website (bookmark this!): https://eaton-lab.org/hack-the-planet</li> <li>Connect, login, and complete notebook 1 on the course server: https://pinky.eaton-lab.org</li> <li>Link to Lecture 1 slides: Introduction to bash</li> </ul>"},{"location":"sessions/session-1/#assignments","title":"Assignments","text":"<ul> <li>Complete the online poll: https://forms.gle/gYuxM2UCQirrEbX77</li> <li>Watch this YouTube video on the history of Unix programming.</li> <li>Complete the terminal tutor tutorial: https://www.terminaltutor.com/</li> </ul>"},{"location":"sessions/session-10/","title":"Session 10","text":""},{"location":"sessions/session-10/#icebreaker-question","title":"Icebreaker question","text":"<ul> <li>What coding superpower (or other superpower) would you like to have?</li> </ul>"},{"location":"sessions/session-10/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will learn about coding modern coding editors, linting, and other coding support tools. By the end of this session you will  be more familiar with the following topics:</p> <ul> <li>Sublime Text</li> <li>Linting</li> </ul>"},{"location":"sessions/session-10/#review-and-discussion","title":"Review and Discussion","text":"<ul> <li>Review WF as a python script</li> </ul>"},{"location":"sessions/session-10/#in-class-exercises","title":"In class exercises","text":"<ul> <li>In class live-demo with Sublime text &amp; linting</li> <li>Discuss the miniproject ideas</li> </ul>"},{"location":"sessions/session-10/#assignments","title":"Assignments","text":"<ul> <li>Read Zen of Python</li> <li>Read python Style guide</li> <li>Tutorial 10.0 Sublime text</li> <li>Tutorial 10.1 styling</li> </ul>"},{"location":"sessions/session-11/","title":"Session 11","text":""},{"location":"sessions/session-11/#icebreaker-question","title":"Icebreaker question","text":"<ul> <li> <p>What is your favorite magical or mythological creature and why?</p> </li> <li> <p>Kurukurupira (Brazil), Nidhaug (Norse), Flying bison from Avatar the last  airbender, Jackalope (American), Basilisk (Greek), Loch Ness Monster (Scotland), Nekomata (Japan), Phoenix (Traditional), Dijang (headless furry creature with  four wings presents luck and power; China), Selkie (European)</p> </li> </ul>"},{"location":"sessions/session-11/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will estlish a repository for our mini-projects and start filling it in. By the end of this session you will  be more familiar with the following topics:</p> <ul> <li>Python package structure</li> <li>Working with Sublime Text</li> </ul>"},{"location":"sessions/session-11/#in-class-exercises","title":"In class exercises","text":"<ul> <li>Getting started with the mini-project</li> </ul>"},{"location":"sessions/session-11/#assignments","title":"Assignments","text":"<ul> <li>Begin thinking about your Project Proposal</li> </ul>"},{"location":"sessions/session-12/","title":"Session 12","text":""},{"location":"sessions/session-12/#icebreaker-question","title":"Icebreaker question","text":"<ul> <li>If you were hosting a dinner party and could invite any 3 people (either living or dead), who would they be?</li> </ul>"},{"location":"sessions/session-12/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will learn about accessing biological data online using REST APIs. By the end of this session you will be more familiar  with the following topics:</p> <ul> <li>The format of JSON data</li> <li>Using API calls to access data online</li> </ul>"},{"location":"sessions/session-12/#review-and-discussion","title":"Review and Discussion","text":"<ul> <li>Check-in on mini-projects</li> </ul>"},{"location":"sessions/session-12/#in-class-exercises","title":"In class exercises","text":"<ul> <li>Lecture 12: Accessing biological data online with REST APIs</li> <li>Tutorial 12.0: REST APIs</li> <li>Tutorial 12.1: VCF files</li> </ul>"},{"location":"sessions/session-12/#assignments","title":"Assignments","text":"<ul> <li>Continue working on your mini-projects, we will have a status check-in next week.</li> </ul>"},{"location":"sessions/session-13/","title":"Session 13","text":""},{"location":"sessions/session-13/#icebreaker-question","title":"Icebreaker question","text":"<ul> <li>Are there any foods you disliked as a child, but love (or at least tolerate) now?</li> </ul>"},{"location":"sessions/session-13/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will learn about using ChatGPT as a coding co-pilot, and trying to decipher whether it is doing as you want or doing something else.</p>"},{"location":"sessions/session-13/#review-and-discussion","title":"Review and Discussion","text":"<ul> <li>pass</li> </ul>"},{"location":"sessions/session-13/#in-class-exercises","title":"In class exercises","text":"<ul> <li>Icebroken activity</li> <li>Can you get ChatGPT to help with your mini-project? AI assistance and follow-up discussion</li> <li>Mini-project hack-a-thon with check-ins on progress and milestone planning using GitHub Projects</li> </ul>"},{"location":"sessions/session-13/#assignments","title":"Assignments","text":"<ul> <li>Continue working on your mini-project</li> <li>Read Chapter 4 'Visualization with Matplotlib' from the Python Data Science Handbook</li> </ul>"},{"location":"sessions/session-14/","title":"Session 14","text":""},{"location":"sessions/session-14/#icebreaker-question","title":"Icebreaker question","text":"<ul> <li>If you could live in a different country for a year, which country would you choose?</li> </ul>"},{"location":"sessions/session-14/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will learn about plotting and visualization with Matplotlib. By the end of this session you will be more familiar with the following topics:</p> <ul> <li>Basic plot types: lines, boxplots, histograms, scatterplots</li> <li>Simple visual manipulations: Colors, line styles, marker styles</li> </ul>"},{"location":"sessions/session-14/#review-and-discussion","title":"Review and Discussion","text":"<ul> <li>Review homework assignments</li> </ul>"},{"location":"sessions/session-14/#in-class-exercises","title":"In class exercises","text":"<ul> <li>Icebroken activity</li> <li>Data visualization with Matplotlib</li> <li>Mini-project check-ins and strategizing</li> </ul>"},{"location":"sessions/session-14/#assignments","title":"Assignments","text":"<ul> <li>Continue working on your mini-project (NB: These are due in 1 week)</li> <li>Read Chapter 5 'Machine Learning' from the Python Data Science Handbook</li> </ul>"},{"location":"sessions/session-15/","title":"Session 15","text":""},{"location":"sessions/session-15/#icebreaker-question","title":"Icebreaker question","text":"<ul> <li>What is your favorite movie?<ul> <li>Who's afraid of virginia woolf?; Hitchiker's guide to the galaxy; About time; She's the man; Halloweentown; Shining; Spirited Away &amp; !Complete Unknown; Interstellar; []</li> </ul> </li> </ul>"},{"location":"sessions/session-15/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will learn about the basics of machine learning. By the end of this session you will  be more familiar with the following topics:</p> <ul> <li>The Scikit-learn API</li> <li>Dimension reduction/decomposition</li> <li>Supervised vs unsupervised learning</li> <li>Classification and Regression model fitting</li> </ul>"},{"location":"sessions/session-15/#in-class-exercises","title":"In class exercises","text":"<ul> <li>Icebroken activity</li> <li>Intro to machine learning w/ scikit-learn</li> </ul>"},{"location":"sessions/session-15/#assignments","title":"Assignments","text":"<ul> <li>Wrap-up your mini-project and be prepared to share what you have with the class on Thursday. </li> </ul>"},{"location":"sessions/session-16/","title":"Session 16","text":""},{"location":"sessions/session-16/#icebreaker-question","title":"Icebreaker question","text":"<ul> <li>If you could bring back any fashion trend, what would it be?</li> </ul>"},{"location":"sessions/session-16/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will review and critique each others mini-projects. We will also continue with the Machine Learning lesson for the remaining time. By the end of this session you will be more familiar with the  following topics: - Supervised vs unsupervised learning - Classification and Regression model fitting</p>"},{"location":"sessions/session-16/#in-class-exercises","title":"In class exercises","text":"<ul> <li>Mini-project presentations</li> <li>Intro to machine learning w/ scikit-learn (cont.)</li> </ul>"},{"location":"sessions/session-16/#assignments","title":"Assignments","text":"<ul> <li>The primary assignment for break is to write up your full project proposal, which will be due the first Thursday after break (3/27/25).</li> </ul>"},{"location":"sessions/session-17/","title":"Session 17","text":""},{"location":"sessions/session-17/#icebreaker-question","title":"Icebreaker question","text":"<ul> <li>TODO</li> </ul>"},{"location":"sessions/session-17/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will learn about advanced usage of GitHub. By the end of this session you will  be more familiar with how to collaborate with others using git and GitHub. We will cover the following:</p> <ul> <li>GitHub forks and git remotes</li> <li>Resolving git conflicts</li> <li>Issues and Pull Requests</li> <li>Pair programming</li> </ul>"},{"location":"sessions/session-17/#review-and-discussion","title":"Review and Discussion","text":"<ul> <li>Discussion of project proposals</li> </ul>"},{"location":"sessions/session-17/#in-class-exercises","title":"In class exercises","text":"<ul> <li>17.0 - git collab</li> <li>17.1 - git conflicts</li> <li>17.2 - git in class</li> </ul>"},{"location":"sessions/session-17/#assignments","title":"Assignments","text":"<ul> <li>None</li> </ul>"},{"location":"sessions/session-2/","title":"Session 2","text":""},{"location":"sessions/session-2/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will review the assignments on the bash terminal,  file system paths, and where software is located on *nix-based operating system. We will then introduce GitHub.  By the end of this session you will be more familiar with the following topics:</p> <ul> <li>Unix-based operating systems.</li> <li>Using a shell / terminal.</li> <li>GitHub repositories and README files.</li> </ul>"},{"location":"sessions/session-2/#in-class-exercises","title":"In class exercises","text":"<ul> <li>Link to Class 1 Prior Experience Poll Results</li> <li>Link to Lecture 2.0: Program design, bash, GitHub.</li> </ul>"},{"location":"sessions/session-2/#assignments","title":"Assignments","text":"<ul> <li>(only if you are a windows user) Install Windows Subsystem for Linux</li> <li>Tutorial 2.0: Create a GitHub account and repository</li> <li>Tutorial 2.1: The terminal/shell, bash variables, PATH</li> <li>Tutorial 2.2: Bash assessment/challenge</li> <li>Read: \"Ten Simple Rules for Developing Usable Software in Computational Biology\"</li> </ul>"},{"location":"sessions/session-3/","title":"Session 3","text":""},{"location":"sessions/session-3/#icebreaker-question","title":"Icebreaker question","text":"<ul> <li>What bird are you most like and why?</li> </ul>"},{"location":"sessions/session-3/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will learn about <code>git</code> and GitHub for version control and  collaborative coding. You will clone your first git repository, make edits to it in a text editor, and use this to develop a webpage hosted on GitHub. By the end of this session you will be more familiar with the following topics: - Github as a version control system - Cloning repositories, and  adding, commiting, and pushing files</p>"},{"location":"sessions/session-3/#review-discussion","title":"Review &amp; Discussion","text":"<ul> <li>Log in to the gitter channel using your github account and post a message</li> <li>Review of bash challenge assignment</li> <li>Discuss \"Ten Simple Rules for Developing Usable Software in Computational Biology\"</li> </ul>"},{"location":"sessions/session-3/#in-class-exercises","title":"In class exercises","text":"<ul> <li>Link to In-class git init exercise: Working with local github repositories</li> </ul>"},{"location":"sessions/session-3/#assignments","title":"Assignments","text":"<ul> <li>Tutorial 3.1: Markdown revisited</li> <li>Tutorial 3.2: Introduction to git branching</li> <li>Tutorial 3.3: Creating a Github pages</li> <li>Read: \"Ten Simple Rules for Effective Computational Research\"</li> </ul>"},{"location":"sessions/session-4/","title":"Session 4","text":""},{"location":"sessions/session-4/#icebreaker-question","title":"Icebreaker question","text":"<ul> <li>What is one thing you wish you understood but don't?</li> </ul>"},{"location":"sessions/session-4/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will learn about using conda for package management and  we will introduce python as a powerful language for scientific computing. By the end of this session you will be more familiar with the following topics:</p> <ul> <li>Installing conda and managing conda environments for installing software</li> <li>Launching jupyter notebooks on your local system</li> <li>The python programming language for scientific computing</li> </ul>"},{"location":"sessions/session-4/#review-and-discussion","title":"Review and Discussion","text":"<ul> <li>Presentations of student GitHub Pages</li> <li>Troubleshooting <code>git</code></li> <li>Link to Lecture 4 slides: Introducing conda for package management, and the python programming language</li> </ul>"},{"location":"sessions/session-4/#in-class-exercises","title":"In class exercises","text":"<ul> <li>Tutorial 4.0: conda installer</li> <li>Tutorial 4.1: jupyter notebook</li> </ul>"},{"location":"sessions/session-4/#assignments","title":"Assignments","text":"<ul> <li>Start thinking about a problem you might be interested in developing a tool to solve. Specifically think about what will be the data available (input) and what you want as the answer (output). We will start discussing project ideas next week (in a very preliminary way).</li> <li>Python tutorial chapters 1 and 3</li> <li>Tutorial 4.2: GitHub forking and Python assessment</li> </ul>"},{"location":"sessions/session-5/","title":"Session 5","text":""},{"location":"sessions/session-5/#icebreaker-question","title":"Icebreaker question","text":"<ul> <li>What is one word that you enjoy, in any language, for whatever reason? <pre><code># Define the icebreaker procedure\nfor student in class:\n    response = icebreaker_question()\n    if response.isfunny():\n        self.laugh()\n    elif response.isinteresting():\n        self.stroke_chin_thoughfully()\n    else:\n        self.thumbs_up()\n</code></pre></li> </ul>"},{"location":"sessions/session-5/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will learn about the the fundamental elements of the python programming langauge: variables, lists, and control flow. By the end of this  session you will be more familiar with the following topics:</p> <ul> <li>How to assign variables of different data types and perform basic manipulations</li> <li>Creating lists and using list indexing and slicing</li> <li>Control flow using 'for' loops to iterate over lists</li> </ul>"},{"location":"sessions/session-5/#review-and-discussion","title":"Review and Discussion","text":"<ul> <li>Review homework assignments</li> <li>Link to Lecture 5 slides: Python variables, lists, and for loops</li> </ul>"},{"location":"sessions/session-5/#in-class-exercises","title":"In class exercises","text":"<ul> <li>Create an account on genepy.org</li> <li>Work through the first 9 genepy exercises (from 'Hello World' to 'Import')</li> <li>Project planning 1: What are the inputs and outputs of the project you have in mind?  What data is available and what is the 'answer' you want to get out of your tool?</li> </ul>"},{"location":"sessions/session-5/#assignments","title":"Assignments","text":"<ul> <li>Assigned problem set on python variables, lists, and for loops</li> <li>Supplementary Reading and additional practice problems: 30 Days Of Python: Day 10 - Loops</li> </ul>"},{"location":"sessions/session-6/","title":"Session 6","text":""},{"location":"sessions/session-6/#icebreaker-question","title":"Icebreaker question","text":"<ul> <li>What is something you enjoy doing when you are not writing python programs?</li> </ul>"},{"location":"sessions/session-6/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will learn about more advanced data structures and control flow mechanisms. By the end of this session you will be more familiar with the following topics:</p> <ul> <li>Dictionaries for storing and retrieving key/value pairs</li> <li>Conditional branching with if/else statements</li> <li>Defining functions to perform specific tasks</li> </ul>"},{"location":"sessions/session-6/#review-and-discussion","title":"Review and Discussion","text":"<ul> <li>Continue w/ Project planning discussion for folks who didn't get to go on Tuesday: What are the inputs and outputs of the project you have in mind? What data is available and what is the 'answer' you want to get out of your tool?</li> <li>Review homework assignments in small groups (2-3 people)<ul> <li>For reference, here are our solutions to Session 5 challenges</li> </ul> </li> <li>Link to Lecture 6 slides: Python dictionaries, conditional statements (if/else), and intro to function definitions</li> </ul>"},{"location":"sessions/session-6/#in-class-exercises","title":"In class exercises","text":"<ul> <li>In-class microproject: The Wright-Fisher model</li> </ul>"},{"location":"sessions/session-6/#assignments","title":"Assignments","text":"<ul> <li> <p>Python tutorial readings:</p> <ul> <li>Chapter 4 (up to and including 4.9.3) on conditionals and functions</li> <li>Chapter 5 (from 5.5 to the end) on Dictionaries</li> </ul> </li> <li> <p>Problem sets covering python dictionaries, conditionals, and functions</p> </li> <li>Supplementary Reading and additional practice problems:<ul> <li>30 Days Of Python: Dictionaries</li> <li>30 Days of Python: Functions</li> </ul> </li> </ul>"},{"location":"sessions/session-7/","title":"Session 7","text":""},{"location":"sessions/session-7/#icebreaker-question","title":"Icebreaker question","text":"<p>If you could magically change one annoying thing about coding forever, what would it be?</p>"},{"location":"sessions/session-7/#learning-objectives","title":"Learning objectives","text":"<ul> <li>Review the assignments  </li> <li>Review the WF micro-project  </li> <li>Introduce classes  </li> <li>Introduce some other upcoming Python tricks  </li> <li>Discuss Exception handling</li> </ul>"},{"location":"sessions/session-7/#review-and-discussion","title":"Review and Discussion","text":"<ul> <li>Review homework assignments answers posted to github</li> </ul>"},{"location":"sessions/session-7/#in-class-exercises","title":"In class exercises","text":"<ul> <li>micro-project hacking</li> </ul>"},{"location":"sessions/session-7/#assignments","title":"Assignments","text":"<ul> <li>Read Python tutorial chapter 8 (Exceptions): https://docs.python.org/3/tutorial/errors.html</li> <li>Read Python tutorial chapter 9 (Classes): https://docs.python.org/3/tutorial/classes.html</li> <li> <p>Read Python tutorial chapter 10 (standard library): https://docs.python.org/3/tutorial/stdlib.html</p> </li> <li> <p>Complete tutorial 7.0-subprocess</p> </li> <li>Complete tutorial 7.1-think</li> <li>Complete tutorial 7.2-scripting</li> <li>Complete tutorial 7.3-imports</li> </ul>"},{"location":"sessions/session-8/","title":"Session 8","text":""},{"location":"sessions/session-8/#icebreaker-question","title":"Icebreaker question","text":"<ul> <li>What is one thing science will never understand?</li> </ul>"},{"location":"sessions/session-8/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will learn about object oriented programming and advanced python modules for scientific programming. By the end of this session you will  be more familiar with the following topics:</p> <ul> <li>Python classes, including data attributes and methods</li> <li>numpy: Efficient numerical computing tools</li> <li>pandas: Structured data analysis and manipulation</li> <li>scipy: Scientific computing algorithms</li> </ul>"},{"location":"sessions/session-8/#review-and-discussion","title":"Review and Discussion","text":"<ul> <li>Review homework assignments</li> </ul>"},{"location":"sessions/session-8/#in-class-exercises","title":"In class exercises","text":"<ul> <li>Link to Lecture 8 slides: Python Classes &amp; Scientific Python (numpy/pandas)</li> <li>In class coding activity: Implementing the WF model as a Python class</li> </ul>"},{"location":"sessions/session-8/#assignments","title":"Assignments","text":"<ul> <li>Read Python Data Science Handbook Ch 2 &amp; 3 (numpy &amp; pandas)</li> <li>Tutorials covering numpy &amp; pandas</li> </ul>"},{"location":"sessions/session-8/#additional-numpypandas-learning-resources","title":"Additional numpy/pandas learning resources","text":"<ul> <li>101 NumPy Exercises for Data Analysis</li> <li>Practical Tutorial on Data Manipulation with Numpy and Pandas in Python</li> <li>100 numpy exercises w/ hints &amp; solutions (github)</li> <li>Pandas exercises w/ solutions (github)</li> <li>100 Pandas puzzles (github)</li> </ul>"},{"location":"sessions/session-9/","title":"Session 9","text":""},{"location":"sessions/session-9/#icebreaker-question","title":"Icebreaker question","text":"<ul> <li>If you're on an outing, how many owls would you have to see before you got suspicious?</li> </ul>"},{"location":"sessions/session-9/#learning-objectives","title":"Learning objectives","text":"<p>In this session we will learn about 'scripting' which means creating executable python code that can be run at the command line, like other CLI programs. By the end of this session you will be more familiar with the following topics:</p> <ul> <li>How to structure a python script</li> <li>The <code>__main__</code> keyword</li> <li>Using <code>argparse</code> to read command line arguments</li> <li>Logging script processes</li> </ul>"},{"location":"sessions/session-9/#review-and-discussion","title":"Review and Discussion","text":"<p>Review homework assignments:</p> <ul> <li>WF model as a python class</li> <li>Revisiting the Iris data w/ numpy/padas</li> </ul>"},{"location":"sessions/session-9/#in-class-exercises","title":"In class exercises","text":"<ul> <li>9.0 Scripting tutorial</li> </ul>"},{"location":"sessions/session-9/#assignments","title":"Assignments","text":"<ul> <li>Read the python argparse tutorial</li> <li>9.1 Scripting the WF model</li> </ul>"},{"location":"tutorials/10.0-sublimetext3/","title":"Sublimetext3","text":"<p>Most biologists first learn to code by typing directly into a shell,  for example by starting an R or Python session in the terminal. Interactive coding environments are also hugely popular, such  as RStudio or Jupyter, which provide a code-editor-like  experience, where you can view or embed figures, see your variables,  and even access useful features like tab-completion. </p> <p>Code editors provide a different set of features from interactive coding  environments, and/or make them available in a faster and/or prettier way.  This includes syntax highlighting  (colorizing different components of code); linting (checking code for style or syntax errors before you run it); tab-completion (and  related documentation searching); building/executing  (allows you to test the code with single command); filetree organization (easier to see all files in folders);  and perhaps most important of all, keybindings. </p>"},{"location":"tutorials/10.0-sublimetext3/#learning-objectives","title":"Learning objectives","text":"<p>In this tutorial you will learn to setup <code>sublimetext</code> for Python development.</p>"},{"location":"tutorials/10.0-sublimetext3/#popular-text-editors-for-coding","title":"Popular text editors for coding","text":"<p>There are many coding text editors available, ranging from complex to simple, and many have a devoted cult following. Despite the many options, one modern editor has gained broad popularity recently: <code>vscode</code>. This has mostly replaced many editors that came before it, including <code>sublime</code>, <code>atom</code>, <code>emacs</code>, and <code>vim</code>. However, in my opinion there are some downsides to vscode  compared to other simpler options.  In particular, it tends to be slow and use a ton of memory, and it contains many distractions. I prefer a more sleek and minimal code editor. You are  free to explore code editors on your own time, but for this exercise, we  will focus on my personal favorite, sublimetext.</p> <p>History: Emacs and Vim have been around the longest and have historically been pitted  against each other as a sort of zero-sum battle to the death. Everyone learns  one or the other, completely falls in love with their choice, and abhors  the competing editor. This is partly because they are so different in style,  and when you get comfortable with one it feels unnatural to change. Regardless of which coding editor you prefer, I would implore you to become very  familiar with at least one coding editor, as the more you learn about how to use it, the more it will superpower your efficiency.</p>"},{"location":"tutorials/10.0-sublimetext3/#why-sublimetext","title":"Why sublimetext?","text":"<p>I personally recommend sublimetext. It is lightweight while also being  super extensible. Compared to vscode it lacks a few features (like a built-in terminal) that set vscode apart, but I am fine with keeping a shell  open to the side of my editor, if needed. Sublime starts up faster, and by  default, it tries to do less than vscode -- it is more minimal. The default setup for vscode examines your entire operating system and tries  to recommend many extensions to you: \"I see you are on wsl2, do you want me to  install the wsl2 extension?\"; \"I see that you don't have a linter installed, do you want me to install one?\" I find this very intrusive.  It leaves you with less knowledge of your setup, since the program  tries to do it all for you. Instead, this tutorial will walk you through  a step-by-step approach to setting up your editor, and in the end  I think you will have a better idea on how to toggle or edit these options.  Another cool feature of sublimetext is that the program itself is written  in Python!</p>"},{"location":"tutorials/10.0-sublimetext3/#install-sublimetext3","title":"Install SublimeText3","text":"<p>To install sublimetext go to https://www.sublimetext.com/ and download the appropriate installer for your operating system. If you are on a mac  then after downloading the DMG file click to open it and run the installer. When finished it should show you a folder with Applications/ and a SublimeText icon in it. Just drag the icon into your Applications folder and you are done. You can then remove the DMG installer file (e.g., drag it to Trash). If you are on Windows the SublimeText application should be accessible in your applications  after installation.</p>"},{"location":"tutorials/10.0-sublimetext3/#test-scripts","title":"Test scripts","text":"<p>To test that your code editor is properly configured we will use it  to examine and edit Python scripts organized into a modular directory  structure. Here we are not planning to push our changes back to GitHub, so you do not need to fork this repo, you can just clone the version from the URL below. I recommend you first cd into your hacks directory and then clone the repo there.</p> <pre><code>cd ~/hacks\ngit clone https://github.com/hackers-test/hack-9-python\n</code></pre>"},{"location":"tutorials/10.0-sublimetext3/#getting-started","title":"Getting started","text":"<p>Next, open sublimetext. You should see two panels, a skinny one on the left and  a wider one on the right. If you don't see this, go to the View tab at the top, and then \"Side bar\" and select show sidebar.  The left panel (side bar) is the file tree that will show you files and  directories accessible from your path. That's right, just like when using a terminal, sublime is aware of the location in which you are accessing files. We can change our location in a number of ways. Let's start by going to the  File tab at the top of sublime, select \"Open Folder\", and then select the <code>hack-9-python</code> folder that we just cloned from where it is located in your filesystem. This should populate the side bar with files and folders from this path location.</p> <p>Another way you can quickly open a editor view to a path if you are using Linux of MacOSX is to use the <code>subl</code> command from a terminal, like below. [Update: it turns out this option is not available by default for Mac users, see the section at the end of this tutorial for how to set it up. Sorry  Windows users I have not had an opportunity to test this for you yet. I expect it will require a similar solution as in OSX, but implemented in WSL. This is totally optional.]</p>          Sorry, your browser doesn't support embedded videos."},{"location":"tutorials/10.0-sublimetext3/#the-command-palette","title":"The command palette","text":"<p>All of Sublimetext is centered around a feature called the command palette. This is a place where you can access all of the options from the dropdown menus, as well as hundreds of additional options for performing operations in the editor. Many of these have keyboard shortcuts, as we will discuss further below, but many others do not, and can only be accessed by finding them in the command palette. To open the command palette on a Mac press cmd+shift+p (hold down command and shift then press 'p'). You can press this key combination again to close the command palette.  The command palette serves as a search bar, so you can begin to type any keywords associated with a command and it will filter the list of possible solutions to match your entry.</p>          Sorry, your browser doesn't support embedded videos."},{"location":"tutorials/10.0-sublimetext3/#hotkeys-and-keybindings","title":"Hotkeys and keybindings","text":"<p>When describing the benefits of learning a text editor I emphasize that  keybindings are one of the most important features. These are learned key-strokes that can be used to accomplish repetitive tasks more efficiently. This includes mundane things like moving your cursor up one line, or to the  end of a line, or highlighting and replacing all instances of the word 'foo' with 'bar'. Such common tasks are the bread and butter of  programming. By learning to enter a set of keystrokes to perform these  activities, rather than using the mouse to select items on the  screen, your efficiency will improve 10X. In fact, once your learn a set of keybindings well, you will become so comfortable and dependent on them that you will likely find it exhausting to type text into any other programs, such as MS Word, that does not support the same richness of key strokes.</p> <p>How do you learn keybindings? Well, you just learned your first one above,  the key-stroke cmd+shift+p to open the command palette. Learning others will take time and practice, but it is worth it. My best tips for learning are to: (1) pick a text editor and stick with it; use the text-editor frequently (take notes with it, write documents and code in it); (3)  when you find yourself reaching for the mouse, stop yourself, and instead search for the appropriate keystroke and try to infuse it to your muscle  memory.</p> <p>How to look up keybindings? It depends which keybindings you are trying to  learn. SublimeText has a default set of keybindings, and those may be the easiest for you to learn, but you also have the choice of installing  alternatives. We'll return to this subject in a minute after learning  about how to install packages.</p>"},{"location":"tutorials/10.0-sublimetext3/#package-control","title":"Package Control","text":"<p>One of the best features of sublimetext is the rich community of developers that create open source packages to extend its capabilities. We will install a few of these now to demonstrate their utility. First, you will need to  install the feature that allows you to search for other packages, called \"Package Control\". To do this, open the command palette and type  Install Package Control and select it. After about one second it  should finish and you are now ready to install packages.</p> <p>You can now use the following steps to install any package: - open the command palette (cmd+shift+p) - type install package and select \"package control: install package\" - enter the name of the program you wish to install and select the match from  the dropdown list. - hit enter and wait for it to finish (usually a new tab will pop-up to provide  info on the installed package, but sometimes not).</p> <p>Let's try it first with a simple package called bracket highlighter. This does exactly what it says, it highlights the brackets on either side of your selection when writing code, making it easier to see which bracket closes a given context. Simply follow the 4-step instructions above to install it. If that worked, then continue to install all of the following packages. Don't worry, these are all very small and lightweight, and can be easily  toggled on or off.</p> <ul> <li>BracketHighlighter: highlights the matching bracket in code.</li> <li>GitGutter: highlights in the gutter which lines have changed.</li> <li>Sublimelinter: enables linters.</li> <li>SublimeLinter-contrib-ruff: a specific linter.</li> <li>Emacs Pro Essentials: enables emacs keybindings.</li> </ul>"},{"location":"tutorials/10.0-sublimetext3/#disable-or-enable-packages","title":"Disable or Enable packages","text":"<p>If you download a package and decide that you no longer like what it does,  you can simply turn it off by typing \"disable package\" into the command  palette and selecting the name of the package you want to disable. (Note: for some packages that affect the look/style of subl you will need to  restart it for them to take effect.) Try this now by disabling the package  'Emacs Pro Essentials'. Then open the command palette and type \"enable\" to find and execute the command to Enable it again.</p>          Sorry, your browser doesn't support embedded videos."},{"location":"tutorials/10.0-sublimetext3/#keybindings-revisited","title":"Keybindings revisited","text":"<p>You now have two options for key-bindings, either the default sublime keys, or the set in your disabled package 'emacs pro essentials'. There are other options as well, such as a package that emulates the keybindings in 'vim'.  In addition to these, you can actually define any keybindings you want by  editing your settings in sublime; simply type keybindings into the command palette it will open up a new window showing you the default system keys on the left, and with a space to write commands to override those on the right. You can mix and match any keys you like. Close this window for now.</p> <p>The default keybindings in sublime is built especially for this editor,  and thus works the most seamlessly, but is highly specific to sublime.  The emacs keyset on the other hand uses many of the same keybindings that also work in your terminal (e.g., ctrl-a and ctrl-e to move the cursor to the beginning versus end of a line, as we learned previously),  and so learning these provides utility that is more broadly transferrable.  Personally, I'm hooked on emacs keybindings and I'll never change.  But if you're learning for the first time you may consider one of the alternatives. Even if you implement the emacs or vim keys in sublime all of its other features are still available to you either through different  keystrokes, or through the command palette. </p>"},{"location":"tutorials/10.0-sublimetext3/#practice-using-emacs-style-keys","title":"Practice using emacs-style keys","text":"<p>Basic Keybindings: Readline vs. Emacs Movement and Navigation:</p> <pre><code>Ctrl + a: Move cursor to the beginning of the line \nCtrl + e: Move cursor to the end of the line \nCtrl + f: Move cursor forward by one character \nCtrl + b: Move cursor backward by one character \nCtrl + n: Move cursor down by one character\nCtrl + p: Move cursor up by one character\nAlt + f: Move cursor forward by one word \nAlt + b: Move cursor backward by one word\n</code></pre> <p>Editing and Deleting:</p> <pre><code>Ctrl + d: Delete the character under the cursor\nCtrl + k: Kill (cut) the text from the cursor to the end of the line\nCtrl + y: Yank (paste) the last killed text\nCtrl + /: Comment this line\n</code></pre> <p>Undo and Redo:</p> <pre><code>Ctrl + _ (ctrl + shift + -): Undo the last action.\nCtrl + g: Cancel the current command or editing.\n</code></pre> <p>Search and History:</p> <pre><code>Ctrl + r: search up through script from cursor location\nCtrl + h: open search and replace box for one script (local)\nCtrl + shift + f: open search and replace for whole directory (global)\n</code></pre> <p>Save changes to a file:</p> <pre><code>Ctrl + x + s (Ctrl+x then Ctrl+s): Save file.\n</code></pre>"},{"location":"tutorials/10.0-sublimetext3/#configuring-for-your-python-environment","title":"Configuring for your Python environment","text":"<p>For some extensions to work properly they must be able to find the  specific Python installation that you want them to use. In this case we  of course will want sublime to find our conda installed version of Python and its packages. This can be specified globally, but I prefer to set this option separately for each project, since you may have different conda environments associated with different projects. To do this we need to create a Project file for our current project.</p> <p>Go the <code>Project</code> tab at the top of your SublimeText editor and select \"Save Project as\". (Follow these instructions carefully). This will open a view to your filesystem with  a default name for the Project file labeled \"untitled.sublime-project\". Rename this file to \"darwinday.sublime-project\" then select in the file browser to make sure it is saving it to your <code>hack-9-python</code> directory, then click save. You should now see the darwinday.sublime-project file in your left side bar. Click on it in sublime to open it in the edit panel. You should see something like below, which is a mostly empty JSON format file where we can entere preferences for this project:</p> <pre><code>{\n    \"folders\":\n    [\n        {\n            \"path\": \".\"\n        }\n    ]\n}\n</code></pre> <p>The only variable defined in here so far is \"path\", which is telling it the path location of files to show in the left side bar. Follow the instructions below to add additional variables to this that will specify which version of Python we want to use to execute code (i.e., the build system), and some other things.</p>"},{"location":"tutorials/10.0-sublimetext3/#configuring-a-build-system","title":"Configuring a build system","text":"<p>Navigate to the file called <code>darwinday.py</code> in the sidebar file browser. Once the file is opened, use the dropdown menu to select Tools, Build System, and then Automatic. Now press CMD+B to build the script (or a  similar keystroke, depending on your system; look in the dropdown menu),  meaning that it will execute the script as if it had been called from the  terminal. The 'automatic' mode should provide a dropdown asking you which  build system to use. Select Python (or something similar that it shows),  which tells it to execute the current file using the default Python build settings. This is equivalent to calling <code>python darwinday.py</code> from a  terminal to execute the script. Because this python module  has a <code>__main__</code> dunder at the end designating which part of the code is meant to be run as an executable, it should run that part of the  code and print the output in a build-results window that will pop up from the bottom of sublime. It should print a few strings of text into the  stdout palette that will open at the bottom of your sublimetext editor.</p> <p>Hopefully this worked. But this is actually NOT what we will be using going forward. In general, we do not want to use the system-wide version of Python, we want to use a specific version that is installed in a conda environment. To do this we will set a specific \"build system\" for this project.</p> <p>For this we'll follow instructions below. Go to your Project file in the left side bar and enter your file path to your conda versin of Python.  To check this is absolutely correct look for this path in your terminal  first by using tab auto-completion. Your path will be similar to my example below, but different for your OS and username.  Note that you cannot use relative path names here (no .. or ~ characters in the path). Once your project script looks similar to the one below, save the file by typing <code>ctrl+x ctrl+s</code> (or look at the File tab, then save, for the similar keystroke for your OS) Then save the file and it should ask you to save it in </p> Linux / MacWindows (WSL) <pre><code>{\n    \"folders\":\n    [\n        {\n            \"path\": \".\"\n        }\n    ],\n    \"build_systems\": [\n        {\n            \"name\": \"python-conda-base\",\n            \"cmd\": [\"/home/deren/miniconda3/bin/python\", \"$file\"],\n            \"file_regex\": \"^\\\\s*File \\\"(...*?)\\\", line ([0-9]*)\",\n            \"selector\": \"source.python\",                \n        },\n    ],\n}\n</code></pre> <pre><code>{\n    \"folders\":\n    [\n        {\n            \"path\": \".\"\n        }\n    ],\n    \"build_systems\": [\n        {\n            \"name\": \"python-conda-base\",                \n            \"cmd\": [\"wsl\", \"/home/deren/miniconda3/bin/python\", \"$file\"],\n            \"file_regex\": \"^(...*?):([0-9]*):?([0-9]*)\",\n            \"selector\": \"source.python\"\n        },\n    ],\n}\n</code></pre> <p>Note that if you are on Windows WSL you should click on the tab in the code block above to view the slightly different instructions. Please message me if this doesn't work for you, I was not able to test it yet at the time of writing.</p> <p>Now when you try to build a Python file by pressing CMD+B it will ask you to select either python or python-conda-base as the build option, and you can  choose the latter to build with your latest version of Python. To set this as the default choice go to the tool bar and select Tools, Build System, and select python-conda-base instead of Automatic. This will be remembered for this project.</p>"},{"location":"tutorials/10.0-sublimetext3/#configuring-your-linters","title":"Configuring your linters","text":"<p>Next we will install a linter. This is a tool that will highlight errors in your code for you. First we need to install the linter into our conda environment. We will use the Python linter <code>ruff</code>. Run the following in a terminal for your default conda environment.</p> <pre><code>conda install ruff -c conda-forge \n</code></pre> <p>Next, to configure sublime to be able to find this specific linter let's add the path to the linter to our Project file like below. This goes in a section  called settings. As long as we are adding settings I also added a few additional ones that are nice. Once again, set the path to the ruff executable using your filepath, not mine.</p> Linux / MacWindows (WSL) <pre><code>{\n    \"folders\":\n    [\n        {\n            \"path\": \".\"\n        }\n    ],\n    \"settings\": {\n        \"tab_size\": 4,\n        \"translate_tabs_to_spaces\": true,\n        \"trim_automatic_white_space\": true,\n        \"SublimeLinter.linters.ruff.executable\": \"/home/deren/miniconda3/bin/ruff\",\n    },\n    \"build_systems\": [\n        {\n            \"name\": \"python-conda-base\",\n            \"cmd\": [\"/home/deren/miniconda3/bin/python\", \"$file\"],\n            \"file_regex\": \"^\\\\s*File \\\"(...*?)\\\", line ([0-9]*)\",\n            \"selector\": \"source.python\",                \n        },\n    ],\n}\n</code></pre> <pre><code>{\n    \"folders\":\n    [\n        {\n            \"path\": \".\"\n        }\n    ],\n    \"settings\": {\n        \"tab_size\": 4,\n        \"translate_tabs_to_spaces\": true,\n        \"trim_automatic_white_space\": true,\n        \"SublimeLinter.linters.ruff.executable\": \"/home/deren/miniconda3/bin/ruff\",\n    },        \n    \"build_systems\": [\n        {\n            \"name\": \"python-conda-base\",                \n            \"cmd\": [\"wsl\", \"/home/USERNAME/miniconda3/bin/python\", \"$file\"],\n            \"file_regex\": \"^(...*?):([0-9]*):?([0-9]*)\",\n            \"selector\": \"source.python\"\n        },\n    ],\n}\n</code></pre>"},{"location":"tutorials/10.0-sublimetext3/#alternative-setup-options","title":"Alternative setup options","text":"<p>Note: There are other ways to setup sublimetext to try to automate this process, similar to in vscode. If you go searching you might find instructions to install a sublimetext text package called <code>anaconda</code> for interacting with a conda environment. I don't  recommend this.</p>"},{"location":"tutorials/10.0-sublimetext3/#optional-start-subl-from-the-terminal","title":"[Optional] Start <code>subl</code> from the terminal","text":"<p>For some reason the default installation method on OSX does not install  the <code>subl</code> binary into your PATH. This means that initially you can only  start sublimetext by clicking on the icon in your Applications bar, and then  finding the file or folder that you want to open from within sublimetext.  That's fine, but it feels a bit slow to me. More often, you will find yourself working in your terminal, <code>cd</code>'d into a directory that you are working on, and you will then decide you want to open sublimetext from within that location. It's convenient to be able to open your editor to a view of your current directory. So, the first customized setup option we are going to configure is to setup  the <code>subl</code> binary (if you are on Linux you'll already have it).</p> <p>Here is a demonstration of what we will enable:</p>          Sorry, your browser doesn't support embedded videos.      <p>To enable this we will create a new symlink, called <code>subl</code>, that will be  located in your PATH and point to the installed sublimetext binary in Applications. Up to this point in class we have only installed local software using <code>conda</code>.  Here we are instead installing a tool that we want to be available system-wide.  To make this work we will add the symlink to a location where other binaries  are located globally, in <code>/usr/local/bin/</code>. You will need permissions to write the symlink into this location, so the  following will ask for your password. Be sure to use tab-completion (seriously, always) when writing the filepaths below to make sure you do not enter a typo.</p> <pre><code>sudo ln -s \"/Applications/Sublime Text.app/Contents/SharedSupport/bin/subl\" /usr/local/bin/subl\n</code></pre> <p>Perfect. Now that <code>subl</code> is in your PATH you can call it from any location from  your terminal. Try it out for youself now. In your terminal use <code>cd</code> to  navigate to the <code>~/hacks</code> directory and start sublimetext to see all of your repos for this class in one place in your text editor. Or, you can just enter the filepath of your hacks folder as the target to <code>subl</code> like in the example below:</p> <pre><code>subl ~/hacks/\n</code></pre>"},{"location":"tutorials/10.1-style/","title":"black style","text":""},{"location":"tutorials/10.1-style/#python-linters","title":"Python linters","text":""},{"location":"tutorials/10.1-style/#learning-objectives","title":"Learning objectives:","text":"<p>By the end of this tutorial you should: - Understand why using a style guide is a good idea - Be familiar with the 'black' style guide for Python. - Be able to implement 'black' on your code from a shell.</p>"},{"location":"tutorials/10.1-style/#install-some-linters","title":"Install some linters","text":"<p>Let's start with installing the <code>pycodestyle</code>, <code>pylint</code> and <code>black</code> linters.</p> <pre><code>conda install pycodestyle pylint black -c conda-forge\n</code></pre>"},{"location":"tutorials/10.1-style/#reading","title":"Reading","text":"<p>Please read the following short article about why using a style guide is a good idea. - Why use a style guide (JS)</p> <p>Then read the following articles which introduce black, and why you should use it as your preferred style. (I do not necessary promote this as the best style guide,  personally I use pylint, but I think black is good to know about.) - Black code style</p>"},{"location":"tutorials/10.1-style/#implementing-black","title":"Implementing black","text":"<p>Unlike other linters that we will learn about, black is intended not to be modified,  in other words, if you use black you are expected to accept all of its recommendations. For this reason, it doesn't really function as a recommender, but moreso as an  implementer. It can make changes directly to your Python files to fix the style errors that it finds. Personally, I find this a little obtrusive, so I always first  run it with the argument <code>--diff</code>, which will show you the changes it intends to make  without actually making them. It's sort of a dry run. </p> <p>Let's try this on a few example files from a public repository. Use the commands below to clone two repos into your <code>~/hacks</code> directory. We will not bother forking the repos this time, since we do not intend to push the changes we will make to these files back to the origin repos.</p> <pre><code>cd ~/hacks/\ngit clone https://github.com/rajanil/fastStructure\ngit clone https://github.com/eaton-lab/toytree/\n</code></pre> <p>Let's start by running black on one of the main scripts in the fastStructure package. This is a tool that was published about 6 years ago, so its a bit outdated now, but  still in common use. It is written in Python2.7, and impressively black is able to  recognize this and propose changes to the code style. Here I run it using the  <code>--diff</code> option. </p> <p>The format of this output is called a <code>diff</code>, it is showing the differences  between the original file and the file that black would have made if it had been allowed to overwrite the original file (i.e., if we hadn't used the --diff arg). On the left side of each line it shows a minus or plus sign. The minus lines are from the old file, and the plus lines are showing what would replace the old lines. In some cases it may look like no change was made,  this usually means that the difference has to do with the whitespace, for example,  by removing extra spaces at the ends of lines.</p> <p><pre><code>black --diff fastStructure/structure.py\n</code></pre> <pre><code>--- fastStructure/structure.py  2021-02-03 17:02:15.106875 +0000\n+++ fastStructure/structure.py  2021-02-03 21:20:31.833481 +0000\n@@ -1,137 +1,157 @@\n-\n import numpy as np\n-import fastStructure \n+import fastStructure\n import parse_bed\n import parse_str\n import random\n import getopt\n import sys\n import pdb\n import warnings\n\n # ignore warnings with these expressions\n-warnings.filterwarnings(&amp;apos;ignore&amp;apos;, &amp;apos;.*divide by zero.*&amp;apos;,)\n-warnings.filterwarnings(&amp;apos;ignore&amp;apos;, &amp;apos;.*invalid value.*&amp;apos;,)\n+warnings.filterwarnings(\n+    &amp;quot;ignore&amp;quot;,\n+    &amp;quot;.*divide by zero.*&amp;quot;,\n+)\n+warnings.filterwarnings(\n+    &amp;quot;ignore&amp;quot;,\n+    &amp;quot;.*invalid value.*&amp;quot;,\n+)\n+\n\n def parseopts(opts):\n\n     &amp;quot;&amp;quot;&amp;quot;\n     parses the command-line flags and options passed to the script\n     &amp;quot;&amp;quot;&amp;quot;\n\n-    params = {&amp;apos;mintol&amp;apos;: 1e-6,\n-            &amp;apos;prior&amp;apos;: &amp;quot;simple&amp;quot;,\n-            &amp;apos;cv&amp;apos;: 0,\n-            &amp;apos;full&amp;apos;: False,\n-            &amp;apos;format&amp;apos;: &amp;apos;bed&amp;apos;\n-            }\n+    params = {\n+        &amp;quot;mintol&amp;quot;: 1e-6,\n+        &amp;quot;prior&amp;quot;: &amp;quot;simple&amp;quot;,\n+        &amp;quot;cv&amp;quot;: 0,\n+        &amp;quot;full&amp;quot;: False,\n+        &amp;quot;format&amp;quot;: &amp;quot;bed&amp;quot;,\n+    }\n\n     for opt, arg in opts:\n\n         if opt in [&amp;quot;-K&amp;quot;]:\n-            params[&amp;apos;K&amp;apos;] = int(arg)\n+            params[&amp;quot;K&amp;quot;] = int(arg)\n\n         elif opt in [&amp;quot;--input&amp;quot;]:\n-            params[&amp;apos;inputfile&amp;apos;] = arg\n+            params[&amp;quot;inputfile&amp;quot;] = arg\n\n         elif opt in [&amp;quot;--output&amp;quot;]:\n-            params[&amp;apos;outputfile&amp;apos;] = arg\n+            params[&amp;quot;outputfile&amp;quot;] = arg\n\n         elif opt in [&amp;quot;--prior&amp;quot;]:\n-            params[&amp;apos;prior&amp;apos;] = arg\n-\n-            if params[&amp;apos;prior&amp;apos;] not in [&amp;apos;simple&amp;apos;,&amp;apos;logistic&amp;apos;]:\n+            params[&amp;quot;prior&amp;quot;] = arg\n+\n+            if params[&amp;quot;prior&amp;quot;] not in [&amp;quot;simple&amp;quot;, &amp;quot;logistic&amp;quot;]:\n                 print &amp;quot;%s prior is not currently implemented, defaulting to the simple prior&amp;quot;\n-                params[&amp;apos;prior&amp;apos;] = &amp;apos;simple&amp;apos;\n+                params[&amp;quot;prior&amp;quot;] = &amp;quot;simple&amp;quot;\n\n         elif opt in [&amp;quot;--format&amp;quot;]:\n-            params[&amp;apos;format&amp;apos;] = arg\n+            params[&amp;quot;format&amp;quot;] = arg\n\n         elif opt in [&amp;quot;--cv&amp;quot;]:\n-            params[&amp;apos;cv&amp;apos;] = int(arg)\n-        \n+            params[&amp;quot;cv&amp;quot;] = int(arg)\n+\n         elif opt in [&amp;quot;--tol&amp;quot;]:\n-            params[&amp;apos;mintol&amp;apos;] = float(arg)\n+            params[&amp;quot;mintol&amp;quot;] = float(arg)\n\n         elif opt in [&amp;quot;--full&amp;quot;]:\n-            params[&amp;apos;full&amp;apos;] = True\n+            params[&amp;quot;full&amp;quot;] = True\n\n         elif opt in [&amp;quot;--seed&amp;quot;]:\n             np.random.seed(int(arg))\n             random.seed(int(arg))\n\n     return params\n\n+\n def checkopts(params):\n\n     &amp;quot;&amp;quot;&amp;quot;\n     checks if some of the command-line options passed are valid.\n     In the case of invalid options, an exception is always thrown.\n     &amp;quot;&amp;quot;&amp;quot;\n\n-    if params[&amp;apos;mintol&amp;apos;]&amp;lt;=0:\n+    if params[&amp;quot;mintol&amp;quot;] &amp;lt;= 0:\n         print &amp;quot;a non-positive value was provided as convergence criterion&amp;quot;\n         raise ValueError\n-    \n-    if params[&amp;apos;cv&amp;apos;]&amp;lt;0:\n+\n+    if params[&amp;quot;cv&amp;quot;] &amp;lt; 0:\n         print &amp;quot;a negative value was provided for the number of cross-validations folds&amp;quot;\n         raise ValueError\n\n-    if not params.has_key(&amp;apos;K&amp;apos;):\n+    if not params.has_key(&amp;quot;K&amp;quot;):\n         print &amp;quot;a positive integer should be provided for number of populations&amp;quot;\n         raise KeyError\n\n-    if params[&amp;apos;format&amp;apos;] not in [&amp;apos;bed&amp;apos;,&amp;apos;str&amp;apos;]:\n+    if params[&amp;quot;format&amp;quot;] not in [&amp;quot;bed&amp;quot;, &amp;quot;str&amp;quot;]:\n         print &amp;quot;%s data format is not currently implemented&amp;quot;\n         raise ValueError\n\n-    if params[&amp;apos;K&amp;apos;]&amp;lt;=0:\n+    if params[&amp;quot;K&amp;quot;] &amp;lt;= 0:\n         print &amp;quot;a negative value was provided for the number of populations&amp;quot;\n         raise ValueError\n-    \n-    if not params.has_key(&amp;apos;inputfile&amp;apos;):\n+\n+    if not params.has_key(&amp;quot;inputfile&amp;quot;):\n         print &amp;quot;an input file needs to be provided&amp;quot;\n-        raise KeyError \n-\n-    if not params.has_key(&amp;apos;outputfile&amp;apos;):\n+        raise KeyError\n+\n+    if not params.has_key(&amp;quot;outputfile&amp;quot;):\n         print &amp;quot;an output file needs to be provided&amp;quot;\n         raise KeyError\n-    \n+\n+\n def write_output(Q, P, other, params):\n\n     &amp;quot;&amp;quot;&amp;quot;\n     write the posterior means and variational parameters\n     to separate output files.\n     &amp;quot;&amp;quot;&amp;quot;\n\n-    handle = open(&amp;apos;%s.%d.meanQ&amp;apos;%(params[&amp;apos;outputfile&amp;apos;],params[&amp;apos;K&amp;apos;]),&amp;apos;w&amp;apos;)\n-    handle.write(&amp;apos;\\n&amp;apos;.join([&amp;apos;  &amp;apos;.join([&amp;apos;%.6f&amp;apos;%i for i in q]) for q in Q])+&amp;apos;\\n&amp;apos;)\n+    handle = open(&amp;quot;%s.%d.meanQ&amp;quot; % (params[&amp;quot;outputfile&amp;quot;], params[&amp;quot;K&amp;quot;]), &amp;quot;w&amp;quot;)\n+    handle.write(&amp;quot;\\n&amp;quot;.join([&amp;quot;  &amp;quot;.join([&amp;quot;%.6f&amp;quot; % i for i in q]) for q in Q]) + &amp;quot;\\n&amp;quot;)\n     handle.close()\n\n-    handle = open(&amp;apos;%s.%d.meanP&amp;apos;%(params[&amp;apos;outputfile&amp;apos;],params[&amp;apos;K&amp;apos;]),&amp;apos;w&amp;apos;)\n-    handle.write(&amp;apos;\\n&amp;apos;.join([&amp;apos;  &amp;apos;.join([&amp;apos;%.6f&amp;apos;%i for i in p]) for p in P])+&amp;apos;\\n&amp;apos;)\n+    handle = open(&amp;quot;%s.%d.meanP&amp;quot; % (params[&amp;quot;outputfile&amp;quot;], params[&amp;quot;K&amp;quot;]), &amp;quot;w&amp;quot;)\n+    handle.write(&amp;quot;\\n&amp;quot;.join([&amp;quot;  &amp;quot;.join([&amp;quot;%.6f&amp;quot; % i for i in p]) for p in P]) + &amp;quot;\\n&amp;quot;)\n     handle.close()\n\n-    if params[&amp;apos;full&amp;apos;]:\n-        handle = open(&amp;apos;%s.%d.varQ&amp;apos;%(params[&amp;apos;outputfile&amp;apos;],params[&amp;apos;K&amp;apos;]),&amp;apos;w&amp;apos;)\n-        handle.write(&amp;apos;\\n&amp;apos;.join([&amp;apos;  &amp;apos;.join([&amp;apos;%.6f&amp;apos;%i for i in q]) for q in other[&amp;apos;varQ&amp;apos;]])+&amp;apos;\\n&amp;apos;)\n+    if params[&amp;quot;full&amp;quot;]:\n+        handle = open(&amp;quot;%s.%d.varQ&amp;quot; % (params[&amp;quot;outputfile&amp;quot;], params[&amp;quot;K&amp;quot;]), &amp;quot;w&amp;quot;)\n+        handle.write(\n+            &amp;quot;\\n&amp;quot;.join([&amp;quot;  &amp;quot;.join([&amp;quot;%.6f&amp;quot; % i for i in q]) for q in other[&amp;quot;varQ&amp;quot;]])\n+            + &amp;quot;\\n&amp;quot;\n+        )\n         handle.close()\n\n-        handle = open(&amp;apos;%s.%d.varP&amp;apos;%(params[&amp;apos;outputfile&amp;apos;],params[&amp;apos;K&amp;apos;]),&amp;apos;w&amp;apos;)\n-        handle.write(&amp;apos;\\n&amp;apos;.join([&amp;apos;  &amp;apos;.join([&amp;apos;%.6f&amp;apos;%i for i in np.hstack((pb,pg))]) \\\n-            for pb,pg in zip(other[&amp;apos;varPb&amp;apos;],other[&amp;apos;varPg&amp;apos;])])+&amp;apos;\\n&amp;apos;)\n+        handle = open(&amp;quot;%s.%d.varP&amp;quot; % (params[&amp;quot;outputfile&amp;quot;], params[&amp;quot;K&amp;quot;]), &amp;quot;w&amp;quot;)\n+        handle.write(\n+            &amp;quot;\\n&amp;quot;.join(\n+                [\n+                    &amp;quot;  &amp;quot;.join([&amp;quot;%.6f&amp;quot; % i for i in np.hstack((pb, pg))])\n+                    for pb, pg in zip(other[&amp;quot;varPb&amp;quot;], other[&amp;quot;varPg&amp;quot;])\n+                ]\n+            )\n+            + &amp;quot;\\n&amp;quot;\n+        )\n         handle.close()\n\n+\n def usage():\n-    \n+\n     &amp;quot;&amp;quot;&amp;quot;\n     brief description of various flags and options for this script\n     &amp;quot;&amp;quot;&amp;quot;\n\n     print &amp;quot;\\nHere is how you can use this script\\n&amp;quot;\n-    print &amp;quot;Usage: python %s&amp;quot;%sys.argv[0]\n+    print &amp;quot;Usage: python %s&amp;quot; % sys.argv[0]\n     print &amp;quot;\\t -K &amp;lt;int&amp;gt; (number of populations)&amp;quot;\n     print &amp;quot;\\t --input=&amp;lt;file&amp;gt; (/path/to/input/file)&amp;quot;\n     print &amp;quot;\\t --output=&amp;lt;file&amp;gt; (/path/to/output/file)&amp;quot;\n     print &amp;quot;\\t --tol=&amp;lt;float&amp;gt; (convergence criterion; default: 10e-6)&amp;quot;\n     print &amp;quot;\\t --prior={simple,logistic} (choice of prior; default: simple)&amp;quot;\n@@ -139,16 +159,25 @@\n     print &amp;quot;\\t --format={bed,str} (format of input file; default: bed)&amp;quot;\n     print &amp;quot;\\t --full (to output all variational parameters; optional)&amp;quot;\n     print &amp;quot;\\t --seed=&amp;lt;int&amp;gt; (manually specify seed for random number generator; optional)&amp;quot;\n\n\n-if __name__==&amp;quot;__main__&amp;quot;:\n+if __name__ == &amp;quot;__main__&amp;quot;:\n\n     # parse command-line options\n     argv = sys.argv[1:]\n     smallflags = &amp;quot;K:&amp;quot;\n-    bigflags = [&amp;quot;prior=&amp;quot;, &amp;quot;tol=&amp;quot;, &amp;quot;input=&amp;quot;, &amp;quot;output=&amp;quot;, &amp;quot;cv=&amp;quot;, &amp;quot;seed=&amp;quot;, &amp;quot;format=&amp;quot;, &amp;quot;full&amp;quot;] \n+    bigflags = [\n+        &amp;quot;prior=&amp;quot;,\n+        &amp;quot;tol=&amp;quot;,\n+        &amp;quot;input=&amp;quot;,\n+        &amp;quot;output=&amp;quot;,\n+        &amp;quot;cv=&amp;quot;,\n+        &amp;quot;seed=&amp;quot;,\n+        &amp;quot;format=&amp;quot;,\n+        &amp;quot;full&amp;quot;,\n+    ]\n     try:\n         opts, args = getopt.getopt(argv, smallflags, bigflags)\n         if not opts:\n             usage()\n             sys.exit(2)\n@@ -160,22 +189,27 @@\n     params = parseopts(opts)\n\n     # check if command-line options are valid\n     try:\n         checkopts(params)\n-    except (ValueError,KeyError):\n+    except (ValueError, KeyError):\n         sys.exit(2)\n\n     # load data\n-    if params[&amp;apos;format&amp;apos;]==&amp;apos;bed&amp;apos;:\n-        G = parse_bed.load(params[&amp;apos;inputfile&amp;apos;])\n-    elif params[&amp;apos;format&amp;apos;]==&amp;apos;str&amp;apos;:\n-        G = parse_str.load(params[&amp;apos;inputfile&amp;apos;])\n-    G = np.require(G, dtype=np.uint8, requirements=&amp;apos;C&amp;apos;)\n+    if params[&amp;quot;format&amp;quot;] == &amp;quot;bed&amp;quot;:\n+        G = parse_bed.load(params[&amp;quot;inputfile&amp;quot;])\n+    elif params[&amp;quot;format&amp;quot;] == &amp;quot;str&amp;quot;:\n+        G = parse_str.load(params[&amp;quot;inputfile&amp;quot;])\n+    G = np.require(G, dtype=np.uint8, requirements=&amp;quot;C&amp;quot;)\n\n     # run the variational algorithm\n-    Q, P, other = fastStructure.infer_variational_parameters(G, params[&amp;apos;K&amp;apos;], \\\n-                    params[&amp;apos;outputfile&amp;apos;], params[&amp;apos;mintol&amp;apos;], \\\n-                    params[&amp;apos;prior&amp;apos;], params[&amp;apos;cv&amp;apos;])\n+    Q, P, other = fastStructure.infer_variational_parameters(\n+        G,\n+        params[&amp;quot;K&amp;quot;],\n+        params[&amp;quot;outputfile&amp;quot;],\n+        params[&amp;quot;mintol&amp;quot;],\n+        params[&amp;quot;prior&amp;quot;],\n+        params[&amp;quot;cv&amp;quot;],\n+    )\n\n     # write out inferred parameters\n     write_output(Q, P, other, params)\n&lt;b&gt;would reformat fastStructure/structure.py&lt;/b&gt;\n&lt;b&gt;All done! \u2728 \ud83c\udf70 \u2728&lt;/b&gt;\n&lt;b&gt;1 file would be reformatted&lt;/b&gt;.\n</code></pre></p>"},{"location":"tutorials/10.1-style/#pylint","title":"Pylint","text":"<p>Running this first example below will encounter an error and STOP  when run on the structure.py script, since the script cannot successfully execute in its current mode. The terminal error in this case is caused by the fact  that pylint uses your current Python version to test for errors, and this script is written in Python2, whereas we are testing in Python3.  It raises an error saying that the print function is being called  incorrectly. This is a common error-producing difference between py2/3.  This is fine, good to know, we'll continue to the next example. <pre><code>pylint fastStructure/structure.py\n</code></pre> <pre><code>************* Module structure\nfastStructure/structure.py:44:23: E0001: Missing parentheses in call to &amp;apos;print&amp;apos;. Did you mean print(&amp;quot;%s prior is not currently implemented, defaulting to the simple prior&amp;quot;)? (&amp;lt;unknown&amp;gt;, line 44) (syntax-error)\n</code></pre></p> <p>Now let's run pylint on some code that is written to work in either Python 2 or Python 3. Writing code in this way is kind of a pain, but is worth it  for big general use packages. The Python package Toytree is an example.  You can see in this example that pylint finishes running and reports a score of 7.26/10. Not bad. It has several recommendations having to do with  mundane style (extra whitespace), but also some useful suggestions for cleaner code, like \"unnecessary else after break\". If we were to edit the files  at the suggested lines to implement these suggestions, and rerun pylint,  it should return improved scores until it reaches 10/10. <pre><code>pylint toytree/toytree/Rooter.py\n</code></pre> <pre><code>************* Module toytree.Rooter\ntoytree/toytree/Rooter.py:52:26: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:90:42: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:106:27: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:114:65: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:138:31: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:139:33: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:158:60: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:182:73: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:183:66: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:196:69: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:197:70: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:216:88: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:244:70: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:247:23: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:248:32: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:250:9: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:262:73: C0303: Trailing whitespace (trailing-whitespace)\ntoytree/toytree/Rooter.py:1:0: C0103: Module name &amp;quot;Rooter&amp;quot; doesn&amp;apos;t conform to snake_case naming style (invalid-name)\ntoytree/toytree/Rooter.py:11:0: C0115: Missing class docstring (missing-class-docstring)\ntoytree/toytree/Rooter.py:11:0: R0902: Too many instance attributes (11/7) (too-many-instance-attributes)\ntoytree/toytree/Rooter.py:50:8: C0103: Variable name &amp;quot;x0&amp;quot; doesn&amp;apos;t conform to snake_case naming style (invalid-name)\ntoytree/toytree/Rooter.py:51:8: C0103: Variable name &amp;quot;x1&amp;quot; doesn&amp;apos;t conform to snake_case naming style (invalid-name)\ntoytree/toytree/Rooter.py:70:4: C0116: Missing function or method docstring (missing-function-docstring)\ntoytree/toytree/Rooter.py:79:4: C0116: Missing function or method docstring (missing-function-docstring)\ntoytree/toytree/Rooter.py:83:8: W0212: Access to a protected member _coords of a client class (protected-access)\ntoytree/toytree/Rooter.py:131:12: R1723: Unnecessary &amp;quot;else&amp;quot; after &amp;quot;break&amp;quot; (no-else-break)\ntoytree/toytree/Rooter.py:104:4: R0912: Too many branches (13/12) (too-many-branches)\ntoytree/toytree/Rooter.py:228:4: C0112: Empty method docstring (empty-docstring)\ntoytree/toytree/Rooter.py:261:4: C0116: Missing function or method docstring (missing-function-docstring)\ntoytree/toytree/Rooter.py:281:8: C0103: Variable name &amp;quot;x0&amp;quot; doesn&amp;apos;t conform to snake_case naming style (invalid-name)\ntoytree/toytree/Rooter.py:282:8: C0103: Variable name &amp;quot;x1&amp;quot; doesn&amp;apos;t conform to snake_case naming style (invalid-name)\n\n------------------------------------------------------------------\nYour code has been rated at 7.26/10 (previous run: 7.26/10, +0.00)\n</code></pre></p> <p>You can see that pycodestyle makes similar recommendations as pylint, but fewer, mostly having to do with things of little consequence (extra whitespace or variable names). It does run quite a bit faster though, which is convenient for when the linter is  running automatically in the background of your code editor (as we'll see later). <pre><code>pycodestyle toytree/toytree/Rooter.py\n</code></pre></p> <pre><code>toytree/toytree/Rooter.py:30:80: E501 line too long (82 &amp;gt; 79 characters)\ntoytree/toytree/Rooter.py:52:27: W291 trailing whitespace\ntoytree/toytree/Rooter.py:70:5: E303 too many blank lines (3)\ntoytree/toytree/Rooter.py:79:5: E303 too many blank lines (2)\ntoytree/toytree/Rooter.py:87:5: E303 too many blank lines (3)\ntoytree/toytree/Rooter.py:90:43: W291 trailing whitespace\ntoytree/toytree/Rooter.py:104:5: E303 too many blank lines (3)\ntoytree/toytree/Rooter.py:106:28: W291 trailing whitespace\ntoytree/toytree/Rooter.py:114:66: W291 trailing whitespace\ntoytree/toytree/Rooter.py:138:32: W291 trailing whitespace\ntoytree/toytree/Rooter.py:139:34: W291 trailing whitespace\ntoytree/toytree/Rooter.py:145:80: E501 line too long (80 &amp;gt; 79 characters)\ntoytree/toytree/Rooter.py:158:61: W291 trailing whitespace\ntoytree/toytree/Rooter.py:182:74: W291 trailing whitespace\ntoytree/toytree/Rooter.py:183:67: W291 trailing whitespace\ntoytree/toytree/Rooter.py:194:5: E303 too many blank lines (3)\ntoytree/toytree/Rooter.py:196:70: W291 trailing whitespace\ntoytree/toytree/Rooter.py:197:71: W291 trailing whitespace\ntoytree/toytree/Rooter.py:216:80: E501 line too long (88 &amp;gt; 79 characters)\ntoytree/toytree/Rooter.py:216:89: W291 trailing whitespace\ntoytree/toytree/Rooter.py:220:17: E128 continuation line under-indented for visual indent\ntoytree/toytree/Rooter.py:220:80: E501 line too long (81 &amp;gt; 79 characters)\ntoytree/toytree/Rooter.py:221:17: E128 continuation line under-indented for visual indent\ntoytree/toytree/Rooter.py:221:80: E501 line too long (81 &amp;gt; 79 characters)\ntoytree/toytree/Rooter.py:222:17: E128 continuation line under-indented for visual indent\ntoytree/toytree/Rooter.py:223:17: E128 continuation line under-indented for visual indent\ntoytree/toytree/Rooter.py:228:5: E303 too many blank lines (3)\ntoytree/toytree/Rooter.py:244:71: W291 trailing whitespace\ntoytree/toytree/Rooter.py:247:24: W291 trailing whitespace\ntoytree/toytree/Rooter.py:248:33: W291 trailing whitespace\ntoytree/toytree/Rooter.py:250:10: W291 trailing whitespace\ntoytree/toytree/Rooter.py:261:5: E303 too many blank lines (3)\ntoytree/toytree/Rooter.py:262:74: W291 trailing whitespace\ntoytree/toytree/Rooter.py:270:5: E303 too many blank lines (3)\n</code></pre> <p>Finally, let's run black. Studying the output of the --diff command to black can be  really insightful about what the actual solutions are to the many recommendations that were provided by pylint above.  <pre><code>black --diff toytree/toytree/Rooter.py\n</code></pre> <pre><code>--- toytree/toytree/Rooter.py   2021-02-03 17:22:53.767184 +0000\n+++ toytree/toytree/Rooter.py   2021-02-03 21:30:12.332704 +0000\n@@ -26,11 +26,11 @@\n         # the new node that will be inserted\n         self.nnode = None\n\n         # make a copy and ensure supports are either all int or float\n         self.maxsup = max([int(i.support) for i in self.tree.treenode.traverse()])\n-        self.maxsup = (1.0 if self.maxsup &amp;lt;= 1.0 else 100)\n+        self.maxsup = 1.0 if self.maxsup &amp;lt;= 1.0 else 100\n         self.get_features()\n\n         # parse node selecting arguments (nastuple) with NodeAssist\n         self.get_match(*nastuple)\n\n@@ -45,13 +45,13 @@\n             if len(self.node2.children) == 1:\n                 self.node2 = self.node2.up\n                 self.node1 = self.node1.up\n\n         # if rooting where root already exists then return current tree\n-        x0 = (self.node1.is_root())\n-        x1 = (self.node2.is_root() and self.tree.is_rooted())\n-        if not (x0 or x1):           \n+        x0 = self.node1.is_root()\n+        x1 = self.node2.is_root() and self.tree.is_rooted()\n+        if not (x0 or x1):\n\n             # create new root node on an existing edge to split it.\n             self.insert_new_node()\n\n             # update edge lengths given new node insertion\n@@ -62,58 +62,51 @@\n             self.restructure_tree()\n\n             # update coodrds on tree\n             self.update_tree_from_tdict()\n             self.update()\n-\n-\n\n     def update_tree_from_tdict(self):\n         # update tree structure and node labels\n         for node in self.tdict:\n             node.up = self.tdict[node][0]\n             node.children = self.tdict[node][1]\n             for key, val in self.tdict[node][2].items():\n                 setattr(node, key, val)\n\n-\n     def update(self):\n         # update coordinates which updates idx and adds it to any new nodes.\n         self.tree.treenode = self.nnode\n         self.tree.treenode.ladderize()\n         self.tree._coords.update()\n\n-\n-\n     def redirect_edge_features(self):\n         &amp;quot;&amp;quot;&amp;quot;\n         Set support values to maximum for new node since the user forced\n-        rooting, i.e, it is not uncertain. \n+        rooting, i.e, it is not uncertain.\n         &amp;quot;&amp;quot;&amp;quot;\n         # mark new split with zero...\n         for feature in set(self.edge_features) - set([&amp;quot;support&amp;quot;, &amp;quot;dist&amp;quot;]):\n             self.tdict[self.node2][2][feature] = 0.0\n\n         # unless support value, then mark with full.\n         if &amp;quot;support&amp;quot; in self.edge_features:\n-            self.tdict[self.node2][2][&amp;apos;support&amp;apos;] = self.maxsup\n+            self.tdict[self.node2][2][&amp;quot;support&amp;quot;] = self.maxsup\n         else:\n-            self.tdict[self.node2][2][&amp;apos;support&amp;apos;] = self.node2.support\n-\n-\n+            self.tdict[self.node2][2][&amp;quot;support&amp;quot;] = self.node2.support\n\n     def restructure_tree(self):\n         &amp;quot;&amp;quot;&amp;quot;\n-        At this point tdict \n+        At this point tdict\n            (node): (parent) (children), features\n         {\n             nnode: [None, [node1, node2], {}]\n             node1: [nnode, node1.children, {&amp;apos;dist&amp;apos;}]\n             node2: [nnode, node2.children, {&amp;apos;dist&amp;apos;: 0.0}]\n         }\n         &amp;quot;&amp;quot;&amp;quot;\n-        # start with the node leading from new root child2 to the \n+        # start with the node leading from new root child2 to the\n         # rest of the tree structure and move up until old root.\n         tnode = self.node2.up\n\n         # label all remaining nodes by moving up from tnode to old root.\n         while 1:\n@@ -133,12 +126,12 @@\n                 # need a root add feature here if unrooted...\n                 if len(children) &amp;gt; 1:\n\n                     # update dist from new parent\n                     self.tdict[tnode] = [\n-                        parent, \n-                        children, \n+                        parent,\n+                        children,\n                         {&amp;quot;dist&amp;quot;: parent.dist},\n                     ]\n\n                     # update edge features from new parent\n                     for feature in self.edge_features:\n@@ -153,11 +146,11 @@\n\n                 # get children that are not in tdict yet\n                 else:\n                     for child in children:\n\n-                        # record whose children they are now \n+                        # record whose children they are now\n                         # (node2 already did this)\n                         if parent is self.node2:\n                             self.tdict[self.node2][1].append(child)\n                         else:\n                             self.tdict[parent][1].append(child)\n@@ -170,33 +163,31 @@\n                 break\n\n             # normal nodes\n             else:\n                 # update tnode.features [dist will be inherited from child]\n-                features = {&amp;apos;dist&amp;apos;: tnode.dist, &amp;apos;support&amp;apos;: tnode.support}\n+                features = {&amp;quot;dist&amp;quot;: tnode.dist, &amp;quot;support&amp;quot;: tnode.support}\n\n                 # keep connecting swap parent-child up to root\n                 if not tnode.up.is_root():\n                     children += [tnode.up]\n\n                 # pass support values down (up in new tree struct)\n-                child = [i for i in tnode.children if i in self.tdict][0]                \n-                for feature in {&amp;apos;dist&amp;apos;}.union(self.edge_features):                   \n+                child = [i for i in tnode.children if i in self.tdict][0]\n+                for feature in {&amp;quot;dist&amp;quot;}.union(self.edge_features):\n                     features[feature] = getattr(child, feature)\n\n                 # store node update vals\n                 self.tdict[tnode] = [parent, children, features]\n\n             # move towards root\n             tnode = tnode.up\n\n-\n-\n     def config_root_dist(self):\n         &amp;quot;&amp;quot;&amp;quot;\n-        Now that the new root node is inserted .dist features must be \n-        set for the two descendant nodes. Midpoint rooting is a common \n+        Now that the new root node is inserted .dist features must be\n+        set for the two descendant nodes. Midpoint rooting is a common\n         option, but users can toggle &amp;apos;resolve_root_dist&amp;apos; to change this.\n         &amp;quot;&amp;quot;&amp;quot;\n         # if not already at root polytomy, then connect node2 to parent\n         if self.node2.up:\n             if not self.node2.up.is_root():\n@@ -206,31 +197,29 @@\n         if self.resolve_root_dist is False:\n             self.resolve_root_dist = 0.0\n\n         # if True then use midpoint rooting\n         elif self.resolve_root_dist is True:\n-            self.tdict[self.node1][2][&amp;quot;dist&amp;quot;] = self.node1.dist / 2.\n-            self.tdict[self.node2][2][&amp;quot;dist&amp;quot;] = self.node1.dist / 2.\n+            self.tdict[self.node1][2][&amp;quot;dist&amp;quot;] = self.node1.dist / 2.0\n+            self.tdict[self.node2][2][&amp;quot;dist&amp;quot;] = self.node1.dist / 2.0\n\n         # split the edge on 0 or a float\n         if isinstance(self.resolve_root_dist, float):\n-            self.tdict[self.node1][2][&amp;quot;dist&amp;quot;] = self.node1.dist - self.resolve_root_dist            \n+            self.tdict[self.node1][2][&amp;quot;dist&amp;quot;] = self.node1.dist - self.resolve_root_dist\n             self.tdict[self.node2][2][&amp;quot;dist&amp;quot;] = self.resolve_root_dist\n             if self.resolve_root_dist &amp;gt; self.node1.dist:\n-                raise ToytreeError(&amp;quot;\\n&amp;quot;\n-                &amp;quot;To preserve existing edge lengths the &amp;apos;resolve_root_dist&amp;apos; arg\\n&amp;quot;\n-                &amp;quot;must be smaller than the edge being split (it is selecting a \\n&amp;quot;\n-                &amp;quot;a point along the edge.) The edge above node idx {} is {}.&amp;quot;\n-                .format(self.node1.idx, self.node1.dist)\n+                raise ToytreeError(\n+                    &amp;quot;\\n&amp;quot;\n+                    &amp;quot;To preserve existing edge lengths the &amp;apos;resolve_root_dist&amp;apos; arg\\n&amp;quot;\n+                    &amp;quot;must be smaller than the edge being split (it is selecting a \\n&amp;quot;\n+                    &amp;quot;a point along the edge.) The edge above node idx {} is {}.&amp;quot;.format(\n+                        self.node1.idx, self.node1.dist\n+                    )\n                 )\n\n-\n-\n     def insert_new_node(self):\n-        &amp;quot;&amp;quot;&amp;quot;\n-\n-        &amp;quot;&amp;quot;&amp;quot;\n+        &amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;&amp;quot;\n         # the new root node to be placed on the split\n         self.nnode = self.tree.treenode.__class__()\n         self.nnode.name = &amp;quot;root&amp;quot;\n         self.nnode.add_feature(&amp;quot;idx&amp;quot;, self.tree.treenode.idx)\n         self.nnode.support = self.maxsup\n@@ -239,36 +228,32 @@\n         self.node2.children.remove(self.node1)\n\n         # new node has no parent and 1,2 as children and default features\n         self.tdict[self.nnode] = [None, [self.node1, self.node2], {}]\n\n-        # node1 has new root parent, same children, and dist preserved \n+        # node1 has new root parent, same children, and dist preserved\n         # (or split?), or should: node1.dist / 2.\n         self.tdict[self.node1] = [\n-            self.nnode, \n-            self.node1.children, \n-            {&amp;quot;dist&amp;quot;: self.node1.dist}\n-        ]  \n+            self.nnode,\n+            self.node1.children,\n+            {&amp;quot;dist&amp;quot;: self.node1.dist},\n+        ]\n\n         # node2 has new root parent, same children + mods, and dist/supp mods\n         self.tdict[self.node2] = [\n             self.nnode,\n             self.node2.children,\n             {&amp;quot;dist&amp;quot;: 0.0},\n         ]\n\n-\n-\n     def get_features(self):\n-        # define which features to use/keep on nodes and which are &amp;quot;edge&amp;quot; \n+        # define which features to use/keep on nodes and which are &amp;quot;edge&amp;quot;\n         # features which must be redirected on rooting.\n         testnode = self.tree.treenode.get_leaves()[0]\n         extrafeat = {i for i in testnode.features if i not in self.features}\n         self.features.update(extrafeat)\n\n-\n-\n     def get_match(self, names, wildcard, regex):\n         &amp;quot;&amp;quot;&amp;quot;\n         tries to get monophyletic clade from selection, then tests\n         the reciprocal set, then reports error.\n         &amp;quot;&amp;quot;&amp;quot;\n@@ -276,20 +261,18 @@\n         self.nas = NodeAssist(self.tree, names, wildcard, regex)\n         # self.nas.match_query()\n         self.tipnames = self.nas.get_tipnames()\n\n         # check for reciprocal match\n-        x0 = (not self.nas.is_query_monophyletic())\n-        x1 = (self.nas.get_mrca().is_root())\n+        x0 = not self.nas.is_query_monophyletic()\n+        x1 = self.nas.get_mrca().is_root()\n         if x0 or x1:\n             clade1 = self.nas.tipnames\n             self.nas.match_reciprocal()\n\n             # check reciprocal match\n             if not self.nas.is_query_monophyletic():\n                 # clade2 = self.nas.tipnames\n\n                 # reports the smaller sized clade\n-                raise ToytreeError(\n-                    &amp;quot;Matched query is paraphyletic: {}&amp;quot;.format(clade1)\n-                )\n+                raise ToytreeError(&amp;quot;Matched query is paraphyletic: {}&amp;quot;.format(clade1))\n                 # .format(sorted([clade1, clade2], key=len)[0]))\n&lt;b&gt;would reformat toytree/toytree/Rooter.py&lt;/b&gt;\n&lt;b&gt;All done! \u2728 \ud83c\udf70 \u2728&lt;/b&gt;\n&lt;b&gt;1 file would be reformatted&lt;/b&gt;.\n</code></pre></p>"},{"location":"tutorials/10.1-style/#assessment","title":"Assessment","text":"<p>None. Continue to the next tutorials where we will continue to learn about style.</p>"},{"location":"tutorials/10.1-style/#cleanup","title":"Cleanup","text":"<p>Now that you've finished the exercise you can cleanup by removing the repos that we had cloned only for this example. Remember, to remove a git repo you will need to use the arguments <code>-rf</code>; this is because the .git/ subfolder  in the repo wants you to be sure you really want to remove it before you do  so. Here we are quite sure, so go ahead and run the commands below to remove both folders.</p> <pre><code># move into your hacks directory\ncd ~/hacks\n\n# rm the two repos\nrm -rf ./toytree\nrm -rf ./fastStructure\n</code></pre>"},{"location":"tutorials/11.0-miniproject-kickoff/","title":"mini-project kick-off activity","text":""},{"location":"tutorials/11.0-miniproject-kickoff/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this session you should: - Have a new github repository for your mini-project formatted as a python module. - </p>"},{"location":"tutorials/11.0-miniproject-kickoff/#defining-the-mini-project-package-structure","title":"Defining the mini-project package structure","text":""},{"location":"tutorials/11.0-miniproject-kickoff/#create-a-new-mini-project-repository","title":"Create a new mini-project repository","text":"<p>Go to your github account and create a new repository called <code>mini-project</code>. Clone the repository to your local computer in the <code>hacks</code> directory, and then continue populating your new repo with the following directory structure and files. <pre><code>mini-project/\n\u251c\u2500\u2500 mini-project/\n\u2502   \u251c\u2500\u2500 __init__.py\n|   |   __main__.py\n\u2502   \u2514\u2500\u2500 module.py\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 setup.py\n</code></pre></p>"},{"location":"tutorials/11.0-miniproject-kickoff/#populate-the-readmemd","title":"Populate the README.md","text":"<p>Fill in the basic information about your mini-project in the README.md file.</p> <ul> <li>Write the name of your program as a level-1 header</li> <li>Briefly describe your mini-project as best you can below the header as a text.<ul> <li>Include a brief desription of the input data and the expected output.</li> </ul> </li> <li>Write a level-3 header called \"Installation\"</li> <li>Write a paragraph below this describing how developers can install the  program locally to help work on the code. This should include instructions like the following:</li> </ul> <pre><code>conda install [list dependencies here...] -c conda-forge ...\n\ngit clone [myproject-link]\ncd ./myproject-name\npip install -e .\n</code></pre> <p>Test to make sure your code is installable, even if the Python  modules are mostly empty for now.</p>"},{"location":"tutorials/11.0-miniproject-kickoff/#populate-the-setuppy","title":"Populate the <code>setup.py</code>","text":"<p>Copy the format of your <code>setup.py</code> file from your <code>hack-9-python</code> repository (the darwinday example module). You will need to change some of the values to match your current project's information.</p>"},{"location":"tutorials/11.0-miniproject-kickoff/#populate-__init__py","title":"Populate <code>__init__.py</code>","text":"<p>Do the same for <code>__init__.py</code>, in this case at the moment you might only have the version info.</p>"},{"location":"tutorials/11.0-miniproject-kickoff/#populate-__main__py","title":"Populate <code>__main__.py</code>","text":"<p>Copy the text for <code>__main__.py</code> from the <code>hack-9-python</code> directory. You will probably have to  remove or modify some things initially, but the structure of this file will be very useful, i.e. the <code>parse_command_line()</code> and <code>main()</code> functions will be useful whatever your mini-project is.</p> <p>NB: <code>__main__.py</code> should be used for parsing command line and setting up and calling the  functions in your <code>module.py</code> file. There shouldn't be much 'heavy lifting' in this file, as the majority of your functional code should be in external modules organized as classes (if needed).</p>"},{"location":"tutorials/11.0-miniproject-kickoff/#a-couple-further-useful-directories","title":"A couple further useful directories","text":"<p>I also like to create directories at the top level of my package called <code>notebooks</code> and <code>example_data</code> for holding jupyter notebooks I use either for prototyping or testing, and as a place to store example data for using as a test-case with your tool (a very good practice).</p>"},{"location":"tutorials/11.0-miniproject-kickoff/#begin-working-on-your-mini-project","title":"Begin working on your mini-project","text":"<p>For the remainder of this session start working on your mini-project. This can take a couple of forms:</p> <ul> <li>Compiling a toy example dataset: It is useful to have an example dataset that is structured in the same way as the data you anticipate manipulating, so you might spend some time creating (or finding) an appropriate example dataset. This dataset should be small enough to run fast, but have enough variation to meaningfully demonstrate the functions of your code.</li> <li>Prototyping: I will often start a project with a new juptyer notebook called <code>project-name-dev.ipynb</code> in which I will prototype code to get it working before copy/pasting it into a class or function within my package. You can start prototyping to develop the functions of your code.</li> <li>Defining needed CLI arguments: It's also sometimes helpful to start with the <code>argparse</code> arguments you anticipate your program will need, and fill these in.</li> </ul>"},{"location":"tutorials/12.0-api-access/","title":"Notebook 12.0 RESTful GBIF","text":"<p>This notebook will introduce you to methods for access and parse data from online databases by accessing websites that have RESTful APIs. </p>"},{"location":"tutorials/12.0-api-access/#learning-objectives","title":"Learning objectives","text":"<ul> <li>Gain familiarity with the GBIF biological database</li> <li>Understand the structure of REST API requests</li> <li>Be able to use the <code>request</code> Python library to query REST APIs</li> </ul>"},{"location":"tutorials/12.0-api-access/#gbif-the-global-biodiversity-information-facility","title":"GBIF - The Global Biodiversity Information Facility","text":"<p>Check out how amazing GBIF is as a source for biological data. Wouldn't it be great if you could automate accessing the information here????</p>"},{"location":"tutorials/12.0-api-access/#required-software","title":"Required software","text":"<p>Install the following with conda before running this notebook</p> <pre><code># conda install pandas requests toyplot -c conda-forge\n</code></pre> <pre><code>import toyplot\nimport requests\nimport pandas as pd\n</code></pre>"},{"location":"tutorials/12.0-api-access/#the-design-of-rest-apis","title":"The design of REST APIs.","text":"<p>The idea behind REST APIs is that data on a server (like a webpage) can be accessed with a consistent type of argument in the form of a URL, to query data which will then be returned in a form that is easy to analyze (usually json or xml), as opposed to being returned in messy HTML that needs to be parsed. Many websites have REST APIs, but some are much easier to use than others. </p>"},{"location":"tutorials/12.0-api-access/#limits","title":"Limits","text":"<p>Many REST APIs have limits on the way that you can use them. For example, the REST APIs for Twitter, GitHub, and Reddit require that you login in order to access data, and some sites will throttle how many requests you can make per hour. In this notebook we will be focusing on accessing data from websites that are designed to be queried -- they purposefully created an API for this purpose. It's worth noting that there exists other methods to parse data from the raw HTML representation of websites, but that is not our focus here. By contrast, sites with API access typically have data stored in a server database that allows efficient access to even enormous datasets with billions of records (e.g., Twitter).</p>"},{"location":"tutorials/12.0-api-access/#good-rest-apis","title":"Good REST APIs","text":"<p>A good REST API will have good documentation explaining its intended usage. Two very good examples are the USDA Bison API and the Global Biodiversity Information Facility (GBIF) API. We'll focus on the latter in this notebook. The GBIF database is an international effort to collect all observation data on plants, animals, and fungi into a single place where it can be searched. It is actually a conglomeration of many separate databases, with data from museums and similar institutions all over the world. These APIs are free to use but request that you cite them if the data is used in a publication eventually. </p> <p>(Although GBIF is free to use it does limit the size of a request you can make at once, but there are ways around this as explained in its documentation.)</p>"},{"location":"tutorials/12.0-api-access/#what-does-gbif-do","title":"What does GBIF do?","text":"<p>GBIF can be used to find specimen collection records, or other types of observation data, stored in museum type databases. The website offers a convenient way to request taxa by name, and to select specific research criteria. For example, if we wanted to find all specimens of bumblebees (genus Bombus) that were collected between 1910 and 1920 we could request this through the website. It will draw a nice map with their locations and you can download a table with coordinates of where they were collected. This is actually one of the best databases around, since it organizes the data quite easily for you to download, but nevertheless, we'll use it as our example to learn REST APIs. </p>"},{"location":"tutorials/12.0-api-access/#rest-apis-and-websites","title":"REST APIs and websites","text":"<p>It's worth noting that the GBIF website itself is designed around the REST API. When you fill in the search form on the site to tell it to search a particular species from a particular area, its response is collected from the database in the same way that your response would be when you make the same request using a URL passed to the API. The website simply takes this response (likely in JSON format) and renders it nicely into a table or map for you to view on the website. This is how many websites work!</p> <p>Even though GBIF has a very nice web interface, it is obviously often more efficient to be able to query this database programmatically, instead of having to type each name we wish to search, and click on several buttons. This can provide a much more powerful way of applying filters over many different types of searches. That is the idea behind REST APIs and the reason why GBIF provides one. </p>"},{"location":"tutorials/12.0-api-access/#the-base-url","title":"The base-url","text":"<p>The base URL is the web address of the API. This is simply a string that we wil add arguments to in order to request particular types of data be returned to use from the database. For GBIF this is the following, which we'll store as a string for now. This base-url address is given to us right at the top of the GBIF API documentation. You can see that it looks much like any other web address. </p> <pre><code># store the base url as a string variable\nbaseurl = \"http://api.gbif.org/v1/occurrence/search?\"\n</code></pre>"},{"location":"tutorials/12.0-api-access/#how-to-query-gbif","title":"How to query GBIF","text":"<p>As you can see in the URL below, an API query just has additional arguments added to the baseurl. The string below searches for records with the name Bombus, which is the genus for bumblebees. We've added just the 'query' option 'q' and the name. How did I know that 'q' was valid parameter to this API? By reading the documentation.</p> <p>We'll see next how to make more complex queries. But first, copy the URL below (without the quotation marks around it) and paste it into a web browser. This will show you what the returned data looks like. It might look a bit different depending on which browser you are using (I recommend using firefox or chrome) but the underlying data is the same, and is called JSON data.</p> <pre><code># store a endpoint request as a string variable\nsearch_url = \"http://api.gbif.org/v1/occurrence/search?q=Bombus\"\n</code></pre>"},{"location":"tutorials/12.0-api-access/#json-format","title":"JSON format","text":"<p>We will be using the <code>requests</code> library to get data from online, but before we do, let's talk a bit about how the data will be structured so we know what to expect. The data that you should see in your browser now is called JSON formatted data.  You'll notice that this format is almost identical to what a Python dictionary looks like. It is composed of key:value pairs. This will make it particularly easy to work with. </p>"},{"location":"tutorials/12.0-api-access/#requests","title":"Requests","text":"<p>Documentation</p> <p>The <code>requests</code> package work a bit like an automated web browser. We've used <code>requests</code> briefly in the past but now we'll start to use it more effectively. The main function we will call is <code>.get()</code>, which will send a GET command (a form of HTTP method that the web is built on) to the web address and return a Response Class object. We will then access attributes and functions of the Response instance to see if our request worked, and to parse the resulting text from it. Let's try this on our <code>search_url</code> string defined above. </p> <pre><code># create a Response instance from a request\nresponse = requests.get(search_url)\n</code></pre> <pre><code># check that your request worked (200 = worked; other codes No))\nresponse.status_code \n</code></pre> <pre><code># or, run this to check if it worked.\n# This would return an error message if it didn't work (else None)\nresponse.raise_for_status()\n</code></pre>"},{"location":"tutorials/12.0-api-access/#parse-a-response","title":"Parse a Response","text":"<p>Before when we've used <code>requests</code> we've parsed the results as plain text, since it was usually in a format that was easiest to work with as a string (we used requests in an early notebook to download iris-data-dirty.csv). In this case, we are going to access the data a bit differently, by instead  accessing it in JSON format. This is easily available from the object just like text is. The first is not very easily readable or parseable, whereas the second can be accessed and searched more easily. </p> <pre><code># first 500 characters of the .text string from GBIF API query\nresponse.text[:500]\n</code></pre> <p>As you can see above, the result is a string. But we want it to be parsed as a dictionary. The <code>.json()</code> function of the response object will do this for us.</p> <pre><code># or, get results as a dictionary (JSON converted)\nrdict = response.json()\n\n# get some quick info on the dictionary keys\nlist(rdict.keys())\n</code></pre>"},{"location":"tutorials/12.0-api-access/#parsing-the-results","title":"Parsing the results","text":"<p>In GBIF our response can be parsed into a dictionary object using the JSON format, and this has six keys shown above. These are explained in the API docs, and correspond to information about what records are available for our query. However, it did not return all of the data for those records to us yet. That would be too easy. Instead, databases usually have limits on the amount of data from each request as a way of limiting the bandwidth they will need for sending the data, and to make it faster. For GBIF the default number, shown under the \"limit\" key, is 20. And the default starting position, shown under \"offset\" is 0. The total number of records is in \"count\". So for Bombus, as we show below, there are &gt;2M records, but only records 1-20 were returned to us so far.</p> <pre><code>## how many records are there for this query\nrdict[\"count\"]\n</code></pre> <pre><code>## how many records were returned\nrdict[\"limit\"]\n</code></pre> <pre><code>## starting from which record\nrdict[\"offset\"]\n</code></pre>"},{"location":"tutorials/12.0-api-access/#so-wheres-the-data","title":"So where's the data?","text":"<p>It's stored under the <code>results</code> key, and is returned as a list of dictionaries, where each dictionary is a record with lots of information. Below I show the first record from our search. </p> <pre><code># here is the first record, it's also a dictionary\nrdict[\"results\"][0]\n</code></pre> <p>There are too many columns for you see them all here. We will call .columns to see all the column names printed as a list.</p> <pre><code># load as a dataframe\nsdf = pd.json_normalize(rdict['results'])\nsdf.head()\n</code></pre> <pre><code>sdf.columns\n</code></pre>"},{"location":"tutorials/12.0-api-access/#building-a-request","title":"Building a request","text":"<p>Here we add more arguments to further filter the results. To see which options are available, you can either look at the results from our existing calls so far, or you can read further into the API docs. Sometimes API docs will be incomplete though, so it can be useful to learn to try to infer which options are possible from looking at the results. A more complex search is accomplished by building a URL that has more key:value pairs each appended to the end of the URL, and separated by a \"&amp;\" symbol. For large searches it begins to get difficult to write out by hand, and that is where <code>requests</code> comes in handy. Here we enter the additional arguments we want using a simple python dictionary into the entry 'params'.</p> <pre><code># previously we wrote this request by hand\nurlpath = \"http://api.gbif.org/v1/occurrence/search?q=Bombus\"\n</code></pre> <pre><code># here we create the same urlpath using params\nresponse = requests.get(\n    url=\"https://api.gbif.org/v1/occurrence/search/\",\n    params={\"q\": \"Bombus\"}\n)\n\n# show url path\nprint(response.url)\n</code></pre>"},{"location":"tutorials/12.0-api-access/#narrowing-requestresponses","title":"Narrowing request/responses","text":"<p>If you looked closely at the results above you may have noticed that the records returned are not actually all for organisms in the genus Bombus. Instead results include things like Chaetocercus bombus and other organisms that happen to have \"bombus\" in their names.</p> <p>This is why its important to look closely at your data. Looking back at the documentation we can see that the 'q=something' search parameter returns a fuzzy hit to anything that has the query in its data. If we instead want to restrict to the genus Bombus we need to find the <code>genusKey</code> for Bombus. This can be found using the 'species' endpoint in the API. So let's take a side track to find this. Note we are searching a different baseurl now, to look in the 'species' path instead of the 'occurrence' path. </p> <p>The results below provide unique identifiers that are more reliable for searching the database. We will use the genusKey=1340278 for our next search of the occurrence database.</p> <pre><code># get taxonomy info for the genus Bombus\nres = requests.get(\n    url=\"https://api.gbif.org/v1/species/match/\",\n    params={\"genus\": \"Bombus\"},\n)\nres.json()\n</code></pre> <p>Here is a different search for the genus Pedicularis. This is a group of plants that I study. You can see that it returns a different set of taxonomic keys. Feel free to try searching a taxon of your choice.</p> <pre><code># get taxonomy info for the genus Pedicularis\nres = requests.get(\n    url=\"https://api.gbif.org/v1/species/match/\",\n    params={\"genus\": \"Pedicularis\"},\n)\nres.json()\n</code></pre>"},{"location":"tutorials/12.0-api-access/#building-more-complex-queries","title":"Building more complex queries","text":"<p>Below I show the URL for when we add the requirement that a record have coordinate data, and for when we add additional arguments to raise the limit for the number of records returned. The max records at a time (limit - offset) is 300. Above that you need to increment the offset to search higher values. You can see that the URL is simply appending additional queries to the end after the ? symbol to build more complex queries.</p> <pre><code># add requirement that the record have coordinate data\nres = requests.get(\n    url=\"https://api.gbif.org/v1/occurrence/search/\",\n    params={\n        \"genusKey\": 1340278, \n        \"hasCoordinate\": \"true\",\n    }\n)\nres.url\n</code></pre> <pre><code># request records 0-100\nres = requests.get(\n    url=\"https://api.gbif.org/v1/occurrence/search/\",\n    params={\n        \"genusKey\": 1340278, \n        \"hasCoordinate\": \"true\",\n        \"offset\": 100,\n        \"limit\": 20,\n    }\n)\nres.url\n</code></pre>"},{"location":"tutorials/12.0-api-access/#a-complex-search","title":"A complex search","text":"<p>Here I request all Bombus records from 1900-1910 that are associated with a preserved specimen (as opposed to HUMAN_OBSERVATION or FOSSIL_SPECIMEN), has spatial data, and is in the US. The 'count' shows us that there are &gt;6000 records meeting these requirements. This individual search returned only 20 of these results though, and at most can do 300 at a time. So we will need to use a trick to get all the records.</p> <pre><code>res = requests.get(\n    url=\"https://api.gbif.org/v1/occurrence/search/\",\n    params={\n        \"genusKey\": 1340278, \n        \"year\": \"1900,1910\", \n        \"basisOfRecord\": \"PRESERVED_SPECIMEN\",\n        \"hasCoordinate\": \"true\",\n        \"hasGeospatialIssue\": \"false\",\n        \"country\": \"US\",\n    },\n)\n\nprint(res.json()[\"count\"])\n</code></pre>"},{"location":"tutorials/12.0-api-access/#combining-many-searches","title":"Combining many searches","text":"<p>If we wanted to collect all records for a given search then we need to increment the \"offset\" argument until we reach the end of the records. Each is returned as a list of dictionaries, so we can just join all of those lists together and return them. That sounds a bit complex, so let's to it in two parts, first we'll write a function to fulfill a single request, and then a function to call many requests.</p> <pre><code>def get_single_batch(genusKey, year, offset=0, limit=20):\n    \"\"\"\n    Returns a GBIF REST query with records between offset\n    and offset + limit in JSON format. The genusKey and \n    year interval can be changed.\n    \"\"\"\n    res = requests.get(\n        url=\"https://api.gbif.org/v1/occurrence/search/\",\n        params={\n            \"genusKey\": genusKey,\n            \"year\": year,\n            \"offset\": offset,\n            \"limit\": limit,\n            \"hasCoordinate\": \"true\",\n            \"country\": \"US\",\n        }\n    )\n    return res.json()\n</code></pre> <pre><code># test single batch function\njdata = get_single_batch(\n    genusKey=3171670,\n    year=\"1990,2020\",\n    offset=0, \n    limit=20\n)\n\n# how many results were fetched?\nprint(len(jdata[\"results\"]))\n</code></pre> <pre><code># did we reach the end of the records?\njdata[\"endOfRecords\"]\n</code></pre> <pre><code>def get_all_records(genusKey, year):\n    \"\"\"\n    Iterate requests over incremental offset positions until\n    all records have been fetched. When the last record has\n    been fetched the key 'endOfRecords' will be 'true'. Takes\n    the API params as a dictionary. Returns result as a list\n    of dictionaries.\n    \"\"\"\n    # for storing results\n    alldata = []\n\n    # continue until we call 'break'\n    offset = 0\n    while 1:\n\n        # get JSON data for a batch \n        jdata = get_single_batch(genusKey, year, offset, 300)\n\n        # increment counter by 300 (the max limit)\n        offset += 300\n\n        # add this batch of data to the growing list\n        alldata.extend(jdata[\"results\"])\n\n        # stop when end of record is reached\n        if jdata[\"endOfRecords\"]:\n            print(f'Done. Found {len(alldata)} records')\n            break\n\n        # print a dot on each rep to show progress\n        print('.', end='')\n\n    return alldata\n</code></pre> <pre><code># call function to search over all offset values until end. \n# THIS MAY TAKE A FEW MINUTES TO RUN\njdata = get_all_records(1340278, \"1900,1902\")\n</code></pre>"},{"location":"tutorials/12.0-api-access/#the-full-data","title":"The full data","text":"<pre><code># convert to a data frame\ndf = pd.json_normalize(jdata)\n</code></pre> <pre><code># keys (columns) in the dataframe (there are many!)\nlist(df.columns)\n</code></pre> <pre><code># view just the columns we're interested in for now.\nsdf = df[[\"species\", \"year\", \"decimalLatitude\", \"decimalLongitude\"]]\nsdf.head()\n</code></pre> <pre><code># how many records?\nsdf.shape\n</code></pre> <pre><code># which unique species?\nprint(sdf.species.unique())\n</code></pre> <pre><code># plot the number of each species in order (hover over bars for names)\nsp_counts = df.species.value_counts()\ntoyplot.bars(sp_counts, height=350, title=sp_counts.index);\n</code></pre> <p>Hover over the bars in the plot above to see the names of species. From this we can easily see which species have the most records, and which are more rare.</p>"},{"location":"tutorials/12.0-api-access/#assignment","title":"Assignment:","text":""},{"location":"tutorials/12.0-api-access/#task-1","title":"Task 1:","text":"<p>Write a Class object called <code>Records</code> that can be given a taxon query and a range of years and will return a class instance with all results from GBIF for the queried range using the same params from our example above, but allowing the 'genusKey' and 'year' arguments to be changed. You can reuse the code above to create the core functions for your object, and modify it further if you wish. Look at the example below for the intended usage of your <code>Records</code> class object. It should do the following:</p> <ol> <li>Store the genusKey and year params during init().</li> <li>Write the function <code>get_single_batch</code> to take optional arguments that limit the number of results, and have it return a JSON result as a dictionary.</li> <li>Write the fuction <code>get_all_records</code> to store the JSON results to the instance object, storing JSON as a dictionary to <code>self.json</code> and as a dataframe to <code>self.df</code>. </li> </ol> <pre><code># skeleton of a class\n\nclass Records:\n    def __init__(self, genusKey=None, year=None):\n\n        # store input params\n        self.genusKey = genusKey\n        self.year = year\n\n        # will be used to store output results\n        self.df = None\n        self.json = None\n\n    def get_single_batch(self, offset=0, limit=20):\n        \"returns JSON result for a small batch query\"\n        # ...\n\n    def get_all_records(self):\n        \"stores result for all records to self.json and self.df\"\n        # ...\n</code></pre> <p>When finished, you should be able to use your class object in the following way. This means that after writing your Class object, test it using the code below and make sure it gives proper results, otherwise keep hacking away at it. </p> <p>You need to write the Records class before executing the code below</p> <pre><code># create instance by entering query and a range of years as integers\nrec = Records(genusKey=1340278, year=\"1980,1985\")\n\n# show a small result\nprint(rec.get_single_batch(offset=0, limit=10))\n\n# get all records\nrec.get_all_records()\n\n# access all of the returned records as a dataframe \n# (here asking for the shape to see how many records there are)\nrec.df.shape\n</code></pre>"},{"location":"tutorials/12.0-api-access/#task-2","title":"Task 2:","text":"<p>Once you have tested your Record class object in this notebook and it is working, follow these instructions to create a Python package with the following file structure:</p> <pre><code>records/\n\u251c\u2500\u2500 setup.py\n\u2514\u2500\u2500 records/\n    \u251c\u2500\u2500 __init__.py\n    \u2514\u2500\u2500 records.py\n</code></pre> <ol> <li>Create a new GitHub repo called 'records'.</li> <li>Clone it to your computer.</li> <li>Create a subfolder called records (<code>records/records/</code>)</li> <li>Create an init file (<code>records/records/__init__.py</code>)</li> <li>Create a module called records.py (<code>records/records/records.py</code>)</li> <li>Open the folder in your text editor (vscode or sublime)</li> <li>Copy your Records class object from here to records.py.</li> <li>Create a setup.py script to make your package installable (<code>records/setup.py</code>). </li> <li>Run <code>pip install -e .</code> from <code>records/</code> to install your package locally. </li> <li>Test that your package is installed and working by importing your new package (called records) in the cell below and running the code. Try to make the Records class object importable in this way. (You may need to restart your notebook). Seek help if you get stuck.</li> </ol> <pre><code># import your library\nimport records\n\n# get an instance given some query parameters\nrec = records.Records(genusKey=1340278, year=\"1990,2000\")\n\n# access the dataframe results\nprint(rec.get_single_batch())\n</code></pre>"},{"location":"tutorials/12.0-api-access/#optional-advanced-challenge","title":"[Optional] Advanced challenge","text":"<p>If you accomplished this task easily then try to add an additional function to your package to allow entering the genus as a string, such that your code will search the taxonomic database to automatically find the integer genusKey to use in the occurrence database query, instead of requiring you to enter it as a numeric genusKey.</p>"},{"location":"tutorials/12.0-api-access/#assessment","title":"Assessment","text":"<p>You will be graded on the <code>records</code> class package in your GitHub repo. This notebook is only for instructions and learning and does not need to be submitted.</p>"},{"location":"tutorials/12.1-vcf-files/","title":"Notebook 12.1 Reading VCF files","text":"<p>This notebook will introduce you to the VCF file format, and methods for reading and manipulating variant call data (SNPs).</p>"},{"location":"tutorials/12.1-vcf-files/#learning-objectives","title":"Learning objectives","text":"<ul> <li>Understand the VCF file format</li> <li>Reading VCF files as pd data frames</li> <li>Basic manipulations of the vcf data</li> </ul>"},{"location":"tutorials/12.1-vcf-files/#variant-call-format-vcf-files","title":"Variant Call Format (VCF) files","text":"<p>VCF is a very common file format for storing and retrieving DNA sequence data, specifically it is most often used for storing single-nucleotide polymorphism (SNP) data, i.e. only sites that are variable within a population or sample.</p>"},{"location":"tutorials/12.1-vcf-files/#required-software","title":"Required software","text":"<p>Install the following with conda before running this notebook (if you haven't already done so).</p> <pre><code># conda install pandas requests toyplot -c conda-forge\n</code></pre> <pre><code>import toyplot\nimport requests\nimport pandas as pd\n</code></pre>"},{"location":"tutorials/12.1-vcf-files/#fetch-an-example-vcf-file","title":"Fetch an example vcf file","text":"<p>This is an in-class challenge activity, where I will give you prompts and motivations and then you'll have to figure out how to do what you need to do on your own (or with a partner).</p> <p>First, use the <code>requests</code> module to download the vcf file using this URL. Save the returned data to a file called <code>wcs.vcf</code> (this data is from a White-crowned sparrow study). <pre><code>vcf_url = \"https://raw.githubusercontent.com/isaacovercast/easySFS/refs/heads/master/example_files/wcs_1200.vcf\"\n</code></pre></p>"},{"location":"tutorials/12.1-vcf-files/#converting-to-a-pd-data-frame","title":"Converting to a pd data frame","text":"<p>Try loading the <code>wcs.vcf</code> file into a pandas dataframe using <code>pd.read_csv</code>. What happens?</p> <p>Pandas expects a file to be formatted as tabular data, which a VCF actually is if you can somehow remove all the extra header information. <code>read_csv()</code> can take an optional argument called <code>header</code> where you can pass in the row number of the line that contains information about each column. See if you can figure out a way to identify the header row in this vcf file, and then load it into a df using the <code>header</code> parameter.</p>"},{"location":"tutorials/12.1-vcf-files/#challenge-question-calculate-missing-data","title":"Challenge question: Calculate % missing data","text":"<p>Missing data is often something useful to quantify in a vcf file. In most cases missing data is specified as './.', indicating no genotype calls for a sample at this SNP. Please calculate the % of missing sites in this dataset. Ask for hints about how to proceed if necessary.</p>"},{"location":"tutorials/13.0-DebuggingChallenges/","title":"Notebook 13.0 Debugging Challenges","text":"<p>This notebook will give some practice in debugging python code, and reading, understanding, and responding to python error messages in small functions.</p>"},{"location":"tutorials/13.0-DebuggingChallenges/#learning-objectives","title":"Learning objectives","text":"<ul> <li>Understanding python error messages</li> <li>Debugging python scripts</li> </ul>"},{"location":"tutorials/13.0-DebuggingChallenges/#methodology","title":"Methodology","text":"<p>This tutorial involves identifying and fixing small errors or bugs in python code. For this set of challenges you will open a new jupyter notebook, copy the code from each of the challenges, and attempt to fix each of them according to the directions. You may use whatever to do this that are at your disposal.</p> <p>Hint: Remember that using print statements inside functions is a good way to easily trace execution.</p>"},{"location":"tutorials/13.0-DebuggingChallenges/#challenge-find-all-elements-smaller-than-a-given-number","title":"Challenge: Find all elements smaller than a given number","text":"<p>This function is supposed to return a list of all values less than a given integer value. The function optionally takes a <code>max_value</code>, and it requires to pass in a list of numbers. Your goal is to get this function to work correctly. This code block has two errors, which you can solve consecutively. <pre><code>def get_smaller(my_list, max_value='5'):\n    \"\"\"Return a list of all values smaller than max_value\"\"\"\n    for element in my_list:\n        low = []\n        if element &lt; max_value:\n            low.append(element)\n    return low\n\nmy_list = [5, 2, 12, 7, 3, 8]\nget_smaller(my_list=my_list)\n</code></pre></p>"},{"location":"tutorials/13.0-DebuggingChallenges/#challenge-implement-fizzbuzz","title":"Challenge: Implement FizzBuzz","text":"<p>FizzBuzz is a classical programming challenge in which you are given the task to take consecutive integer values and print \"Fizz\" for each integer divisible by 3, \"Buzz\" for integers divisible by 5, and \"FizzBuzz\" for integers divisible by both 3 and 5, and remain silent for all other integers. In this case we have given you most of the code but there is an error, please fix it and verify that it works. This code block has two errors, which you can solve consecutively. <pre><code>def fizzbuzz(max_num):\n    \"This method implements FizzBuzz\"\n    three_mul = 'fizz'\n    five_mul = 'buzz'\n    num1 = 3\n    num2 = 5 \n\n    # Google for 'range in python' to see what it does\n    for i in range(1,max_num):\n        # % or modulo division gives you the remainder \n        if i%num1==0 and i%num2==0:\n            print(i,three_mul+five_mul)\n        elif i%num1=0:\n            print(i,three_mul)\n        elif i%num2==0:\n            print(i,five_mul)\nfizzbuzz()\n</code></pre></p>"},{"location":"tutorials/13.0-DebuggingChallenges/#challenge-sum-of-positive-integers","title":"Challenge: Sum of positive integers","text":"<p>This function takes one argument, <code>numbers</code>, which should be a list of numbers. The function should sum all positive numbers in this list. Why doesn't it work? <pre><code>def sum_positive(numbers):\n    total = 0\n    for num in numbers:\n        if num &gt; 0:\n            total + num\n    return total\n\nsum_positive([1,2,3,4,5,6,7])\n</code></pre></p>"},{"location":"tutorials/14.0-DebuggingChallenges2/","title":"Notebook 14.0 Debugging Challenges","text":"<p>This notebook will give some practice in debugging python code, and reading, understanding, and responding to python error messages in small functions.</p>"},{"location":"tutorials/14.0-DebuggingChallenges2/#learning-objectives","title":"Learning objectives","text":"<ul> <li>Understanding python error messages</li> <li>Debugging python scripts</li> </ul>"},{"location":"tutorials/14.0-DebuggingChallenges2/#methodology","title":"Methodology","text":"<p>This tutorial involves identifying and fixing small errors or bugs in python code. For this set of challenges you will open a new jupyter notebook, copy the code from each of the challenges, and attempt to fix each of them according to the directions. You may use whatever to do this that are at your disposal.</p> <p>Hint: Remember that using <code>print()</code> statements inside functions is a good way to easily trace execution.</p>"},{"location":"tutorials/14.0-DebuggingChallenges2/#challenge-add-two-positive-numbers","title":"Challenge: Add two positive numbers","text":"<p>This function is supposed to accept two required arguments, add them together and return the sum. There are two at least two conditions that this function should handle which it currently doesn't: 1) If one of the passed in values is not strictly positive; and 2) If one of the values is not a number. Your goal is to get this function to work correctly. There are several ways to do this so we will discuss alternative strategies.</p> <pre><code>def add(a, b):\n    if a &gt; 0 and b &gt; 0:\n        return a + b\n\nresult = add(-1, 5)\nprint(result + 2)\n</code></pre> Hints  - Return values for functions that don't explicitly call `return` are set to `None`. - You can use the function `type()` to get the type of a variable, and then test this in a conditional - In the condition where a bad value is passed in (e.g. a string or char instead of an int) the decision  of whether to return a 'safe' and sensible result or to raise an exception is up to you."},{"location":"tutorials/14.0-DebuggingChallenges2/#challenge-implement-a-person-class","title":"Challenge: Implement a 'Person' class","text":"<p>Here is a simple class that represents information about a \"Person\". This code block implements the Person class, instantiates a new person and tries to print it to the screen. Your goal is to fix this class to generate the expected output.</p> <p><pre><code>class Person:\n    def __init__(self, name):\n        '''Initialize the Person object'''\n        self.name = name\n\n    def __repr__(self):\n        '''Describe the string representation of a Person'''\n        return f\"{self.name} is {self.age} years old\"\n\np = Person(\"Phylo\")\nprint(p)\n</code></pre> The expected output is: <pre><code>Phylo is 10 years old\n</code></pre></p>"},{"location":"tutorials/14.0-DebuggingChallenges2/#challenge-implement-a-simple-dog-class","title":"Challenge: Implement a simple Dog class","text":"<p>This class describes a <code>Dog</code> with the ability to <code>bark()</code>. The expected output is <code>Woof!</code>. Your goal is to fix this class.</p> <pre><code>class Dog:\n    def __init__(self, name):\n        self.name = name\n    def bark():\n        print(\"Woof!\")\n\nd = Dog(\"Phylo\")\nd.bark()\n</code></pre>"},{"location":"tutorials/14.1-intro-plotting/","title":"Data Visualization - Plotting with Matplotlib","text":""},{"location":"tutorials/14.1-intro-plotting/#prerequisites","title":"Prerequisites","text":"<p>Let's make sure we have necessary modules installed, including <code>matplotlib</code> and <code>scikit-learn</code>, which we will briefly introduce, but will get into more detail on next week.</p> <pre><code>conda install -c conda-forge matplotlib scikit-learn\n</code></pre> <p>Open a new notebook in your <code>hack-5-python/notebooks</code> directory and rename this notebook to \"14.1-plotting.ipynb\". In a new cell, include a few imports that we will need:</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.datasets import load_iris\nfrom sklearn.linear_model import LinearRegression\n</code></pre>"},{"location":"tutorials/14.1-intro-plotting/#fetch-the-iris-data","title":"Fetch the Iris data","text":"<p>We have been loading and cleaning the iris data by hand up to this point, but now we are going to make use of a nice feature in scikit-learn, which provides the iris data as a pre-loaded dataset. This chunk of code is 'data curation': we load in the iris data, transform it into a pandas DataFrame (it is not structured natively as a dataframe because it a bunch of other features internally), and then create a new column called <code>species</code> to hold the species IDs.</p> <pre><code>iris = load_iris()\niris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\niris_df['species'] = pd.Categorical.from_codes(iris.target, iris.target_names)\niris_df\n</code></pre>"},{"location":"tutorials/14.1-intro-plotting/#exploring-the-data-1-d-at-a-time-with-histograms","title":"Exploring the data 1-D at a time with histograms","text":"<p>Let's say we want to visualize the differences between the different measurements for each of the species. A simple way to do this is with histograms. Here we will use the <code>pd.groupby</code> method to group the data by species ID.</p> <pre><code># Define a variable for the feature we wish to plot\nfeature = \"sepal length (cm)\"\n# Group the data in the dataframe by species ID\ngb = iris_df.groupby(\"species\")\n# Iterate through the groupby object\nfor sp, dat in gb:\n    # For each species, plot the data for the given feature as a histogram\n    plt.hist(dat[feature], label=sp)\n</code></pre>"},{"location":"tutorials/14.1-intro-plotting/#set-the-alpha-channel","title":"Set the alpha channel","text":"<p>The initial result looks good, but <code>hist</code> defaults to plotting all histograms with zero opacity, so it's not clear what is happening in regions where the histograms overlap. Matplotlib plotting functions can take an opacity parameter called <code>alpha</code> which takes values between 0 and 1. Try setting the <code>alpha</code> to a small value and replotting.</p> <pre><code>feature = \"sepal length (cm)\"\ngb = iris_df.groupby(\"species\")\nfor sp, dat in gb:\n    plt.hist(dat[feature], label=sp, alpha=0.01)\nplt.legend()\n</code></pre> <p>This produces a ghostly outline of the histogram. Try experimenting with different alpha values until you find something you are happy with.</p>"},{"location":"tutorials/14.1-intro-plotting/#change-the-colors","title":"Change the colors","text":"<p>By default, matplotlib will choose different colors for each histogram, and this is fine, but you might want to control the colors for each histogram to unify color schemes across your plots, and also to beautify them. You can specify colors in several different ways, but the most  straightforward way is to pick from the large list of matplotlib named colors. Here are some examples:</p> <pre><code>feature = \"sepal length (cm)\"\ngb = iris_df.groupby(\"species\")\n# Create a dictionary mapping species IDs to color names, which we will access inside the for loop\ncdict = {'setosa':'cornflowerblue',\n         'versicolor':'salmon',\n         'virginica':'goldenrod'}\nfor sp, dat in gb:\n    plt.hist(dat[feature], label=sp, alpha=0.5, color=cdict[sp])\n</code></pre> <p>Experiment with different color schemes until you find one you are happy with.</p>"},{"location":"tutorials/14.1-intro-plotting/#add-a-legend","title":"Add a legend","text":"<p>If you add labels to the <code>hist</code> call (as we have done), then matplotlib can easily generate a legend for your figure with the <code>plt.legend()</code> method. <pre><code>feature = \"sepal length (cm)\"\ngb = iris_df.groupby(\"species\")\ncdict = {'setosa':'cornflowerblue',\n         'versicolor':'salmon',\n         'virginica':'goldenrod'}\nfor sp, dat in gb:\n    plt.hist(dat[feature], label=sp, alpha=0.5, color=cdict[sp])\nplt.legend()\n</code></pre></p> <p>By default matplotlib <code>legend()</code> will place itself in the most unoccupied region of the figure, and generally it does this pretty well, but you can control the placement of the legend within the figure using the <code>loc</code> argument, which you can learn more about in the <code>legend</code> documentation.</p>"},{"location":"tutorials/14.1-intro-plotting/#add-axis-labels-and-title","title":"Add axis labels and title","text":"<p>Finally, we will wrap up this figure by providing axis labels and a plot title, which we can do with the <code>plt.title()</code>, and <code>plt.xlabel()</code>/<code>plt.ylabel()</code> methods. <pre><code>feature = \"sepal length (cm)\"\ngb = iris_df.groupby(\"species\")\ncdict = {'setosa':'cornflowerblue',\n         'versicolor':'salmon',\n         'virginica':'goldenrod'}\nfor sp, dat in gb:\n    plt.hist(dat[feature], label=sp, alpha=0.5, color=cdict[sp])\n\nplt.title(f'Histogram of {feature} by Species')\nplt.ylabel('Count')\nplt.xlabel(feature)\n</code></pre></p> <p>If you wish to modify the style of the title and axis labels you can change many of these properties (for example the <code>fontsize</code>), all of which are documented in the <code>text</code> documentation</p>"},{"location":"tutorials/14.1-intro-plotting/#saving-figures-to-a-file","title":"Saving figures to a file","text":"<p>Once you are happy with your figure, you can either right-click on the image in the notebook and \"copy output to clipboard\", but this will copy a low-res version of the image, which is fine for presentations but not great for publications. For this reason matplotlib provides a <code>savefig()</code> method for saving the resulting figure in several different possible output formats, also allowing to control the output resolution (using the <code>dpi</code> argument, for example). Here is an example of saving as a standard resolution PNG file.</p> <p><pre><code>feature = \"sepal length (cm)\"\ngb = iris_df.groupby(\"species\")\ncdict = {'setosa':'cornflowerblue',\n         'versicolor':'salmon',\n         'virginica':'goldenrod'}\nfor sp, dat in gb:\n    plt.hist(dat[feature], label=sp, alpha=0.5, color=cdict[sp])\n\nplt.title(f'Histogram of {feature} by Species')\nplt.ylabel('Count')\nplt.xlabel(feature)\nplt.savefig('sepal_length.png')\n</code></pre> After you call this code you should see a new file called \"sepal_length.png\" in your jupyter lab browser, and you can even double-click it to open it in jupter lab to verify that it looks good.</p> <p>You can see what other file formats are available by calling the  <code>get_supported_filetypes()</code> function, like this: <pre><code>plt.gcf().canvas.get_supported_filetypes()\n</code></pre> <pre><code>{'eps': 'Encapsulated Postscript',\n 'jpg': 'Joint Photographic Experts Group',\n 'jpeg': 'Joint Photographic Experts Group',\n 'pdf': 'Portable Document Format',\n 'pgf': 'PGF code for LaTeX',\n 'png': 'Portable Network Graphics',\n 'ps': 'Postscript',\n 'raw': 'Raw RGBA bitmap',\n 'rgba': 'Raw RGBA bitmap',\n 'svg': 'Scalable Vector Graphics',\n 'svgz': 'Scalable Vector Graphics',\n 'tif': 'Tagged Image File Format',\n 'tiff': 'Tagged Image File Format',\n 'webp': 'WebP Image Format'}\n</code></pre></p>"},{"location":"tutorials/14.1-intro-plotting/#post-a-copy-of-your-finished-histogram","title":"Post a copy of your finished histogram","text":"<p>I have created a google slides presentation for sharing our data visualizations. Open this link (you will need to use your CU account), and paste your favorite visualization into a new slide.</p>"},{"location":"tutorials/14.1-intro-plotting/#challenge-visualize-another-column-of-data","title":"Challenge: Visualize another column of data","text":"<p>Now that you have the code settled for one column of the data, and you abstracted out the feature to plot as a variable named <code>feature</code>, it should be simple to plot another feature by dropping in another variable name. Go ahead and try it.</p>"},{"location":"tutorials/14.1-intro-plotting/#visualizing-2-d-data-with-scatterplots","title":"Visualizing 2-D data with scatterplots","text":"<p>Often we will have more than one dimension of data and we might have hypotheses about how the different dimension of data co-vary in our dataset. Let's remind ourselves of what types of data we have available in the iris data.</p> <p><pre><code>print(iris_df.columns)\n</code></pre> <pre><code>Index(['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)',\n       'petal width (cm)', 'species'],\n      dtype='object')\n</code></pre></p> <p>Let's choose sepal length and width, as these seem like they might be reasonably correlated. The machinery of plotting 2D data is pretty similar to plotting the 1D data with the exception that we need to provide x and y values for each datapoint. Whereas above with <code>hist</code> we only passed in one column of data, now we need to pass in two columns, otherwise the details of manipulating the 'look' of the figure are quite similar.</p> <pre><code>gb = iris_df.groupby(\"species\")\nx_feature = \"sepal length (cm)\"\ny_feature = \"sepal width (cm)\"\nfor sp, dat in gb:\n    plt.scatter(dat[x_feature], dat[y_feature], label=sp)\nplt.legend()\n</code></pre>"},{"location":"tutorials/14.1-intro-plotting/#styling-scatterplots","title":"Styling scatterplots","text":"<p>The details of figure styling for scatterplots are identical to those for histogram, so we can copy our approach for styling the figure above. <pre><code>x_feature = \"sepal length (cm)\"\ny_feature = \"sepal width (cm)\"\n\ngb = iris_df.groupby(\"species\")\ncdict = {'setosa':'cornflowerblue',\n         'versicolor':'salmon',\n         'virginica':'goldenrod'}\nfor sp, dat in gb:\n    plt.scatter(dat[x_feature], dat[y_feature], label=sp, alpha=0.75, color=cdict[sp])\n\nplt.title(f'Histogram of {feature} by Species')\nplt.ylabel('Count')\nplt.xlabel(feature)\nplt.legend()\nplt.savefig('sepal_length.png')\n</code></pre></p> <p>One difference with <code>scatter</code> is that you can define a \"marker style\", which controls the form of the scatter points. You can define the marker for a scatterplot using the  <code>marker</code> argument, for example <code>marker=\"*\"</code> would use stars instead of points. There are many options for marker style that you can see in the documentation</p>"},{"location":"tutorials/14.1-intro-plotting/#scatterplot-challenge","title":"Scatterplot challenge","text":"<p>In fact you can reasonably represent 3-Dimensions in a scatterplot by using the size of the marker to indicate a third dimension. This is something that was shown in the reading this week in section 04.02. If you have time, experiment with seeing if you can recreate this figure.</p>"},{"location":"tutorials/14.1-intro-plotting/#post-a-copy-of-your-finished-scatterplot","title":"Post a copy of your finished scatterplot","text":"<p>As before, post your finished scatterplot to our doc for sharing our data visualizations. Go ahead and post it on the same slide as your histogram, side by side.</p>"},{"location":"tutorials/14.1-intro-plotting/#further-challenges-if-time-remains","title":"Further challenges if time remains","text":"<p>Use the <code>requests</code> module to download a small mammal life history dataset that was published by Ernst in 2003 in the journal Ecology.</p> <p>Load this data into a pandas DataFrame. You will need to use a couple additional arguments when reading this file, which indicate tab separated values and replace missing data values with NaN.  Here is the call you'll need to load the data: <code>pd.read_csv(\"Mammal_lifehistories_v2.txt\", sep=\"\\t\", na_values=['-999', '-999.00'])</code></p> <ul> <li>Use a scatter plot to investigate adult mass vs. newborn mass. What do you notice about this plot?</li> <li>Try transforming the data using <code>np.log10()</code> and then replotting the same data</li> <li>Develop a hypothesis about the relationship between adult body mass and litter size. Should litter size be smaller or larger with increasing body mass? Plot the data to get a sense of whether you were right about this. When plotting, will you log-transform both, one, or neither of the axis? Justify your decision.</li> </ul>"},{"location":"tutorials/14.1-intro-plotting/#wrapping-up","title":"Wrapping up","text":"<p>Add, commit, and push your notebook to your github repo.</p>"},{"location":"tutorials/14.1-modules/","title":"importing","text":""},{"location":"tutorials/14.1-modules/#understanding-imports-and-modules","title":"Understanding imports and modules","text":"<p>Table of Contents: * Table of contents</p>"},{"location":"tutorials/14.1-modules/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this tutorial you should: - Understand that Python packages are just folders full of Python scripts. - Understand that <code>sys.path</code> lists the locations of importable packages. - Be able to import custom Python packages. - Be familiar with how to organize Python scripts into a package.</p>"},{"location":"tutorials/14.1-modules/#the-import-statement","title":"The <code>import</code> statement","text":"<p>The <code>import</code> statement is one of the first things located in  any Python script. It is used to load Python code from other  files located on your system. But what is it actually importing?  What do those files and folders look like?</p> <p>In your last tutorial you learned how to write a single  Python script that contains code that can be imported. This  is often referred to as a module. Here we will learn about writing  a collection of modules together in a folder, which is called a  package. Both modules and packages are very similar in the  way that <code>import</code> statements are used to access code from  Python files to make it accessible in other places.</p>"},{"location":"tutorials/14.1-modules/#organizing-a-package","title":"Organizing a package","text":"<p>Python packages are only useful when they are organized in a way  that makes it easy to understand how they should be used. Because  GitHub has become a standard place to store code, we will discuss  the organization of our code more broadly in terms of how it should be organized in a git repository. It is useful to follow a similar set of conventions whether the repo is intended as a Python software package, or if it is simply an archive of a research project.</p> <p>In either case, we will usually have the following:  - a README file in the top level directory describing the project. - a code directory (that can take different names) containing Python code. - a notebooks directory containing demonstrations/analyses of the code. - a data directory containing example data to be analyzed in the notebooks.</p> <p>Here we will focus on the structure of your code directory.  You have already cloned the repo <code>hack-7-python</code> which currently contains only a README file and notebooks directory. Let's create an additional folder to contain our scripts, called <code>mypackage</code>, and add an empty file  to this folder called <code>mymodule.py</code>. You can do this from your terminal by following the code block below.</p> <pre><code># make sure we are located in the repo dir\ncd ~/hacks/hack-7-python\n\n# make a new subdirectory \nmkdir -p mypackage/\n\n# make an empty file \ntouch ./mypackage/mymodule.py\n</code></pre>"},{"location":"tutorials/14.1-modules/#file-trees","title":"File trees","text":"<p>As an aside, let's install and use an interesting tool for visualizing the  filestructure of our repository. This will make it easier to keep track of  and understand how our files are organized, especially as we continue to  make more complex modules with many files. Use conda from your terminal to install the program <code>tree</code>:</p> <pre><code>conda install tree -c conda-forge\n</code></pre> <p>We can now use the <code>tree</code> command from within our repo to view the  file structure in a nicely formatted \"file tree\" design. In the  next sections our goal will be to put Python code into the mymodule.py file located in the mypackage folder, and to be able to import that code into a notebook located in the notebooks directory.</p> <pre><code>tree .\n</code></pre> <pre>.\n\u251c\u2500\u2500 mypackage\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 mymodule.py\n\u251c\u2500\u2500 notebooks\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 nb-7.0-subprocess.ipynb\n\u2514\u2500\u2500 README.md\n\n2 directories, 7 files\n</pre>"},{"location":"tutorials/14.1-modules/#tldr-a-video-demonstration","title":"TLDR; a video demonstration","text":"Watch the video below for a visual demonstration of what we plan to accomplish,  and then follow along with the rest of the tutorial for a slower paced  explanation. Click to make video larger.           Sorry, your browser doesn't support embedded videos."},{"location":"tutorials/14.1-modules/#write-a-python-module","title":"Write a Python module","text":"<p>Let's add a simple function to the mymodule.py file. In the video example  above I wrote a short py script. Here you can just copy the code below and paste it into the file using <code>nano</code> or another text editor.</p> <p><pre><code># open the myscript.py file in the nano text editor\nnano ./mypackage/mymodule.py\n</code></pre> Copy and paste the code below into the myscript.py file and save and close it.</p> <pre><code>#!/usr/bin/env python\n\"magic eight ball function to tell your future.\"\n\nimport random\n\ndef magic_eight_ball():\n    \"\"\"\n    Returns a random statement from a magic eight ball containing\n    a 10 sided die (I was too lazy to write all 20 typical answers)\n    https://en.wikipedia.org/wiki/Magic_8-Ball\n    \"\"\"\n    RESPONSES = {\n        0: \"It is certain.\",\n        1: \"It is decidedly so.\",\n        2: \"Without a doubt.\",\n        3: \"Yes \u2013 definitely.\",\n        4: \"You may rely on it.\",\n        5: \"Reply hazy, try again.\",\n        6: \"Better not tell you now.\",\n        7: \"Cannot predict now.\",\n        8: \"My reply is no\",\n        9: \"Outlook not so good\",\n        10: \"Very doubtful\",\n    }\n    return RESPONSES[random.choice(range(10))]\n</code></pre>"},{"location":"tutorials/14.1-modules/#importing-design","title":"Importing design","text":"<p>So far you have learned how to use the <code>import</code> statement to import code from Python packages and/or modules that are part of the standard library.  These are a collection of Python scripts organized into folders, similar to what you will be creating here. As an example, we learned about the <code>os.path</code> module in an earlier tutorial, which is used to format file path strings. This module is part of the <code>os</code> package. The functions located in the <code>path</code> module can be accessed in several ways from the <code>os</code> package:</p> <p><pre><code>import os\nos.path.join\n</code></pre> <pre><code>from os import path\npath.join\n</code></pre> <pre><code>from os import *\npath.join\n</code></pre> <pre><code>from os.path import join\njoin\n</code></pre></p> <p>Our goal here will be to design our package in the same way, so that you can import the function <code>magic_eight_ball()</code> from <code>mypackage.mymodule</code>  in all of these same ways. </p>"},{"location":"tutorials/14.1-modules/#packages-and-modules","title":"Packages and modules","text":"<p>A module is a script that can be imported. A package is a folder full of modules. The dot format in the example above, where the file or  function names are nested within another name, is meant to recapitulate the file structure in which these files or functions are written.</p> <p>So far we have a folder (package) and a file (module) and within it a function. Does this mean that we can now import this code from any other Python file? No. We need to do a few more steps to make it possible for Python to know that this package can be imported. For this, we need to learn about <code>sys.path</code>: the location where Python looks for modules. This is simply a list of filepaths  represented as strings. </p> <code>import</code> can only import packages or modules from folders  listed in <code>sys.path</code>. By default this will include only the location of standard library packages in <code>~/miniconda3/python3.8/</code>, of other installed packages (e.g., by conda or pip) in <code>~/miniconda3/python3.8/site-packages</code>, as well as your current directory  (<code>./</code>).      Here we will learn how to add additional paths to the  <code>sys.path</code> variable so that we an import any code. This is particularly useful (1) during code development; or (2) for importing a small number of scripts that do not compose a  full library.      Later we will learn to design packages that are installable, meaning that they will be copied into the  (<code>~/miniconda3/python3.8/site-packages</code>) dir where other packages are located.  <p>Open a new notebook from in the notebooks dir and rename it <code>import-test</code>  and follow along. From inside the notebook import the <code>sys</code> package from  the standard library and examine the <code>sys.path</code> variable. (see the video tutorial above to make sure you are following as intended.)</p> <pre><code># import sys from the standard lib\nimport sys\nprint(sys.path)\n</code></pre> <p>To add new locations for Python to find packages you can append a new string to the <code>sys.path</code> list. This new string should point to the parent directory of  your package (the directory containing the package directory). The path can be written as either a full path or relative path. Because we are currently located within a notebook in the <code>notebooks/</code> dir, the <code>mypackage</code> dir is located up one directory (in the parent directory of our current dir). See the <code>tree</code> output above to  confirm this. Therefore we can add our current parent dir to the <code>sys.path</code>  to make the <code>mypackage/</code> folder importable. (Using a relative path as opposed to a full path here is actually preferred, since if someone else cloned our repo and ran the code in this notebook, it would be able to find and import the code from the parent dir (<code>..</code>) without requiring them to change the path, which they otherwise would need to do if writing a fullpath.)</p> <pre><code>import sys\n\n# append your current parent dir to the sys.path list\nsys.path.append(\"../\")\n\n# show the updated sys.path \nprint(sys.path)\n</code></pre> <pre>['/home/deren/miniconda3/envs/dev/bin',\n '/home/deren/miniconda3/envs/dev/lib/python38.zip',\n '/home/deren/miniconda3/envs/dev/lib/python3.8',\n '/home/deren/miniconda3/envs/dev/lib/python3.8/lib-dynload',\n '/home/deren/miniconda3/envs/dev/lib/python3.8/site-packages',\n '/home/deren/miniconda3/envs/dev/lib/python3.8/site-packages/IPython/extensions',\n '/home/deren/.ipython',\n '..']\n</pre>"},{"location":"tutorials/14.1-modules/#why-does-this-make-mypackage-importable","title":"Why does this make <code>mypackage</code> importable?","text":"<p>Any folder that is located inside of one of the folders listed above can be imported. The <code>mypackage</code> folder is located in the filepath that we  appended to the end of the list (<code>../</code>). This will make the following <code>import</code> statements available to us that will allow us to access the  <code>magic_eight_ball()</code> function in the <code>mymodule</code> script. You can test this from your notebook, and you can also explore what is accessible to import from each object by using tab-completion.</p> <p><pre><code>import mypackage.mymodule\nmypackage.mymodule.magic_eight_ball()\n</code></pre> <pre><code>from mypackage import mymodule\nmymodule.magic_eight_ball()\n</code></pre> <pre><code>from mypackage.mymodule import magic_eight_ball\nmagic_eight_ball()\n</code></pre></p> <p>The only method that is not yet supported is to be able to import the  package name alone and access all objects nested within it. This is slightly  different from the first example above, and would look like this:</p> <p><pre><code># this workflow is not yet supported\nimport mypackage\nmypackage.mymodule.magic_eight_ball()\n</code></pre> This last method is particularly convenient, since it allows the user to  explore the entire package themselves to find any objects that might be  useful. So how do we support this last method?</p>"},{"location":"tutorials/14.1-modules/#the-__init__py-script","title":"The <code>__init__.py</code> script","text":"<p>To support this last mode for <code>import</code> we need to learn about a special file called <code>__init__.py</code>. You can tell it is special because it uses the dunder naming convention. An init file is a file that is  automatically run when a package is imported. It is placed inside of  a folder and used to <code>import</code> other files or folders that are nested within this folder. By using an <code>__init__.py</code> file to only select some of the subfolders or files in a folder you can limit or expand  the scope of what the user will see when using tab-completion to search  for possible importable modules. This is a useful design feature that  can be used to organize your code so that all of the most useful class and function objects are accessible from the top level package name, or from particular modules. Let's create an init file and edit its contents:</p> <pre><code># add an __init__.py file to the mypackage dir\ncd ~/hacks/hack-7-python/\ntouch mypackage/__init__.py\nnano mypackage/__init__.py\n</code></pre> <p>In the <code>__init__.py</code> file we will add a shebang and docstring, and then add an import statement. In this case the import is making it so that the package will automatically import the module. In other words, <code>mypackage.mymodule</code> will be automatically imported. Here we use the convention <code>from .</code> to tell it where to the mymodule module is located, where <code>.</code> means the current directory.</p> <pre><code>#!/usr/bin/env python\n\"\"\"\nThe mypackage package is used to learn about package filestructure.\n\"\"\"\nfrom . import mymodule\n</code></pre> <p>Now if we restart the notebook and update our <code>sys.path</code> variable as before, we should be able to access all contents of the mypackage  folder from the top level name. In addition, we can view a docstring  for the package which we defined in the init file.</p> <pre><code># add our local package scope to sys.path\nimport sys\nsys.path.append(\"..\")\n\n# access our module function from the package-level import\nimport mypackage\nmypackage.mymodule.magic_eight_ball()\n\n# show the package-level docstring\nmypackage?\n</code></pre>"},{"location":"tutorials/14.1-modules/#summary","title":"Summary","text":"<ul> <li>modules are Python scripts located inside folders.</li> <li>packages are folders containing one or more modules. </li> <li>Both of these things can be imported, allowing you to access folders, files, or code objects within them.</li> <li>An <code>__init__.py</code> file can be used to make objects nested within a package (modules or their contents) accessible from the higher-level imported  object (package).</li> <li>Packages or modules can be imported if they are in your <code>sys.path</code> variable.</li> <li>You can edit <code>sys.path</code> to add new paths to it to make your code importable.</li> <li>We will learn later how to make packages 'installable', such that they will  automatically be added to your <code>sys.path</code>.</li> </ul>"},{"location":"tutorials/14.1-modules/#assessment","title":"Assessment","text":"Ensure that your code is working and can successfully import and run the code in the block above. If it is working then save and close your notebook. Use git to add, commit, and push your mypackage/ dir and  your test notebook to your forked git repo for grading."},{"location":"tutorials/15.0-DebuggingChallenge3/","title":"Notebook 15.0 Debugging Challenges","text":"<p>This notebook will give some practice in debugging python code, and reading, understanding, and responding to python error messages in small functions.</p>"},{"location":"tutorials/15.0-DebuggingChallenge3/#learning-objectives","title":"Learning objectives","text":"<ul> <li>Understanding python error messages</li> <li>Debugging python scripts</li> </ul>"},{"location":"tutorials/15.0-DebuggingChallenge3/#methodology","title":"Methodology","text":"<p>This tutorial involves identifying and fixing small errors or bugs in python code. For this set of challenges you will open a new jupyter notebook, copy the code from each of the challenges, and attempt to fix each of them according to the directions. You may use whatever to do this that are at your disposal.</p> <p>Hint: Remember that using <code>print()</code> statements inside functions is a good way to easily trace execution.</p>"},{"location":"tutorials/15.0-DebuggingChallenge3/#challenge-load-a-dataset-from-a-csv","title":"Challenge: Load a dataset from a csv","text":"<p>The following code will download a small dataset that we will use in the machine learning exercise today. There is a bug in this code that you'll need to find and fix in order to proceed with the exercise later.</p> <pre><code>import requests\nurl = \"https://raw.githubusercontent.com/eaton-lab/hack-the-planet/refs/heads/master/docs/data/penguin_data.csv\"\n\nwith open(\"penguin_data.csv\", 'w') as outfile:\n    outfile.write(requests.get(url).text)\n\ndata = penguin_data.csv\ndf = pd.read_csv(data)\n</code></pre>"},{"location":"tutorials/15.0-DebuggingChallenge3/#challenge-testing-multiple-conditions-in-an-if-statement","title":"Challenge: Testing multiple conditions in an <code>if</code> statement","text":"<p>Here is a quick function to test whether either of the two first input values are less than the third (optional) value that defaults to 4. <pre><code>def either_less(a, b, c=4):\n    if a or b &lt; c:\n        print(\"Both are less\")\n    else:\n        print(\"Both aren't less\")\n\neither_less(3, 5)\n</code></pre> The expected output (only if both input values actually are less): <pre><code>Both are less\n</code></pre></p>"},{"location":"tutorials/15.0-DebuggingChallenge3/#challenge-fix-all-the-bugs-in-one-shot","title":"Challenge: Fix all the bugs in one shot","text":"<p>Here is a different kind of challenge. This code should just print a message to the console but there are  many small problems with it. See how many of the bugs you can fix before running this cell to test it. Keep track of how many bugs you find before you get this code to run. How many was it total?</p> <pre><code>if true\nprint helloworld\n</code></pre>"},{"location":"tutorials/15.1-intro-scikit/","title":"Intro to Machine Learning with Scikit-Learn","text":"<p>In this session we will get a hands-on introduction to Machine learning with the <code>scikit-learn</code> package. In this lesson we will become familiar with:</p> <ul> <li>Basic machine learning vocabulary</li> <li>Data importing, transformation, and test/train splitting</li> <li>Unsupervised learning for clustering/dimensionality reduction</li> <li>Supervised learning for classification/regression tasks</li> </ul>"},{"location":"tutorials/15.1-intro-scikit/#prerequisites","title":"Prerequisites","text":"<p>You should already have the necessary packages installed, but if you don't you can install them like this: </p> <pre><code>conda install -c conda-forge matplotlib scikit-learn\n</code></pre> <p>Open a new notebook in your <code>hack-5-python/notebooks</code> directory and rename this notebook to \"15.1-intro-scikit.ipynb\". In a new cell, include a few imports that we will need:</p> <pre><code>import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import datasets\nfrom sklearn.decomposition import PCA\n</code></pre>"},{"location":"tutorials/15.1-intro-scikit/#fetch-the-iris-data","title":"Fetch the Iris data","text":"<p>We have been loading and cleaning the iris data by hand up to this point, but now we are going to make use of a nice feature in scikit-learn, which provides the iris data as a pre-loaded dataset.</p> <p>The iris data is loaded as a dictionary with several keys. Spend a few moments plotting the values associated with each of those keys and make sure you understand the structure of this data. <pre><code>data = datasets.load_iris()\n\niris.keys()\n</code></pre></p>"},{"location":"tutorials/15.1-intro-scikit/#data-cleaning","title":"Data Cleaning","text":"<p>Previously we had been removing rows that had contained missing values from the iris data. This might not be the best strategy because for a given row with missing data, it may still have values in the columns that are not missing, and throwing away data  feels bad. In the case where you want to retain all your data you can elect to impute missing values, which means to fill them in using some strategy which is hopefully defensible. A very simple and defensible strategy is to impute missing data with the mean value for a given column. Much more detailed information about imputation is available on the <code>scikit.impute documentation</code>. <pre><code>from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer(strategy='mean')  \nimputed_data = imputer.fit_transform(iris.data)\n</code></pre></p>"},{"location":"tutorials/15.1-intro-scikit/#visualizing-raw-data","title":"Visualizing raw data","text":"<p>As we did last week, we can use matplotlib <code>scatter</code> to visualize the relationship between 2 of the dimensions of data. <pre><code>plt.scatter(iris.data[:, 0], iris.data[:, 1], c=data.target)\nplt.xlabel('Sepal Length')\nplt.ylabel('Sepal Width')\n</code></pre></p>"},{"location":"tutorials/15.1-intro-scikit/#unsupervised-learning-dimension-reduction-clustering","title":"Unsupervised learning: Dimension reduction &amp; clustering","text":"<p>The nature of 'Big Data' is that it is hugely multidimensional, so plotting 2 dimension at a time might be a pointless operation. Unsupervised learning is a class of methods that takes unlabeled high-dimensional data and collapses it into a smaller number of dimensions that can capture in some way the relationship between the data points. I sometimes  think of unsupervised learning as 'exploratory data analysis', because it's a way of looking at the structure of the data through different lenses. Unsupervised learning also includes clustering methods for finding groupings of data-points that are 'similar' given some statistical model. We'll only talk about dimension reduction (or 'decomposition') today, but you can  learn more about both of these things in the scikit-learn documentation on \"Unsupervised learning: Clustering\" &amp; \"Unsupervised learning: Decomposition\"</p>"},{"location":"tutorials/15.1-intro-scikit/#principle-component-analysis","title":"Principle component analysis","text":"<p>Principal component analysis is a dimensionality reduction method used to transform and project  data points onto fewer orthogonal axes that can explain the greatest amount of variance in the data.</p> <p>We begin by constructing a <code>PCA</code> object, specifying to retain 3 components, and then calling  <code>fit_transform()</code> passing in the iris data. <code>fit_transform()</code> is actually a shortcut for calling <code>pca.fit(iris.data).transform(iris.data)</code>, because fitting and transforming are two different actions, but in some cases (as with PCA) it isn't necessary (or useful) to fit a model to data without transforming it as well. <pre><code>from sklearn.decomposition import PCA\n\npca = PCA(n_components=3)\nX_r = pca.fit_transform(iris.data)\n</code></pre> Here <code>X_r</code> is a new variable holding the values of each data point transformed with PCA.</p>"},{"location":"tutorials/15.1-intro-scikit/#evaluate-the-pca","title":"Evaluate the PCA","text":"<p>One key piece of information with PCA is the amount of variance explained along each  orthogonal PC axis. By definition the variance explained monotonically decreases from  the first to the last PC, meaning the first axis captures the most variation, and the second axis captures the second most, and so on. This allows you to 'read the tea leaves' a bit in interpreting the relationship between samples in PC-space.</p> <pre><code>## Percentage of variance explained for each component\nprint(f\"Explained variance ratio (first two components): {pca.explained_variance_ratio_})\n</code></pre>"},{"location":"tutorials/15.1-intro-scikit/#visualize-samples-in-pc-space","title":"Visualize samples in PC space","text":"<p>We can now plot the transformed data to see a 2-dimensional representation of our 4-dimensional iris dataset. <pre><code>colors = [\"navy\", \"turquoise\", \"darkorange\"]\n\nfor color, i, target_name in zip(colors, [0, 1, 2], iris.target_names):\n    plt.scatter(X_r[iris.target == i, 0], X_r[iris.target == i, 1], color=color, label=target_name)\n\nplt.legend()\n</code></pre></p> <p>PCA is a powerful and very widely used tool for dimension reduction, which  has many features that we have not discussed today that you can find in the PCA documentation</p>"},{"location":"tutorials/15.1-intro-scikit/#challenge-plot-pcs-other-than-1-and-2","title":"Challenge: Plot PCs other than 1 and 2","text":"<p>In the previous example we plotted PCs 1 and 2, which by definition explain the most variance in the data. Because we asked for <code>n_components=3</code> we actually have 3 PC dimensions to play with, so try plotting dimensions other than 1 and 2. Try plotting 2 and 3, for example, but first think about how the relationship between the points will change when looking at these PCs </p>"},{"location":"tutorials/15.1-intro-scikit/#supervised-learning-classification-tasks","title":"Supervised learning: Classification tasks","text":"<p>Whereas unsupervised learning used unlabeled data and statistical models to help identify patterns in this data, Supervised learning is a class of methods that uses labeled high-dimensional data, with the goal of learning a mapping between the <code>features</code> (explanatory or predictor variables) and the <code>targets</code> (response variables, or really the labels applied to the data). We could spend an entire semester on supervised learning in scikit-learn, so we will only touch on one specific model and the broad outline of the fit/transform/predict paradigm.</p> <p>The first kind of supervised learning models we will explore are Classifation models. In  a classification task the labels are categorical variables, and the goal of the inference is  to learn a mapping between the values of the data columns (features) and the corresponding  labels (targets).</p> <p>In the simplest terms, we want to be able to look at the values of our iris measurements and learn  something about how all these values combined can tell us about species ID, with the goal of being able to ID a new flower simply by pluggin in values for these measuerements.</p>"},{"location":"tutorials/15.1-intro-scikit/#traintest-split","title":"Train/Test split","text":"<p>For classification problems the target must be categorical, and so we will choose 'species' as the target, and the data columns as the features. One important step in ML workflows is splitting the data into <code>training</code> and <code>testing</code> sets. The reason for this is we want to train the ML model on one set of data, and then we want to evaluate how it performs on a  set of data that it hasn't 'seen' yet. This provides a more honest evaluation of model performance.</p> <p>scikit-learn provides a function for this called <code>test_train_split()</code> which handles all the details of randomly partitioning your data. In ML (particularly in the scikit world),  features are indicated by variables labeled <code>X</code> and targets are indicated by variables labeled <code>y</code>, and in the specific case of <code>test_train_split</code>, which returns a 4-tuple, the train and test data variables are almost always named this way: <pre><code>from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(scaled_data, iris_data.target)\n</code></pre></p> <p>Look at the <code>shape</code> of some of these new variables? What is the shape of <code>iris.data</code>? What can you  infer about the default ratio of training to testing data this function uses?</p>"},{"location":"tutorials/15.1-intro-scikit/#random-forest-classifier","title":"Random Forest Classifier","text":"<p>There is a huge wealth of parameters for <code>tuning</code> Random Forest models. We will side-step these for now by specifying <code>n_estimators=100</code> as the only parameter, and guiding you to the  wonderful documentation dedicated to tuning hyper-parameters of an estimator for more in-depth information.</p> <p>After we instantiate a new <code>RandomForestClassifier</code> object, the next thing we will want to do is \"fit\" the model to the features and the targets.  <pre><code>from sklearn.ensemble import RandomForestClassifier\n\nrf_model = RandomForestClassifier(n_estimators=100) \nrf_model.fit(X_train, y_train)\n</code></pre></p>"},{"location":"tutorials/15.1-intro-scikit/#model-evaluation","title":"Model evaluation","text":"<p>For classification, key metrics include:</p> <ul> <li>Accuracy: Overall proportion of correct predictions</li> <li>Precision: Proportion of positive predictions that are actual positives</li> <li>Recall: Proportion of actual positives predicted positively</li> </ul> <pre><code>from sklearn.metrics import classification_report\n\ny_pred = rf_model.predict(X_test)\nprint(classification_report(y_test, y_pred))\n</code></pre>"},{"location":"tutorials/15.1-intro-scikit/#visualizing-classification-performance","title":"Visualizing classification performance","text":"<p>scikit-learn also provides a nice way of visualy representing classification performance with a confusion matrix. The <code>ConfusionMatrixDisplay</code> class has a method called <code>from_estimator</code> which takes as arguments a trained model, and the test data for features and targets, and plots a nice graphical representation that captures most of the information in the classification report in a way that is very confusing at first, which is how it got this name. ;)</p> <pre><code>from sklearn.metrics import ConfusionMatrixDisplay\n\nConfusionMatrixDisplay.from_estimator(rf_model, X_test, y_test)\n</code></pre>"},{"location":"tutorials/15.1-intro-scikit/#supervised-learning-regression-tasks","title":"Supervised learning: Regression tasks","text":"<p>In our previous example of a classification task, we had a categorical target (response variable),  so the predictions were category probabilities (with the most probable category being the predicted value). If we have continuous value targets (e.g. numerical values), we can approach this task as a regression procedure where we are attempting to find a (potentially non-linear)  relationship between the features and the target(s).</p>"},{"location":"tutorials/15.1-intro-scikit/#traintest-split_1","title":"Train/Test split","text":"<p>Let's look back at the iris data one more time, to see what features we have available. <pre><code>print(iris.feature_names)\n</code></pre> <pre><code>['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n</code></pre> For this exercise we will choose <code>Petal width (cm)</code> as the <code>target</code> (response variable), and we'll use the other 3 measurements as <code>features</code> (predictor variables). Essentially we will ask how well we can predict petal width, if we only have information about sepal length/width, and petal length. Here we have to redo the <code>test_train_split()</code> call, because now we will split on  a different subset of the data.</p> <pre><code># imputed_data[:, :3] - The first columns of the imputed_data matrix\n# imputed_data[:, -1] - The last column of this matrix\n\nX_train, X_test, y_train, y_test = train_test_split(imputed_data[:, :3], imputed_data[:, -1])\n</code></pre>"},{"location":"tutorials/15.1-intro-scikit/#random-forest-regression","title":"Random Forest Regression","text":"<p>The format of the call to fit the random forest regressor is identical to the call to fit the classifier, we simply call <code>fit()</code> and pass in the features and targets from the training set. <pre><code>from sklearn.ensemble import RandomForestRegressor\n\nrgr_model = RandomForestRegressor(n_estimators=100) \nrgr_model.fit(X_train, y_train)\n</code></pre></p>"},{"location":"tutorials/15.1-intro-scikit/#model-evaulation","title":"Model evaulation","text":"<p>Sklearn regression estimators have a different evaluation mechanism for performance, because the 'targets' (response variables) are continuous  and not categorical. To evaluate regression performance you can use the <code>score()</code> method, passing in the held-out features (<code>X_test</code>) and targets (<code>y_test</code>). <pre><code>print(rgr_model.score(X_test, y_test))\n</code></pre></p>"},{"location":"tutorials/15.1-intro-scikit/#visualizing-regression-performance","title":"Visualizing regression performance","text":"<p>You can also visualize regression prediction performance by calling <code>predict()</code> on the held-out features (<code>X_test</code>) to generate target predictions (here <code>y_pred</code>) and then plotting the results in a scatter plot, with \"True\" values on the y-axis and predicted values on the y-axis. <pre><code>y_pred = rgr_model.predict(X_test)\nplt.scatter(y_test, y_pred)\n</code></pre></p>"},{"location":"tutorials/15.1-intro-scikit/#challenge-re-do-this-analysis-workflow-with-a-new-dataset","title":"Challenge: Re-do this analysis workflow with a new dataset","text":"<p>Go through the same workflow we did above with exploratory analysis (PCA dimension reduction), classification, and regression using the <code>penguin_data.csv</code> file from  today's debugging challenge.</p>"},{"location":"tutorials/15.1-intro-scikit/#wrapping-up","title":"Wrapping up","text":"<p>Add, commit, and push your notebook to your github repo.</p>"},{"location":"tutorials/17.0-git-collab/","title":"git collab","text":""},{"location":"tutorials/17.0-git-collab/#collaborative-coding-with-git","title":"Collaborative coding with git","text":""},{"location":"tutorials/17.0-git-collab/#why-collaborate-code","title":"Why collaborate code?","text":"<p>Collaborative coding is an efficient way to write better and faster code.  By bouncing ideas off of others you can often find better ways to design and implement code to achieve your goals. Everyone's style is different, and most coding problems can be solved in numerous possible ways. By working with  others you will be exposed to new problems and routines that you may wish to include in your own code in the future. </p> <p>Collaborative coding is easier today than it has ever been before, thanks to public code repositories like GitHub, which leverage <code>git</code> to sync code  between local and cloud-based repositories, and to resolve conflicts that can arise when multiple users are editing code at the same time. So far  we have learned to use these tools as an individual user, where conflicts are very uncommon. Now we will begin to implement collaborative coding where you will likely encounter conflicts, so we will need to learn how to resolve them. </p>"},{"location":"tutorials/17.0-git-collab/#example-workflow","title":"Example workflow","text":"<ul> <li>User A has a repo hosted on GitHub.</li> <li>User B forks the repo, commits changes, and pushes to their fork.</li> <li>User B opens a pull request from GitHub telling User A about the new changes.</li> <li>User A looks at the pull request on GitHub to understand the changes.<ul> <li>If the changes are very simple:<ul> <li>User A accepts the request to merge commits into their code, closing the request.</li> </ul> </li> <li>If the changes are complex, or include a conflict:<ul> <li>User A can resolve the conflict in GitHub's editor.</li> <li>Or, User A can check out User B's pull request as a new branch.</li> <li>User A resolves conflicts in their editor, or makes changes to the new code.</li> <li>User A then merges this branch into main and push commits to origin.</li> <li>User A goes back to the pull request on GitHub, which is now identical to main, and closes it.</li> </ul> </li> </ul> </li> </ul>"},{"location":"tutorials/17.0-git-collab/#user-a-has-a-repo-hosted-on-github","title":"User A has a repo hosted on GitHub","text":"<p>User A created a new repo at <code>https://github.com/UserA/collab-test</code> as a simple Python package. </p>"},{"location":"tutorials/17.0-git-collab/#user-b-forks-the-repo-commits-changes-and-pushes-to-their-fork","title":"User B forks the repo, commits changes, and pushes to their fork","text":"<p>User A is collaborating with User B, who is a better coder, and is going to  check in on User A's project occasionally to make edits to improve it. </p> <p>User B creates a fork of User A's repo and clones it to their computer. User B can then make their changes to the main branch or to a new named branch, it doesn't really matter. For clarity, we'll use a new branch here called  <code>Bedits</code>.</p> <pre><code># user B clone's their forked repo and cd into it\ngit clone https://github.com/UserB/collab-test\ncd collab-test/\n\n# creates a new branch for their edits\ngit checkout -b Bedits\n\n# makes changes to the code\n# subl .\n</code></pre> <p>In this case User B saw that User A had written the function below to check whether the number 50 is within a range between two numbers: <pre><code>def is_50_in_list(low, high):\n    \"\"\"\n    Loops over all values checking if it is 50\n    \"\"\"\n    for i in range(low, high):\n        if i == 50:\n            return True\n    return False\n</code></pre> and they realized that this could be written much more efficiently as the  following, and so they made a change to the code: <pre><code>def is_50_in_list(low, high):\n    \"\"\"\n    Finds if the value 50 is within a range of numbers.\n    \"\"\"\n    return 50 in range(low, high)\n</code></pre></p> <p>User B then stages and commits this change and pushes to their fork (origin). They could push to main or to a separate branch name, here we will push to the branch name Bedits. </p> <pre><code># stages, commits and pushes new branch to forked repo\ngit add .\ngit commit -m \"fixed slow for-loop\"\ngit push origin Bedits\n</code></pre>"},{"location":"tutorials/17.0-git-collab/#user-b-opens-a-pull-request","title":"User B opens a pull request","text":"<p>User B now makes a pull request to User A on GitHub to make them  aware that there are new changes to the code. To do this they go to their own forked repo and click on the Pull request button. Here you can see that GitHub is alerting User B that their branch is ahead of User A</p> <p></p> <p>In the pull request User B can enter additional comments to describe the  commits on this new branch. Then they click the green  \"Create pull request\" button to officially send it.</p> <p></p>"},{"location":"tutorials/17.0-git-collab/#user-a-looks-at-the-pull-request-on-github","title":"User A looks at the pull request on GitHub","text":"<p>User A will receive an email alerting them to the pull request,  and it will appear in the pull request tab on their repo page, like below:</p> <p></p> <p>User A can now investigate these proposed changes. They need to figure out if it is a very simple change or a complex one. This will affect their decision of how to deal with the pull request.</p> <p>User A knows that User B is a much better coder, and so they are likely to  accept the changes, but still, User A wants to be sure that the new code makes  sense before accepting (merging) the commits into their project. After all,  this is User A's project, and they have the final say about how the code  should be written.</p> <p>The first thing User A can do is to click on the Pull Request tab  which will show whether or not the changes conflict with any other changes  that User A has made to their code. They can then click on the tab labeled  \"Files changed\" to see a diff of the changes made by User B. This shows  line-by-line which lines were removed or added by User B. Example below:</p> <p></p>"},{"location":"tutorials/17.0-git-collab/#if-the-changes-are-simple","title":"If the changes are simple","text":"<p>If the changes to the code are simple, as in the example here, the User  can go back to the first tab (conversation) of the Pull Request and select  \"Merge pull request\" to accept the changes. These commits will be merged into <code>origin/main</code>. </p>"},{"location":"tutorials/17.0-git-collab/#if-the-changes-are-complex-or-conflicting","title":"If the changes are complex or conflicting","text":"<p>Although User A trusts User B, the changes they proposed may seem wonky, and so User A wants to test run the code before merging into their main branch. They can do this by checking out the commits that User B proposed onto  a new branch. This can be done following the convention below:</p> <pre><code># template for checking out a pull request\ngit fetch origin pull/ID/head:BRANCHNAME\n</code></pre> <p>where ID is replaced by the number that is listed next to the title of the  pull request on GitHub. In this case it was 1, since this was the first pull request. In addition, BRANCHNAME should be replaced by the name that UserA wants to call this branch. I will call it UserB to indicate that it came  from them.</p> <pre><code># checking out pull request #1 as branch UserB\ngit fetch origin pull/1/head:UserB\n</code></pre> <pre><code>\nremote: Enumerating objects: 7, done.\nremote: Counting objects: 100% (7/7), done.\nremote: Compressing objects: 100% (2/2), done.\nremote: Total 4 (delta 2), reused 4 (delta 2), pack-reused 0\nUnpacking objects: 100% (4/4), 414 bytes | 207.00 KiB/s, done.\nFrom https://github.com/hackers-test/collab-test\n * [new ref]         refs/pull/1/head -&gt; UserB\n(base) deren@tuba:~/hacks/collab-test (main)$ \n</code></pre> <p>User A can now check out this branch to test the new code. <pre><code># checkout the new branch\ngit checkout -b UserB\n\n# the new commits are now enacted in your code, view and test the\n# code in your favorite text editor.\nsubl .\n</code></pre></p> <p>Once User A has tested the code and is satisfied that the changes UserB made  are fine, they can merge these changes into their main branch.</p> <pre><code># switch back to the main branch\ngit checkout main\n\n# merge changes from UserB branch into main\ngit merge UserB\n\n# remove the UserB branch that is no longer needed\ngit branch -d UserB\n\n# push to origin main\ngit push origin main\n</code></pre>"},{"location":"tutorials/17.0-git-collab/#syncing-local-and-remote","title":"Syncing local and remote","text":"<p>If you accept a pull request directly on GitHub (the remote), and then later try to push some new changes to the same repo from your command line (local), git will tell you that your local branch is behind the remote branch, and  that you need to perform a <code>git pull</code>. Go ahead and do this to update your current branch, then rety your <code>git push</code> command.</p>"},{"location":"tutorials/17.0-git-collab/#in-case-of-conflicts","title":"In case of conflicts","text":"<p>Let's consider an example of a conflict. Imagine that User A accepted User B's changes directly on GitHub, but they also made a similar change to the code  on their own branch locally. If they try to do a <code>git pull</code> they will encounter a conflict, where the local file includes changes to the same lines that changed in the file on the remote. There are several ways to resolve this, depending on who's version of the result you want to keep. This is the topic of the  next tutorial.</p>"},{"location":"tutorials/17.1-git-conflict/","title":"git collab assignment","text":""},{"location":"tutorials/17.1-git-conflict/#git-conflicts","title":"Git conflicts","text":"<p>Git conflicts arise when changes to a repo are committed from two or more different locations. This is usually a result of two developers collaborating on the same code, but it can also arise when a single person is comitting  changes to a repo, for example, if they commit changes both locally on their laptop and remotely through the GitHub website. </p>"},{"location":"tutorials/17.1-git-conflict/#what-does-a-conflict-look-like","title":"What does a conflict look like?","text":"<p>Let's walk through an example using the repo <code>https://github.com/hackers-test/hack-program</code>. To keep things simple for now, we will make a conflict arise  in the README file, caused by making a change to the same line both on my  laptop and on GitHub. </p> <p>First, I opened my browser to the repo linked to above and clicked on the  pen icon on the README file to edit it directly online. On the third line of the README I then entered the text \"Committed from GitHub\" and committed the change.</p> <p>Next, I opened my local clone of the repo in my terminal. Here I also made a change to the same README.md file, entering on the third line the text \"Committed from local\". I then committed and tried to push the change.</p> <pre><code>git add README.md\ngit commit -m \"...\"\ngit push\n</code></pre> <pre><code>(base) \nTo https://github.com/hackers-test/hack-program.git\n ! [rejected]        main -&gt; main (fetch first)\nerror: failed to push some refs to 'https://github.com/hackers-test/hack-program.git'\nhint: Updates were rejected because the remote contains work that you do\nhint: not have locally. This is usually caused by another repository pushing\nhint: to the same ref. You may want to first integrate the remote changes\nhint: (e.g., 'git pull ...') before pushing again.\nhint: See the 'Note about fast-forwards' in 'git push --help' for details.\n</code></pre> <p>As you can see, we cannot push to the remote repo because it is currently one or more commits ahead of our current branch. This actually doesn't yet mean  that there is a conflict, but it means that we need to check for a conflict by following the instructions, which tell us to perform a <code>git pull</code>. </p> <pre><code>git pull\n</code></pre> <pre><code>\nAuto-merging README.md\nCONFLICT (content): Merge conflict in README.md\nAutomatic merge failed; fix conflicts and then commit the result.\n</code></pre> <p>This tells us that there is a conflict, and that is occurs in the README.md file, and tells us that we need to fix it. So how do we do that?</p>"},{"location":"tutorials/17.1-git-conflict/#resolving-conflicts","title":"Resolving conflicts","text":"<p>When you made the <code>git pull</code> request above you accepted the changes from the  remote main branch into your local main branch. Often people might create a separate branch in which to pull these changes to ensure that you do not mess up your main. Here we're taking a lazier approach. The message above told us which files contain conflicts, so let's take a look at that file. What we  will find is a conflict represented by text that has been inserted into our code like the following:</p> <pre><code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\nCommitted by Local.\n=======\nCommitted by GitHub.\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; af4e39e325cf414f268a0b75f41e1ff72a29322b\n</code></pre> <p>To understand this we first need to revisit some naming conventions from git.  The term <code>HEAD</code> refers to the latest committed state of your current branch.  Thus, anything in the section between <code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</code> and <code>=======</code> represents the code that was entered in our local repo. Alternatively, the code between  <code>======</code> and <code>&gt;&gt;&gt;&gt;&gt;&gt;&gt; ...</code> is code that was entered on the remote -- the code we pulled in from somewhere else. The name of that commit is much uglier, in  this case <code>af4e39e325cf414f268a0b75f41e1ff72a29322b</code>. This is just a random hash value that is a unique signature of that specific commit. As you can  see then, the format of a file that contains a conflict is to show both versions of the code separated by the <code>=======</code> delimiter. Your job as the resolver is to select which version of the code you want to keep.</p> <p>To do this you can simply open the file in your favorite text editor. You must remove the lines with arrows and the delimiter, and then leave just the code you want to keep. For this you have the option to select the code from one commit or the other; or, you can remove both of their commits and enter your own new solution. That's we will do here. I replaced this entire bloock between the  arrowed commits with the line below showing that both users committed to this line:</p> <pre><code>Committed by Local &amp; GitHub.\n</code></pre> <p>Finally, you can now push your changes and they are ensured not to conflict with any other changes on the remote, since you already pulled in and merged all of the changes that are present on the remote. <pre><code>git add README.md\ngit commit -m \"resolved conflict\"\ngit push origin main\n</code></pre></p>"},{"location":"tutorials/17.1-git-conflict/#when-there-is-no-conflict","title":"When there is NO conflict?","text":"<p>Although conflicts can arise, they are not inevitable. Two users can edit code at the same time and as long as they do not edit the exact same lines of code their commits can be merged without any conflicts at all. As an example, let's say you accepted the pull request from another user on GitHub and merged their commits into main. Then, like in the example above, you later try to push some new commits from your local branch. Again, git will tell you that you cannot push because the remote is ahead of you, and so you need to first do a git pull. When you do the <code>git pull</code> this time, because there are no conflicts, it will simply print a summary for you showing which files have been changed:</p> <pre><code>remote: Enumerating objects: 16, done.\nremote: Counting objects: 100% (16/16), done.\nremote: Compressing objects: 100% (12/12), done.\nremote: Total 12 (delta 6), reused 0 (delta 0), pack-reused 0\nUnpacking objects: 100% (12/12), 2.94 KiB | 601.00 KiB/s, done.\nFrom github.com:eaton-lab/hack-the-planet\n   df5c59a..c449dfd  master     -&gt; origin/master\nMerge made by the 'recursive' strategy.\n README.md | 4 ++--\n 1 file changed, 2 insertions(+), 2 deletions(-)\n</code></pre> <p>Your files have been updated and no conflict characters (e.g., <code>&gt;&gt;&gt;&gt;</code>)  were inserted, only the merged commits. </p>"},{"location":"tutorials/17.1-git-conflict/#other-places-conflicts-arise","title":"Other places conflicts arise","text":"<p>In our first example a conflict was identified when we tried to perform a  <code>git push</code> from local, where git informed us that the remote already had  merged commits that would cause a conflict. In other words, the other user beat us to the punch and made changes first. But what if it had been the other way around, and we pushed commits from local before the other user made their pull request. In that case both users will see a message on GitHub telling them that the new pull request contains conflicts and cannot be merged until they are resolved. </p> <p>There is an option to resolve these conflicts using the interactive editor in GitHub, which is an easy option. But for more complex coding changes we'll use the terminal. Here the owner of the repo will pull in the changes from the pull request branch using <code>git pull origin pull/{number}/head</code>. To ensure we do not mess up our main branch I usually do this on a separate branch,  which we first create using <code>git checkout -b {any name}</code>. </p> <pre><code># checkout a new branch\ngit checkout -b hotfix\n\n# merge pull request into this branch -- any conflict will arise\ngit pull origin pull/1/head\n\n# edit to resolve conflicts\n# ...\n\n# test your code with these new changes\n# ...\n\n# swith to main and merge hotfix branch into main\ngit checkout main\ngit merge hotfix\n\n# commit changes back to GitHub -- this will close the PR\n# since the PR branch will become identical to main.\ngit add README.md\ngit commit -m \"resolved conflict with PR #1\"\ngit push origin main\n</code></pre>"},{"location":"tutorials/17.1-git-conflict/#this-seems-complicated","title":"This seems complicated","text":"<p>It is! It takes a long time to get comfortable with <code>git</code> to the level that  you memorize the order in which to call all of these commands. Fortunately,  there are hundreds of tutorials like this one around the web that you can  search to help you whenever you have a question. Revisit them as often as you need, and remember, <code>git</code> is a time machine, you can always rewind to former committed state, so don't worry if you think you've totally broken your repo. Seek help if you get stuck, and you'll figure it out.</p>"},{"location":"tutorials/17.2-git-in-class/","title":"git collab","text":""},{"location":"tutorials/17.2-git-in-class/#git-and-github-collaborative-practice","title":"Git and GitHub Collaborative Practice","text":""},{"location":"tutorials/17.2-git-in-class/#clone-a-repo-to-try-it-out","title":"Clone a repo to try it out","text":"<p>Let's start by cloning a GitHub repository. This is a typical thing we would do if we wanted to try out a software tool that is publicly available. For this example we will use this class repository. First navigate to the class GitHub page at https://github.com/eaton-lab/hack-the-planet and click on the green \"Code\" button to get the SSH URL. Then open a terminal  and clone it to a local directory on your computer.</p> <pre><code>git clone git@github.com:eaton-lab/hack-the-planet.git\n</code></pre>"},{"location":"tutorials/17.2-git-in-class/#a-clone-repo","title":"A clone repo","text":"<p>We can now use the code in the repo, and we can even edit the code in this repo. However, we do not have permissions to push changes we make to this code back to the original repo. What if we decide that we do want to make changes and commit them? This is where we would want to create a fork. What is a fork? It is just a  copy of the repo that is hosted under your GitHub profile, so that you have ownership of it, and is linked to the original repo, so that you can propose changes back to it. Once a repository exists in multiple locations, we refer to these as remotes. The original remote is typically called origin. Other remotes can be called anything you want. You can link multiple remotes to a single repository, such that you pull and push code to each selectively. We can use the command <code>git remote</code> to view the remotes that are currently linked.</p> <pre><code># view the remotes\ngit remote -v\n</code></pre> <pre><code>origin  git@github.com:eaton-lab/hack-the-planet.git (fetch)\norigin  git@github.com:eaton-lab/hack-the-planet.git (push)\n</code></pre>"},{"location":"tutorials/17.2-git-in-class/#create-a-fork","title":"Create a fork","text":"<p>Let's create a fork. Navigate back to the GitHub page and this time click on the \"Fork\" button in the upper right. This will create a fork, and navigate to a new page where your fork is located. Notice that it looks pretty much the same, but your username appears near the top. Once again, click on the green Code button to copy the git SSH URL. Now, we will add this URL as a remote to our repo.</p> <pre><code>git remote add \"upstream\" {pasted-url}\n</code></pre> <pre><code># view the remotes\ngit remote -v\n</code></pre> <pre><code>origin  git@github.com:eaton-lab/hack-the-planet.git (fetch)\norigin  git@github.com:eaton-lab/hack-the-planet.git (push)\nupstream  git@github.com:USERNAME/hack-the-planet.git (push)\nupstream  git@github.com:USERNAME/hack-the-planet.git (push)\n</code></pre>"},{"location":"tutorials/17.2-git-in-class/#make-edits-on-a-branch","title":"Make edits on a branch","text":"<p>Now we can make edits to the code and push our changes to our forked repo. Let's start by editing the REAMDE.md file. Don't worry about what the changes are for now, this is just for practice. Open the README in  any text editor and simply add a few characters of text to it, save, and close the file. Then let's add our changes to git. BUT, notice that when call push here we will specify the 'main' branch on the 'upstream' remote.</p> <pre><code>git add README.md\ngit commit -m \"fixed typo in README\"\ngit push upstream main\n</code></pre>"},{"location":"tutorials/17.2-git-in-class/#view-the-fork-and-origin-on-github","title":"View the fork and origin on GitHub","text":"<p>Now that many of us have pushed our commits to a fork, let's look at what we see on GitHub. You should see on your fork that it is one commit ahead of the origin. It will also suggest that you make a pull request to the origin. Let's follow the instructions to do that.</p>"},{"location":"tutorials/17.2-git-in-class/#reviewing-a-pull-request","title":"Reviewing a pull request","text":"<p>Next, let's check what the owner of the origin repo sees. They will see all of the pull requests made by users and have the option to accept them, just like we did in our first exercise today.</p>"},{"location":"tutorials/18.1-got-collab-assign/","title":"git collab assignment","text":""},{"location":"tutorials/18.1-got-collab-assign/#assignment","title":"Assignment","text":"<ul> <li>Fork the repo of a class mate nearby to you (Go to their GitHub repo page and click 'fork')</li> <li>Clone your fork of the repo to your computer.</li> <li>Open the folder in your text editor.</li> <li>Read the Users README and proposal.md file, if present, on GitHub.<ul> <li>Follow any links documentation for packages they plan to use and browse this to gain an understanding of what this package is for, and how it works.</li> </ul> </li> <li>Create a new file in the top-level of their directory called <code>paired-programming.md</code></li> <li> <p>In this markdown file write headings and paragraphs to answer the following questions. The goal here is to provide feedback to the other student from the perspective of one of their peers. Let them know what you do and don't understand about the project given what is currently present.</p> <ul> <li> <p>Goal of the project: Is it clear to you from the proposal.md how the  goal can be accomplished using Python and the specified packages?</p> </li> <li> <p>The Data: Is it clear to you from the proposal.md what the data for this project is, or will look like? </p> </li> <li> <p>The code: (Look at the Python code files in detail first and try to  comprehend a bit of what is written so far) </p> <ul> <li>Does the current code include a proper skeleton (pseudocode) for starting this project? </li> <li>What can this code do so far?</li> <li>Given the project description, what are some individual functions that could be written to accomplish parts of this goal? </li> </ul> </li> <li> <p>Code contributions/ideas: See description below for what to write here.</p> </li> </ul> </li> <li> <p>Your goal is to try to contribute to this student's project. It is OK if you don't fully understand the code, or even the project goal. But hopefully from the proposal you understand at least some parts of it. For example, the user at some point plans to create a scatterplot with Bokeh, and they included a link to the bokeh documentation. You can contribute by creating a new file called bokeh_plot.py and trying to create simple plot for what you imagine they will eventually hope to do with their data. Or as another example, they describe that they plan to organize data from a REST API into a dataframe, but they haven't written the code to do this yet. You can try to write a class or function to  do this, and put it either in their existing module, or in a new module file. Your goal is to try to make a contribution to the code. (If you're unsure even after reading their proposal very carefully how you can contribute to  their project, then please message me in the chat and I will help.)</p> </li> </ul> <p>After making your contribution describe it in the Code contribution section of the <code>paired-programming.md</code> file. </p>"},{"location":"tutorials/18.1-got-collab-assign/#submitting-assignment","title":"Submitting assignment","text":"<p>Once you've made your changes to the code, you can commit your changes and  push to the remote, and then raise a pull request to make the other user  aware of your proposed changes. We will read the pull requests and give a  grade on your effort. </p> <pre><code># stage and commit changed files to your forked copy of their repo\ngit add src/bokeh_plot.py\ngit add paired-programming.md\ngit commit -m \"added a bokeh plot example module\"\ngit push origin main\n\n# then go to the GitHub page of your forked copy of their repo and \n# raise a pull request.\n</code></pre>"},{"location":"tutorials/18.1-pair-program/","title":"pair-program","text":""},{"location":"tutorials/18.1-pair-program/#assignment","title":"Assignment","text":"<p>In class you will meet with other students that are members of your same  group (A-D), and outside of class you will fork and clone the repo of your paired-programming companion working on the same topic ( see table below). Try to run the minimal working example of their code. </p>"},{"location":"tutorials/18.1-pair-program/#exploring-their-code","title":"Exploring their code","text":"<p>Your goal is to gain a better understanding of their code. You have been paired together because your project goals share some similarities. If you see a place in their code that is poorly formatted (e.g., your linter has highlighted it),  then fix it. Commit the change and in the comment field state why you  re-formatted it. If you are unsure why a certain part of code exists then  stick a print or logger statement inside of the code block to print the state of variables before and after that section of code runs. If you are still  unsure then write a chat to your partner to ask about it.</p> <p>Your goal is to make a commit to their project, and specifically, to identify a place in their code where your commit can be useful. This means going beyond the goal of our first paired-programming exercise where you could commit  anything. We're looking for more than just a comment line here. Need help?  Just ask in the chatroom.</p>"},{"location":"tutorials/18.1-pair-program/#paired-programming-groups","title":"Paired programming groups","text":"Paired programming groups Group Topic A statistical Roiak2 Clan2021 A GUI ttl2132 lili4127 B streamlit webapp 3amMcspicy alicerk B map viz webapp floodowen yam020 C API mapping j-meek HenryLandis C CLI parse/analyze aparnac25 jasmina-dzurlic D evolution elissasoroj cohen-r D biology athe1sm smau8"},{"location":"tutorials/2.0-github/","title":"2.0: Getting started with GitHub","text":""},{"location":"tutorials/2.0-github/#what-are-git-and-github","title":"What are git and GitHub?","text":"<p>Github (github.com) is a website, whereas <code>git</code> is a computer program. Today we will mostly be learning about GitHub, and saving the more complicated  topic of <code>git</code> for next week. But to understand why Github is useful  you will need to understand a little about its relationship to <code>git</code>, and what <code>git</code> is used for.</p>"},{"location":"tutorials/2.0-github/#git","title":"Git","text":"<p>git is a type of version control software. In its most simple form, <code>git</code> is a program for tracking changes  that are made to files over time. This is useful not only as a type of time-machine -- allowing you to go back to previously saved versions of files -- but also as a mechanism for syncing files between multiple  locations (e.g., multiple different computers) and/or among multiple  potential users. The true power of <code>git</code> comes from its methods for  resolving conflicts when multiple users make changes to the same files. It is a collaboration software which helps a user to resolve conflicts and to store one or more versions of files at the same time.</p> <p>Any folder on your computer can be made into a <code>git repository</code>  by activating the <code>git</code> program inside of that folder. This allows you to tell <code>git</code> which files should or should not be tracked for changes. The entire folder full of files and/or subfolders can then be synced between machines. Because computer programs often involve many files and folders that must be maintained in a specific structure, <code>git</code> provides a useful framework for syncing changes to these files (the repository) across machines.</p> <p>Is <code>git</code> installed on your machine? Probably. If you are on Linux  (or using Windows Subsystem for Linux 2) then you will have <code>git</code> installed by default. If you are on OSX then it may be installed. Open a terminal and try the command below; if git is not installed  your terminal will prompt you to install the Xcode command line tools, which includes git as well as several other tools you will want.</p> <pre><code>$ git --version\n</code></pre>"},{"location":"tutorials/2.0-github/#github","title":"GitHub","text":"<p>GitHub is a website. In the sense that <code>git</code> is used to sync a repository across machines, you can think of GitHub as hosting a machine that exists in the cloud. It is of course useful to keep a cloud-based copy of your repository since cloud servers are generally a reliable backup that will never be lost -- as opposed to your own laptop which could  crash and burn  (hackers reference) at any time. Another advantage of keeping your  repository backed up in the cloud is that if multiple users intend to access it, the cloud-based version will always be accessible --  if by contrast it was stored on your local computer, you may at some point disconnect your computer. So in summary, GitHub provides a  cloud-based storage location for <code>git</code> repositories.</p> <p>But GitHub actually does much more than this as well. It acts as a  social network for developers, by making the contents of <code>git</code>  repositories openly readable (unless purposefully kept private) and shared with all users. There are several websites that serve similar functions to GitHub (such gitlab, bitbucket, sourceforge) but the community has mostly coalesced around GitHub. Its a bit like a Facebook versus Friendster battle, you can use one of the alternatives, but nobody is likely to see your content.</p>"},{"location":"tutorials/2.0-github/#how-we-will-use-github","title":"How we will use GitHub","text":"<p>You will need to have a GitHub account for this course. To signup you only need an email address. The service is completely free and is a highly  trusted source that will not overrun you with spam, so feel free to use  your school email address if you like. If you already have a GitHub account feel free to use it for this course, or to create a new one using a separate email address. You will be required to create several git repositories throughout this course. Choose your GitHub username wisely. This is  your public profile as a developer. It is how many people will become familiar with your work, and it can even help you to land a job in  the tech industry. As an example, I use \"dereneaton\" and \"eaton-lab\"  as the usernames for my two accounts. To create a new account:</p> <ul> <li>Go to https://github.com and find the  Sign-up button near the top.</li> <li>Create a username and enter your email address. </li> <li>Follow instructions to create a free account.</li> </ul>"},{"location":"tutorials/2.0-github/#assessment","title":"Assessment","text":"Complete the tasks in this section to earn points for the assignment."},{"location":"tutorials/2.0-github/#task-1","title":"Task 1","text":"<p>Complete the hello-world exercise from the github guide. When you finish creating your account you may be prompted to complete the GitHub starting guide. Complete all steps of this guide to create your  first github repository (https://guides.github.com/activities/hello-world/). To complete this tutorial all you need is a GitHub.com account  and Internet access. You don\u2019t need to use the command line, or have git  installed locally, it is completely based on the GitHub website. You will be graded on completing the creation of the 'hello-world' repository.</p>"},{"location":"tutorials/2.0-github/#task-2","title":"Task 2","text":"<p>Create a new repository named <code>hack-2-shell</code>. Just like in the GitHub Starting Guide, start by creating a new repository and name it hack-2-shell. Initialize the repository with a README file.  That's it. See the other tutorials for this session for further instructions to add content to this repository.</p>"},{"location":"tutorials/2.0-github/#task-3","title":"Task 3","text":"<p>Submit your username so we can find your profile for grading. We will look at your public GitHub profile to find the repositories for grading. Thus it is important that you name the repos using the  names that we instruct you to use. Changes are marked by time-stamps,  and grading will take into account changes made after the deadline. Assignments are due before the beginning of the next class, unless stated otherwise.</p> <p>Finally, to complete the assignment submit your GitHub profile name  at this link</p>"},{"location":"tutorials/2.1-shell/","title":"2.1. Shell, variables, and PATH","text":""},{"location":"tutorials/2.1-shell/#operating-systems","title":"Operating systems","text":"<p>An operating system (OS) is the core software that manages hardware and software  resources on a computer. It includes the kernel, whose core function is to  communicate between hardware and software, and a core set of utilities (programs). Examples of operating systems include Linux, MacOS, and Windows. MacOS and Windows typically maintain a few versions of their OS at a time. By contrast, there are  many different distributions of Linux. These share the use of a Linux kernel, but differ in the set of core software that they come with, and their default settings.</p> <p>For this reason, you will see that the instructions we provide will sometimes  differ slightly between Linux and MacOSX, and this extends to other Linux distributions as well. The most commonly used Linux distribution is called Ubuntu, and this is the distribution you will encounter when using WSL2, or an HPC cluster. Here we will introduce the terminal, or shell, which is a software tool used to call other software programs using commands. </p> <pre><code>echo $OSTYPE\n</code></pre> <pre>\nlinux-gnu   \n</pre>"},{"location":"tutorials/2.1-shell/#system-software-utilities","title":"System software utilities","text":"<p>Your computer has a lot of software tools installed. Of course this includes those you see on your desktop, like email and calendar, but it also includes many smaller and simpler tools that you likely don't know about. This includes some of the core utilities that we've begun to learn about, such <code>cd</code>, <code>ls</code>, and <code>echo</code>.  These are stored in a location in your filesystem that is relatively 'deep' -- near the root (<code>/</code>) -- such as in <code>/bin</code> or <code>/usr/bin</code>.  These folders are protected by your system such that they can only be edited by users with administrative privileges. Which makes sense,  you don't want to make changes to these programs and break them, or  your system would be caput. </p> <p>Let's use the list program <code>ls</code> to list all of the programs in our <code>/bin</code> folder. Here I'm showing only the first few lines of the output, as it contains hundreds of tools. <pre><code># see all the program names in /bin/\nls -l /bin/\n</code></pre></p> <pre>\ntotal 659832\n-rwxr-xr-x 1 root root        55744 Apr  5  2024 '['\n-rwxr-xr-x 1 root root        14640 Mar 31  2024  411toppm\n-rwxr-xr-x 1 root root        18744 Jul 18  2024  aa-enabled\n-rwxr-xr-x 1 root root        18744 Jul 18  2024  aa-exec\n-rwxr-xr-x 1 root root        18736 Jul 18  2024  aa-features-abi\n-rwxr-xr-x 1 root root        22912 Apr  7  2024  aconnect\n-rwxr-xr-x 1 root root         1622 Nov 30 13:21  acpidbg\n-rwxr-xr-x 1 root root        16422 Aug 15 04:26  add-apt-repository\n-rwxr-xr-x 1 root root        14720 Aug  8 22:33  addpart\nlrwxrwxrwx 1 root root           26 Aug  7 06:15  addr2line -&gt; x86_64-linux-gnu-addr2line\n-rwxr-xr-x 1 root root        43552 Mar 31  2024  afm2pl\n-rwxr-xr-x 1 root root        53824 Mar 31  2024  afm2tfm\n-rwxr-xr-x 1 root root       158576 Apr  8  2024  airscan-discover\n...\n</pre> <p>If you scrolled down this list you would see that it even includes a program  called <code>ls</code>. That's right, that file is the <code>ls</code> program executable itself.  Note that although the program is located within the <code>bin</code> folder, we were able to call <code>ls</code> from our shell without having to type the full path to its location. This is because the software tools in <code>bin</code> are all accessible by default in the shell. They are in our PATH (more on this below). However, we can also call  programs from <code>bin</code> by writing the full path to the executable files. The command below should yield the same output as the one above.</p> <pre><code># call the ls program from /bin/\n/bin/ls -l /bin/\n</code></pre>"},{"location":"tutorials/2.1-shell/#the-shellterminal","title":"The Shell/Terminal","text":"<p>A shell provides an interface for users to interact with the operating system. It is primarily used to execute commands, run scripts, and automate tasks. The shell itself is a program. The most common shell programs are <code>bash</code> and <code>zsh</code>,  but there are many alternative options. You can call the command below to find the name of your shell. Take note, we will use this information later. </p> <pre><code>echo $SHELL\n</code></pre> <pre>\n/bin/bash\n</pre>"},{"location":"tutorials/2.1-shell/#shell-variables","title":"Shell variables","text":"<p>Most computer languages use variables as a way of assigning an object to a name that can be used to reference it over and over again.  Usually the <code>=</code> operator is used to assign variables (e.g., <code>x = 3</code>, but  even this differs among languages (e.g., you may be familiar with the syntax of <code>x &lt;- 3</code> in R to assign variables).  Variables can also be used in a shell or terminal. This is an example of the shell being used as a scripting language. Shell scripting languages are  not full programming languages, like C or Python, but provide a minimal  framework for flow control to automate commands, including assigning variables.  The example below is a shell script that stores a variable and then prints it by calling the <code>echo</code> command. </p> <pre><code># store a variable\nx=3\n\n# retrieve the variable's value using $\necho $x\n</code></pre> <pre>\n3\n</pre>"},{"location":"tutorials/2.1-shell/#default-shell-variables","title":"Default shell variables","text":"<p>As we learned in lecture, your shell stores a lot of information as variables behind the scenes. This includes variables that tell it how to display colors  and text in the terminal, how to keep track of its own history, how to generally behave, and importantly, where to look for software or files that can be executed without specifying their path, and found with tab auto-completion. We  just saw some examples of these variables above when we queried the <code>$OSTYPE</code> and <code>$SHELL</code> variables to learn about our system. These are variables that are  automatically loaded and assigned when your terminal is opened. Even this behavior can be modified, as we will learn about more below.</p>"},{"location":"tutorials/2.1-shell/#the-path-variable","title":"The <code>PATH</code> variable","text":"<p>The <code>PATH</code> variable is a colon-separated list of filepaths describing the order in which your shell searches directories for executable binaries -- programs that can be called by name from the command line. This is referred to as a  variable because it is a value that is temporarily stored to the name <code>PATH</code>  when you open a terminal. Use <code>echo</code> in your shell to print the value of your <code>$PATH</code> variable. A simple one might look like the example below:</p> <pre><code># show the $PATH variable where software is searched\necho $PATH\n</code></pre> <pre>\n/usr/local/bin:/usr/bin:/usr/sbin:/sbin\n</pre> <p>The example above includes only the locations of system-wide software --  all of the paths are pointing to filepaths that are not in a user space,  i.e., descended from <code>/home/username</code> on Linux or <code>/Users/username</code> on  OSX. By contrast, and as we'll learn more about in the coming weeks,  we will often wish to install 'local' software within our own user spaces. This is software that will be completely isolated from the system software that we definitely do not want to mess up. You can  see in my PATH below that I have additional filepaths including  <code>~/miniconda3/bin</code> and <code>~/gems/bin</code> (notice I'm using <code>~</code> as an alias to reference my <code>/home/deren</code> prefix) that point to directories located inside my home directory where additional programs are stored.</p> <pre>\n/home/deren/gems/bin:/home/deren/miniconda3/bin:/home/deren/miniconda3/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\n</pre>"},{"location":"tutorials/2.1-shell/#the-order-of-path","title":"The order of <code>PATH</code>","text":"<p>Your PATH variable can be modified and this can be very useful for  specifying a particular version of a program when multiple versions are  available. A key example of this is the program <code>python</code>. You can call <code>python</code> from the command line to execute Python scripts. Your system comes pre-installed with a version of Python that is used to run system-wide software. We generally do not want to use this version of Python for  scientific programming. This is because we cannot easily update or change that version without affecting our entire operating system. So, instead,  we will install a separate version of Python on our computers within our  userspace (somewhere within your home directory) and we will tell the PATH variable to use this one instead of the system-wide version. Do not try to do this just yet, we will go through the process of installing Python later. For now, let's focus on how we know which version is being used.</p> <p>You can find the filepath to a program that is located in your PATH by using  the <code>which</code> or <code>whereis</code> commands. This will help to make clear how the PATH variable works. It is ordered. The first directory in the path is searched first, and then the next one, and then the next one. If python occurs in the first directory, then this version will supercede any programs with the name <code>python</code>  occurring in directories that are listed later in the PATH variable. The  <code>which</code> command will show you which precise program is at the top of your PATH, where as the <code>whereis</code> command will list all programs that contain the target in their name and are present in your PATH. I will show the results from my laptop,  since I have multiple versions of <code>python</code> installed.</p> <pre><code>which python\n</code></pre> <pre>\n/home/deren/miniconda3/bin/python\n</pre> <pre><code>whereis python\n</code></pre> <pre>\npython: /usr/bin/python3.8 /usr/lib/python3.8 /usr/lib/python3.9 /usr/lib/python2.7 /etc/python3.8 /usr/local/lib/python3.8 /usr/include/python3.8 /home/deren/miniconda3/bin/python3.8-config /home/deren/miniconda3/bin/python3.8 /home/deren/miniconda3/bin/python\n</pre>"},{"location":"tutorials/2.1-shell/#dotfiles-preferences","title":"Dotfiles (preferences)","text":"<p>Dotfiles are hidden files, generally located in your home directory  (e.g., <code>/home/deren</code> or <code>/Users/deren</code>), and which start with a dot (.) as the first character in their filenames. By default, your shell and operating system typically hide these files from your view, since you don't need to  interact with them unless you are a hacker. </p> <p>Hacking these dotfiles can be really useful. They are files for setting  preferences, and thus modifying them can make for a more pleasurable experience when interacting with your terminal. Here we will edit one or more dotfiles to add some basic customization to your terminal. You are welcome to do further  customizations on your own (we provide some tips below).  Your shell uses these dotfiles by reading and loading the variables in them when the terminal is started. By editing the variables in the files we can customize the behavior of the shell.</p> <p>First, it is important to be sure which type of shell you have, since this  will determine which dotfile name we need to ecdit. If you are in a bash terminal then the file is <code>.bashrc</code>, if you are in the zsh terminal then is it <code>.zshrc</code>. </p> <p>We want to be careful when editing this file, since a bad configuration can prevent your terminal from opening properly. If this happens, do not worry, it can be fixed by opening the dotfile with a different system utility, like a graphical text editor, and changing it back to its default settings. For this reason, let's  start by creating a backup copy of our dotfile by using the <code>cp</code> command. When typing the command below, be sure to specify the appropriate dotfile for your  system -- you can ensure this by typing only the beginning of the filename and  pressing tab to complete the filepath automatically. If the name does not  autocomplete then you have already started to write the path incorrectly. Take note  of where you are located when typing this (e.g., first run <code>pwd</code>) and remember  that the dotfiles are located in your user home directory.</p> <pre><code># ensure I am in my HOME, and then create backup of my .bash_rc\ncd $HOME\ncp .bashrc .bashrc_backup\n</code></pre>"},{"location":"tutorials/2.1-shell/#the-nano-text-editor","title":"The <code>nano</code> text-editor","text":"<p>To edit a dot file, or any file, we will want to use a text editor. When working in a terminal it can be very useful and efficient to use a terminal-based text editor -- a program that opens right inside of the shell and can be used to edit files. A very simple text editor that is usually installed by default is called <code>nano</code>. You can open a file by typing <code>nano filename</code>. Watch the video below for a short tutorial on  using <code>nano</code>. Note that it uses special key-bindings to accomplish some tasks, such as saving and exiting, where you hold down the control key and press another at  the same time.</p>"},{"location":"tutorials/2.1-shell/#editing-your-dotfile","title":"Editing your dotfile","text":"<p>Alert</p> <p>Complete the tasks in this section to earn points for the assignment. </p> <p>For this assessment use <code>nano</code> to edit your shell's dotfile. We will add an  alias, which is a new named variable that will serve as a shortcut to call a  command that is more tedious to type. One that I find indispensible is the alias <code>ll</code> (the lowercase letter L twice). We can create an alias in your dotfile by  editing the file to add the following line to it:</p> Linux/WLS2MacOSX <pre><code># open your shell's dot file in the \nnano ~/.bashrc\n</code></pre> <pre><code># open your shell's dot file in the \nnano ~/.zshrc\n</code></pre> <p>You will see a lot of text in this file. These are the default preference settings as well as many comments that are intended to direct you towards where to make edits when you are making changes to this file. Scroll down until you find a section that defines some aliases. Add the line below to this file and then save and exit.</p> <pre><code>alias ll='ls -l'\n</code></pre> <p>After you have made the edit, you must then re-load the dotfile, which can  be done by either closing and re-opening the terminal, or by calling the following:</p> Linux/WLS2MacOSX <pre><code># open your shell's dot file in the \nsource ~/.bashrc\n</code></pre> <pre><code># open your shell's dot file in the \nsource ~/.zshrc\n</code></pre> <p>Now that the alias is created and loaded when you type <code>ll</code> you should see  the result that we expect to see when typing <code>ls -l</code>, which is to list the  items in a directory with one item per line.</p> <pre><code># call our new alias \nll\n</code></pre> <p>If you get stuck in this section, try watching the videos below for step by step instructions on customizing terminals.</p>"},{"location":"tutorials/2.1-shell/#optional-further-customize-your-terminal","title":"Optional: further customize your terminal","text":"<p>You do not need to follow all of the instructions in these videos, make any changes that you find useful, and feel free to search for other tutorials or videos for tips. Just take note that you must follow instructions for the  appropriate shell type that you have (e.g., bash versus zsh). If you got stuck on the section above, these videos might prove helpful to you.</p> <ul> <li>A video on customizing an OSX bash terminal</li> <li>A video on customizing an OSX zsh terminal</li> <li>A video on customizing a Windows-subsystem-for-Linux-2 terminal</li> </ul> <p>That's it, you can move on to the next tutorial. There is no required submission for this tutorial.</p>"},{"location":"tutorials/2.2-bash/","title":"2.2. bash challenge","text":""},{"location":"tutorials/2.2-bash/#how-to-approach-the-challenge","title":"How to approach the challenge","text":"<p>To solve the following problem sets try to find the answers by learning to use the tools that have been introduced to you. Start by reviewing the lectures and tutorials, then move on to google searching for tutorials on the tools or tasks that are being asked. Also try the class chatroom.  Please do not turn to AI bots as a first approach. I encourage you to challenge yourself to try to understand the answers that  you find. Only then should you optionally turn to a bot to ask if there is a better or faster way to answer the question, and/or to provide an explanation to you of why your answer works.</p>"},{"location":"tutorials/2.2-bash/#the-assignment","title":"The assignment","text":"<p>Your assignment is to create a new Markdown document on GitHub within your  <code>hack-2-shell</code> repository from tutorial 2.0. To do this, navigate to the  repository webpage and find the button that says Add file, and then select \"Create new file\". Name the file <code>assignment.md</code>. This will bring you inside of an interactive Markdown editor where you can type in code and text and also preview it as rendered text.</p> <p>Enter your answers to the problems below into this document using Markdown, while following these instructions: (1) Label each question with a header; (2) write/copy the question as plain text; (3) write a description of how you found a solution to the problem in plain text; and finally (4) write a code-block with your solution. You will use your terminal to find solutions to the problems, and then enter your  answers into the Markdown document. Below you can see an example response.</p>"},{"location":"tutorials/2.2-bash/#example-response","title":"Example Response","text":""},{"location":"tutorials/2.2-bash/#question-x-sort-the-string","title":"Question X: sort the string","text":"<p>Parse the string X into a list of elements and then use the <code>sort</code> command to sort them in reverse alphanumeric order. <code>X=\"apples,bananas,oranges,pancakes\"</code>.</p> <p>I first looked for shell command to sort items and found the man page of <code>sort</code>.  I see that it sorts lines of text, so I realized I need to first split the elements of X  onto separate lines. Therefore, I looked for a string splitting command and found the substitution tool <code>sed</code> to replace \",\" with \"\\n\", which effectively splits a  string into separate lines. This program works on files, so I need to feed my  string X to it as if it were a file. I did this using a pipe from the program  <code>echo</code> which reads text to stdout. Finally, I sorted the substituted text using <code>sort</code> with the <code>-r</code> option to reverse it.</p> <p><pre><code>echo $x | sed 's/,/\\n/g' | sort -r\n</code></pre> <pre><code>pancakes\noranges\nbananas\napples\n</code></pre></p> <p>Note</p> <p>Follow this same format to answer the 4 questions below and save your answers to your  markdown document on github. If you get stuck, ask your fellow classmates for help  on the shared gitter chatroom page.</p>"},{"location":"tutorials/2.2-bash/#1-get-the-data-files","title":"1. Get the data files","text":"<p>Download the following data files from the internet using the curl command:  <code>http://eaton-lab.org/pdsb/test.fastq.gz</code> and <code>http://eaton-lab.org/pdsb/iris-data-dirty.csv</code>. Use the <code>less</code> or <code>zless</code> commands to look at each file. Describe what these commands do.  Finally, use the <code>head</code> command to print the first 5 lines of the file <code>iris-data-dirty.csv</code>.</p>"},{"location":"tutorials/2.2-bash/#2-clean-the-data","title":"2. Clean the data","text":"<p>Use <code>grep</code>, <code>uniq</code>, and <code>sed</code> for this question.  Check that all of the species names are spelled correctly in  the file <code>iris-data-dirty.csv</code>. Also check for missing values stored as NA. Create a new file where mispelled names are replaced with the correct values, and lines with NA are excluded, and save it as <code>iris-data-clean.csv</code>. Use <code>cut</code>, <code>sort</code> and <code>uniq</code> to list the  number of data values there are for each species in the new cleaned data file. Describe your work.</p>"},{"location":"tutorials/2.2-bash/#3-find-a-sequence","title":"3. Find a sequence","text":"<p>Find how many lines in the data file <code>test.fastq.gz</code> start with \"TGCAG\" and end with \"GAG\". Describe your work. </p>"},{"location":"tutorials/2.2-bash/#4-find-a-sequence-chunk","title":"4. Find a sequence chunk","text":"<p>Using <code>grep</code> and other tools if necessary find all lines that contain the sequence \"AAAACCCC\" and for each print that line, the line above it, and two lines below it (so that a 4-line chunk around each search hit is printed). Describe your work. </p> <p>Alert</p> <p>Do not forget to save your results in the Markdown document in your GitHub hack-2-shell repository. We will be sharing these answers with each other in class next week. If you get stuck on the problems above ask for help from your class mates on the gitter chatroom page.</p>"},{"location":"tutorials/2.3-WSL2/","title":"2.3 Tutorial Windows subsystem for Linux","text":"<p>If you are a windows user then you will need to install the Windows Subsystem for Linux (WSL). This is a program that allows you to  install and run a Linux distribution within your Windows system, and access tools like the bash terminal and core utilities. </p> <p>Please follow this tutorial to install WSL using the default installation instructions...:</p> <p>https://learn.microsoft.com/en-us/windows/wsl/install</p> <p>https://learn.microsoft.com/en-us/windows/wsl/setup/environment</p> <p>If you encounter problems with this installation</p> <ul> <li> <p>https://www.youtube.com/watch?v=_fntjriRe48   (Note: Only follow instructions up to 6:20.    Make sure when you create a username that does not have any spaces in it.    Only install WSL2 and Ubuntu 20.04,    do not follow instructions after 6:20 where he installs additional versions.</p> </li> <li> <p>https://www.omgubuntu.co.uk/how-to-install-wsl2-on-windows-10</p> </li> <li>If problems, please join office hours on Friday 1/15 at 3pm, or Tues 1/19 at 10am.</li> </ul>"},{"location":"tutorials/21.0-fastapi/","title":"data science","text":""},{"location":"tutorials/21.0-fastapi/#python-web-servers","title":"Python web servers","text":"<p>Table of Contents: * Table of contents</p>"},{"location":"tutorials/21.0-fastapi/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this tutorial you will:</p> <ul> <li>Have an improved understanding of what a web server is.</li> <li>Be introduced to the concept of decorators in Python.</li> <li>Be able to write and run a web server for an arbirary Python module.</li> <li>Be familiar with the fastAPI Python package.</li> <li>Be introduced to the heroku web app service.</li> </ul>"},{"location":"tutorials/21.0-fastapi/#requirements","title":"Requirements","text":"<p>Install the fastAPI and  uvicorn Python packages using conda.  The first is used to create a webserver and/or API and the second is used to run a webserver, to communicate information between your Python code  and a network (e.g., localhost:8888).</p> <pre><code>conda install fastapi uvicorn -c conda-forge\n</code></pre>"},{"location":"tutorials/21.0-fastapi/#extending-the-records-package","title":"Extending the records package","text":"This tutorial builds upon completion of the instructions in notebook 12.0,  so you should first complete that assignment which will instruct you to  create a Python package called 'records'.  <p>In the last tutorial you created a Python package called <code>records</code>. Here  we are going to create a new entry-point to this package. Whereas previously we have created entry points as command line interfaces (CLIs) -- where you can  call a function from your terminal -- here we will instead be creating a web server entry point, where functions can be executed through your  web browser. Technically, this is called a web server gateway interface (WSGI; pronounced like whiskey).</p> <p>Our web server will be written in a module called <code>app.py</code>. Create a new  empty file at <code>records/records/app.py</code> so that your package looks like the file tree below.</p> <pre><code>records/\n\u251c\u2500\u2500 setup.py\n\u2514\u2500\u2500 records/\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 app.py    \n    \u2514\u2500\u2500 records.py\n</code></pre>"},{"location":"tutorials/21.0-fastapi/#your-first-web-app","title":"Your first web app","text":"<p>In the <code>app.py</code> file enter the following code, which is copied from the  introductory tutorial from fastAPI. If at any point you get stuck in this tutorial, try reading the fastapi docs for  more information. This is a really well written library with really nice documentation.</p> <p>In this tutorial we will incrementally build up our web app, starting with  a very simple example and becoming more complex. Let's start with the  typical simple exercise of a function that says \"hello world\". </p> <pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\ndef root():\n    return {\"message\": \"Hello World\"}\n</code></pre> <p>This code is similar to Python scripts we have seen before, but it includes a new feature you haven't seen before, called a decorator. Decorators are a feature in Python that start with the @ character, and are written on the line directly above a function definition. Decorators modify the way  a function runs. That is all you really need to know about it for now.</p> <p>In this case the decorator is <code>@app.get('/')</code>, meaning it is calling the  function <code>get()</code> from the the FastAPI class instance <code>app</code>, with the argument <code>'/'</code>. Since this script is pretty short, let's walk through it line-by-line.</p> <ol> <li> <p>First we imported the FastAPI Class object from the fastapi package.</p> </li> <li> <p>Next we created an instance of this class and named in <code>app</code>. </p> </li> <li> <p>In the final step we created a function called <code>root()</code> that simply returns a dictionary with the key \"message\" and value \"Hello World\". The only tricky  thing here is the decorator. The decorator is designating the path  where the returned result of the <code>root()</code> function should be sent. It will be sent to the root location of the server address (<code>/</code>). As an example, we will be running a local server (just like we do when running a jupyter notebook  server) and it will serve to <code>localhost:8000</code>, which you will view in your  web browser. When I say this result will be routed to <code>/</code>, what I really  mean is it will be routed to localhost:8000<code>/</code>.</p> </li> </ol>"},{"location":"tutorials/21.0-fastapi/#running-the-app","title":"Running the app","text":"<p>To run the app we now just need to call a server tool and point it to the corrent entry point in the code where the app exists. This is a similar  syntax to when we pointed to a specific function in the setup.py file to  define a CLI entry point.</p> <p>Here we will be using the <code>uvicorn</code> server, and call it from the terminal as a command line tool. Like other servers we've run before, you can just leave this running in the corner of your screen until you want to stop it. As long as it is running your server will be accessible. Here we give it the option <code>--reload</code> which means that as we make changes to our code it will automatically reload to update the server.</p> <pre><code># called from within records/ repo directory.\n# argument points to records folder, app.py file, app instance\nuvicorn records.app:app --reload\n</code></pre> <pre>\nINFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\nINFO:     Started reloader process [488393] using watchgod\nINFO:     Started server process [488395]\nINFO:     Waiting for application startup.\nINFO:     Application startup complete.\n</pre> <p>Now open your browser to the address shown by the server, likely  localhost:8000. You should see a single JSON result showing \"message\", \"Hello World\". Success. Your Python function is  writing its results to this web address. </p>"},{"location":"tutorials/21.0-fastapi/#so-what","title":"So what?","text":"<p>In this simple example we can see that the returned value of the  function <code>root()</code> is printed to the local network address on port 8000 at the <code>/</code> (root) path. Very simple, right? But why is this useful? </p> <p>Well, following  from this example, we could imagine writing any arbitrary Python code to  return any kind of results to a webpage. This becomes especially powerful  when we begin to use the web browser to receive inputs as well.  This can now replace the need for a command-line interface. Furthermore, if the web server is made public, then any user could interact with your program from any browser.</p>"},{"location":"tutorials/21.0-fastapi/#restful-api","title":"RESTful API","text":"<p>Let's go to the next step: adding arguments to our functions.  To do this you just add need to add arguments to the function being served  as the endpoint. For example, our root function can now take an optional  <code>name</code> argument with a default value of 'person'. Modify your code to  include the following updates:</p> <pre><code>from fastapi import FastAPI\n\napp = FastAPI()\n\n@app.get(\"/\")\ndef root(name=\"person\"):\n    return {\"message\": f\"Hello World to you, {name}\"}\n</code></pre> <p>Save the app.py file after making this change and you should see your  browser update automatically. Now try modifying the URL to enter a params argument to the root path like in ths example:  localhost:8000/?name=Phylo.</p>"},{"location":"tutorials/21.0-fastapi/#serving-json-data","title":"Serving JSON data","text":"<p>Great. Let's extend our script with even further. In this case we will return  JSON formatted data from a database, just like the GBIF API. For simplicity we will just use a pandas dataframe to represent the database, but more  commonly web sites/servers will use a different kind of database, like SQL, which is faster for getting individual results from a very large database.  But that is beyond the scope of our current interest, and pandas will work fine for now. Add code to your script so it looks like the example below:</p> <pre><code>import json\nimport pandas as pd\nfrom fastapi import FastAPI\n\n# create the app as an instance of the fastAPI class\napp = FastAPI()\n\n# load the database once when the server starts\nDATA = pd.read_csv(\n    \"https://eaton-lab.org/data/iris-data-dirty.csv\",\n    names=[\"trait1\", \"trait2\", \"trait3\", \"trait4\", \"species\"],\n)\n\n# create a root endpoint that say's hello\n@app.get(\"/\")\ndef root(name=\"person\"):\n    \"returns a hello world message in JSON\"\n    return {\"message\": f\"Hello World to you, {name}\"}\n\n# create another endpoint for returning iris data\n@app.get(\"/iris\")\ndef iris(species=None):\n    \"\"\"\n    returns iris data in JSON with option to subselect a species\n    \"\"\"\n    # get subset or full data\n    if species is not None:\n        data = DATA.loc[DATA.species == species, :]\n    else:\n        data = DATA\n\n    # convert to JSON and return to endpoint\n    sdata = data.to_json(orient=\"index\")\n    jdata = json.loads(sdata)\n    return jdata\n</code></pre> <p>We have now added a function called <code>iris()</code> that takes a species argument and uses it to optionally select a subset of the pandas dataframe containing the iris data set. The results are then converted to JSON format and returned.</p> <p>After making these changes and saving the app.py file, visit  localhost:8000/iris to see all of the data records,  and also try entering params arguments such as  localhost:8000/iris?species=Iris-setosa to see only a subset of records returned that match your query.  You just created a REST API!</p>"},{"location":"tutorials/21.0-fastapi/#api-documentation","title":"API documentation","text":"<p>One of the coolest features of fastAPI is that it automatically generates documentation for your API as you write it. Simply visit the address localhost:8000/docs and you can see all of the endpoints for your API, including the parameters that they support, and you can even  click on Try it out to enter the parameters and see the results. Such a cool feature, I wish the GBIF API supported this!</p>"},{"location":"tutorials/21.0-fastapi/#assessment","title":"Assessment","text":"Commit and push the new app.py file to your GitHub records repo after     you have tested it and are able to successfully run the api requests     in the examples above."},{"location":"tutorials/21.0-fastapi/#a-web-app-for-any-package-or-module","title":"A web app for any package or module","text":"<p>Let's now create a web app that will make this code publicly accessible  instead of only being available on localhost. </p>  This part of the tutorial is optional, and a bit complicated, so you do not  need to run it yourself -- but you are welcome to.   <p>I think this final step is worth walking through, even if it is complex,  just so you have an idea of the steps involved with making your API  globally accessible from a public URL. There are several ways to deploy your Python code to run on a public server, but a great option is  to use the free service heroku.</p> <p>You can find instructions to install heroku for either Linux  (WSL2) or OSX at the following link. Unfortunately this tool cannot be installed using conda. My instructions  for using heroku below are quite similar to those from the example in their  getting-started docs. So if you get stuck be sure to take a look there as well. You will need to create a heroku login on their website. It is all free.  (Again, this is optional for now.)</p>"},{"location":"tutorials/21.0-fastapi/#setup-for-heroku","title":"Setup for heroku","text":"<p>We will need to add three additional files so that your repo looks like  the following file tree:</p> <pre><code>.\n\u251c\u2500\u2500 Procfile\n\u251c\u2500\u2500 records\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 app.py\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 records.py\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 runtime.txt\n</code></pre> <p>We first need to create a file called <code>Procfile</code> that will tell heroku how  to run the server. This simply contains the command we called to run uvicorn;  here I tell it some additional details that I found online by googling  'uvicorn on heroku': <pre><code># Procfile\nweb: uvicorn records.app:app --host=0.0.0.0 --port=${PORT:-5000}\n</code></pre></p> <p>Then create a file called requirements.txt, which tells the server how to install all of the Python dependencies using <code>pip</code>. This simply lists the  required packages one per line. List everything in the app that is not  from the Python standard library: <pre><code># requirements.txt\nrequests\npandas\nfastAPI\nuvicorn\n</code></pre></p> <p>Then we need to create a runtime.txt file that says which version of  Python to use: <pre><code># runtime.txt\npython-3.7.10\n</code></pre></p>"},{"location":"tutorials/21.0-fastapi/#deploy-your-app-to-a-public-url","title":"Deploy your app to a public URL","text":"<p>Now you can call the <code>heroku</code> command line tool from within your package to create a new git remote that will host your heroku app. Remember, a  remote is a location where a copy of your repo is stored. We usually use  GitHub as a remote (and refer to it as origin), but here we will be using  heroku as a remote. To create this new remote, call the heroku create  command from within your package, which will assign your app a  random name unless you provide one.</p> <pre><code># login to heroku (opens your browser)\nheroku login\n</code></pre> <pre><code># create a heroku app named 'hack-records' (if name is available)\nheroku apps:create hack-records\n</code></pre> <p>Great, now use <code>git add</code> and <code>git commit</code> to commit all changes to your repo on the heroku remote, including the addition of your new Procfile and  requirements.txt, and runtime.txt. You can also push these changes to your GitHub remote (origin) if you want. No harm.</p> <p><pre><code># push updates to your heroku remote main branch\ngit add records/records.py records/app.py      # stage changed file\ngit add requirements.txt runtime.txt Procfile  # stage new files\ngit commit -m \"heroku app created\"             # commit changes\ngit push heroku main                           # push to heroku remote\n</code></pre> When you push heroku will begin to install the app on the remote and will  print some information like the following:</p> <pre>\nEnumerating objects: 10, done.\nCounting objects: 100% (10/10), done.\nDelta compression using up to 8 threads\nCompressing objects: 100% (6/6), done.\nWriting objects: 100% (10/10), 2.04 KiB | 1.02 MiB/s, done.\nTotal 10 (delta 0), reused 0 (delta 0)\nremote: Compressing source files... done.\nremote: Building source:\nremote: \nremote: -----&gt; Building on the Heroku-20 stack\nremote: -----&gt; Python app detected\nremote: -----&gt; Installing python-3.6.13\nremote: -----&gt; Installing pip 20.1.1, setuptools 47.1.1 and wheel 0.34.2\nremote: -----&gt; Installing SQLite3\nremote: -----&gt; Installing requirements with pip\nremote:        Collecting requests\nremote:          Downloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\nremote:        Collecting pandas\nremote:          Downloading pandas-1.1.5-cp36-cp36m-manylinux1_x86_64.whl (9.5 MB)\nremote:        Collecting fastAPI\nremote:          Downloading fastapi-0.63.0-py3-none-any.whl (50 kB)\nremote:        Collecting uvicorn\nremote:          Downloading uvicorn-0.13.3-py3-none-any.whl (45 kB)\nremote:        Collecting urllib3&lt;1.27,&gt;=1.21.1\nremote:          Downloading urllib3-1.26.3-py2.py3-none-any.whl (137 kB)\nremote:        Collecting certifi&gt;=2017.4.17\nremote:          Downloading certifi-2020.12.5-py2.py3-none-any.whl (147 kB)\nremote:        Collecting idna&lt;3,&gt;=2.5\nremote:          Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\nremote:        Collecting chardet&lt;5,&gt;=3.0.2\nremote:          Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\nremote:        Collecting python-dateutil&gt;=2.7.3\nremote:          Downloading python_dateutil-2.8.1-py2.py3-none-any.whl (227 kB)\nremote:        Collecting numpy&gt;=1.15.4\nremote:          Downloading numpy-1.19.5-cp36-cp36m-manylinux2010_x86_64.whl (14.8 MB)\nremote:        Collecting pytz&gt;=2017.2\nremote:          Downloading pytz-2021.1-py2.py3-none-any.whl (510 kB)\nremote:        Collecting starlette==0.13.6\nremote:          Downloading starlette-0.13.6-py3-none-any.whl (59 kB)\nremote:        Collecting pydantic&lt;2.0.0,&gt;=1.0.0\nremote:          Downloading pydantic-1.7.3-cp36-cp36m-manylinux2014_x86_64.whl (9.2 MB)\nremote:        Collecting h11&gt;=0.8\nremote:          Downloading h11-0.12.0-py3-none-any.whl (54 kB)\nremote:        Collecting typing-extensions; python_version &lt; \"3.8\"\nremote:          Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\nremote:        Collecting click==7.*\nremote:          Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\nremote:        Collecting six&gt;=1.5\nremote:          Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\nremote:        Collecting dataclasses&gt;=0.6; python_version &lt; \"3.7\"\nremote:          Downloading dataclasses-0.8-py3-none-any.whl (19 kB)\nremote:        Installing collected packages: urllib3, certifi, idna, chardet, requests, six, python-dateutil, numpy, pytz, pandas, starlette, dataclasses, pydantic, fastAPI, h11, typing-extensions, click, uvicorn\nremote:        Successfully installed certifi-2020.12.5 chardet-4.0.0 click-7.1.2 dataclasses-0.8 fastAPI-0.63.0 h11-0.12.0 idna-2.10 numpy-1.19.5 pandas-1.1.5 pydantic-1.7.3 python-dateutil-2.8.1 pytz-2021.1 requests-2.25.1 six-1.15.0 starlette-0.13.6 typing-extensions-3.7.4.3 urllib3-1.26.3 uvicorn-0.13.3\nremote: -----&gt; Discovering process types\nremote:        Procfile declares types -&gt; web\nremote: \nremote: -----&gt; Compressing...\nremote:        Done: 86.9M\nremote: -----&gt; Launching...\nremote:        Released v3\nremote:        https://hack-records.herokuapp.com/ deployed to Heroku\nremote: \nremote: Verifying deploy... done.\nTo https://git.heroku.com/hack-records.git\n * [new branch]      main -&gt; main\n</pre> <p>The app is now live! Following from instructions in the heroku documentation, we can tell it to use one \"worker\" to run our server (I think on the free  tier you are limited only a few workers total).</p> <pre><code># scale how many concurrent requests your server can handle\nheroku ps:scale web=1\n</code></pre> <p>Now you should be able to visit your app at https://{app-name}.herokuapp.com. Check out my working example for this tutorial. We can see that there are  working endpoints to run each of our defined functions, and even an automated documentation endpoint.</p> <ul> <li>root: https://hack-records.herokuapp.com/</li> <li>docs: https://hack-records.herokuapp.com/docs</li> <li>iris: https://hack-records.herokuapp.com/iris</li> <li>iris query \"species=Iris-setosa\": https://hack-records.herokuapp.com/iris?species=Iris-setosa</li> </ul>"},{"location":"tutorials/21.0-fastapi/#a-route-for-your-code","title":"A route for your code","text":"<p>If you were able to get all of that to work then congratulations, amazing! Here's one more challenge for you... you could add another function to your app.py script that will return results of a request to your Records class object. </p> <p>How would you go about this? I would start by importing your class from  the records module, and then creating a function that returns its json result  to a specific endpoint. Here I use the <code>get_single_record()</code> function for now since it is much faster than querying all records.</p> <pre><code># example code to add an endpoint to run the records.Records function\nfrom records.records import Records\n\n@app.get(\"/gbif\")\ndef gbif(genusKey=3171670, year=\"2000,2020\"):\n    \"returns a specific gbif query as JSON\"\n    rec = Records(genusKey=genusKey, year=year)\n    return rec.get_single_record()\n</code></pre> <p>As you can see from this example, we could create a public endpoint to  run any arbitrary Python code. This is the reason that Python is used so widely for web development as a backend server. The only thing left to do to create fancy looking web or mobile app is to design the front-end which includes things like buttons or forms to accept user input which  could be sent to your API to get a response. Pretty cool!</p>"},{"location":"tutorials/3.0-git-init/","title":"Learning the <code>git</code> command line tool","text":""},{"location":"tutorials/3.0-git-init/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this tutorial you should be familiar with  git terminology, and be able to make changes to git repositories using the command line git program. This tutorial will likely take 15-30 minutes to complete. </p>"},{"location":"tutorials/3.0-git-init/#introduction","title":"Introduction","text":"<p>The <code>git</code> program is a powerful tool not only for programmers but also for any scientist interested in keeping data and analysis scripts synced over multiple machines, and shared online. But learning <code>git</code> can be intimidating to many beginners. Many tutorials are aimed at developers working in large groups, where  the collaborative workflows can seem overly complex and unnecessary to  coders who are mostly writing code on their own, at least to begin with.  But learning to use <code>git</code> and GitHub is still useful even when  writing code on your own, and, it is actually much simpler  to learn and use in this context. We will start simple and work up to more complex workflows. By the end of this session you should be comfortable with creating new remote repos on GitHub,  syncing them to your local computer, and pushing changes back  to the remote repo using <code>git</code>.</p> <p>Here I will try to provide a simple introduction to <code>git</code>, and will also  link to other resources online that I have found useful. Please see the  official git book if you get stuck,  or want to pursue further reading.</p>"},{"location":"tutorials/3.0-git-init/#setting-up-git-for-remote-authentication","title":"Setting up git for remote authentication","text":"<p>GitHub is a very powerful, industry standard repository for source code, which means that they take access control very seriously. Until recently it was enough to authenticate with a username and password, but it turns out this is not a very safe mechanism for authentication. Passwords can be stolen or cracked, so more intricate authentication mechanisms are becoming more prominent (e.g. 2 factor auth, as you might use for accessing CU systems). In the case of GitHub we need to create a \"Personal Access Token\" (PAT) to use as a more secure password. The steps for this are documented on the GitHub page for managing your personal access tokens, and they are somewhat complicated, which is why we are walking through it together in class.</p> <ul> <li>Go to your GitHub home page</li> <li>Click on your avatar image in the upper right hand corner</li> <li>Choose Settings-&gt;Developer settings (all the way at the bottom)</li> <li>Then choose Personal access tokens-&gt;Tokens (classic)</li> <li>Choose Generate New Token (classic)</li> <li>Add a Note (you might choose PDSB-2025 or something related to class)</li> <li>Set Expiration to 'No expiration'</li> <li>Check the boxes to select all available Scopes</li> <li>Then click Generate token</li> <li>This will take you to a new page which shows your token which will be a very long string of numbers and letters. Copy this and save it!</li> </ul> <p>Alert</p> <p>Action: Save your PAT somewhere secure, you won't be able to access it again.</p> <p>Now that we have our PATs we can move forward with cloning a repo, making changes and pushing the changes to GitHub.</p>"},{"location":"tutorials/3.0-git-init/#installation","title":"Installation","text":"<p>Open a terminal and type <code>git</code>. If it is not yet installed your shell will prompt you to install it. If you are on Linux (or WSL2) it will be installed already.</p>"},{"location":"tutorials/3.0-git-init/#git-is-specific-to-your-location","title":"<code>git</code> is specific to your location","text":"<p>When you create a git repository, or convert an existing folder into one, all this means is that the folder will contain a hidden directory named <code>.git/</code>. This directory is where <code>git</code> will store  all of the information it needs to do its work. You will never need to look inside of that folder. Instead, you will use commands from the program <code>git</code> to programmatically tell it how to operate. </p> <p>To use <code>git</code> on a repository, you must be located in that repo. In other words, you must <code>cd</code> from your terminal into that location. If you try a <code>git</code> command from a folder that is not a  git repo (i.e., does not contain a <code>.git/</code> subfolder) then <code>git</code> will raise an error. Let's try this now. We will call the <code>git status</code> command from our $HOME folder, which itself should not be a <code>git</code>  repository. This should raise the following error.</p> <pre><code># move to home folder and call git status\ncd ~\ngit status\n</code></pre> <pre>\nfatal: not a git repository (or any of the parent directories): .git\n</pre> <p>Always read an error message carefully when you receive it. It is  telling us that we are not in a git repo.</p>"},{"location":"tutorials/3.0-git-init/#setup-git","title":"Setup git","text":"<p>The program <code>git</code> is designed for collaboration. For this reason, it wants to keep track of who makes changes to any given file. So before we start using it we need to configure it to tell it who we are. This is done  using the <code>git config</code> commands. You can set different configurations  for specific git repositories, and/or you can also set a global configuration. In general, you will only need to set the global  config, and only need to do this once. The global settings are  stored in <code>~/.gitconfig</code> and can be set with the command below.  You can read more about git configuration in the  git book chapter 1.6.</p> <p>Let's first check our existing global configuration.  This shows the config of your username and email address, and shows the file location where it is stored. <pre><code>git config --list --show-origin --global\n</code></pre> If you have not yet configured git locally it will look like this:</p> <pre>\nfatal: unable to read config file '/home/jovyan/.gitconfig': No such file or directory\n</pre> <p>Because my git is already configured it looks like this, and this will be what we'll do for you in the first part of this exercise:</p> <pre>\nfile:/home/deren/.gitconfig     user.email=de2356@columbia.edu\nfile:/home/deren/.gitconfig     user.name=Deren\nfile:/home/deren/.gitconfig     core.editor=nano\n</pre> <p>To set your global configuration run the following and enter your name and email in place of mine. You can choose any name and email that you want, but you probably want to set it to the same as your GitHub profile. If there is a space in your name then you must surround it with quotes like in the example below. <pre><code>git config --global user.name \"John Doe\"\ngit config --global user.email johndoe@example.com\n</code></pre></p> <p>I also prefer to set the default code editor that git will use  when it asks you to make changes to a file (something that  git does when it encounters a conflict). This needs to be set  to an editor that is installed on your system. I prefer to set  a fast and simple terminal based editor for this, such as <code>nano</code>. <pre><code>git config --global core.editor nano\n</code></pre></p>"},{"location":"tutorials/3.0-git-init/#commit-changes-to-a-repo","title":"Commit changes to a repo","text":""},{"location":"tutorials/3.0-git-init/#cloning-a-git-repo","title":"Cloning a git repo","text":"<p>Let's clone our first repository. This creates an exact copy of a  remote repo onto your local machine. We will start by cloning the repo you created in the last session, called hack-2-shell. To clone a repository you can go to its GitHub page online and click on the  button labeled Code  to select the URL. (For now, we will select the first option, HTTPS, but later we will switch to using the SSH option.) When we clone this repo it will create a copy into your current  directory, so beware of your location before doing so. Let's  <code>cd</code> into our home directory and create a new directory called  hacks/ where you can store all your repos for this class.</p> <pre><code># cd into $HOME\ncd $HOME\n\n# make a new directory here for storing class repos\nmkdir hacks/\n\n# cd into the hacks/ dir\ncd hacks/\n</code></pre> <p>Finding the link for a github repo you are interested in is very easy, just navigate to the repository, click the green \"Code\" button and copy the link provided (it's easier and more fool-proof than trying to type it in from memory). Practice by navigating to your own <code>hack-2-shell</code> repository and copying the link directly from there.</p> <pre><code># clone 'hack-2-shell' (replace USERNAME with YOUR git username)\n# Pasting the link you just copied here should look identical\ngit clone https://github.com/USERNAME/hack-2-shell\n\n# cd into hack-2-shell repo\ncd hack-2-shell/\n</code></pre>"},{"location":"tutorials/3.0-git-init/#edit-the-readme-file","title":"Edit the README file","text":"<p>Let's make a change to the README file. To do this, we'll use the simple <code>nano</code> text editor to open the file, write additional text into it, and then save and close the text editor. Remember, <code>nano</code> requires you to enter a set of hotkey commands to do things like save and  close. These are listed along the bottom of the editor when it is  open. The most important one is labeled Exit.  For me, Exit is ^X, which means hold the control key  and press X (this may vary on Mac or Windows, maybe it is the Alt or Windows key, etc.). This will ask you if you  want to save any changes, and then it will close the editor. </p> <p>Alert</p> <p>Action: Edit the README.md file to add a link (using Markdown) to any videos or webpages that you used when creating your dotfiles.  Add a description, such as \"I followed instructions from this video to edit my  .zshrc file.\"</p> <pre><code># open the README file in the nano text editor\nnano README.md\n\n# remember you can exit nano by entering the 'Exit'\n# hotkey commands listed at the bottom of the editor.\n</code></pre>"},{"location":"tutorials/3.0-git-init/#sync-to-the-remote","title":"Sync to the remote","text":"<p>We will now sync these changes to the remote repo on GitHub. This involves three steps, which is all you need to memorize to become a <code>git</code> user. These are the core basic commands:  <code>add</code>, <code>commit</code>, and <code>push</code>. Run the commands below to sync your changes to the remote. In the next section we will break this  down step by step to better comprehend what each step is doing. The final step will sync your changes to GitHub, and will require you to enter your username and password. After it syncs, refresh  your repo page on GitHub to see if the changes appear.</p> <pre><code>git add ./README.md\ngit commit -m \"added links to README file\"\ngit push\n</code></pre> <p>Now, the first time you <code>push</code> a change to a cloned repository you must authenticate. It will prompt you for your username and password. Enter your username at the following prompt (for example <code>iao2122</code>):</p> <pre>\nUsername for 'https://github.com': iao2122\n</pre> <p>Then when prompted for your password you must copy your auth token (which we created earlier) and paste it in here. The paste action won't appear to do anything because the password is masked:</p> <pre>\nPassword for 'https://iao2122@github.com':\n</pre> <p>If it succeeds you'll see a message like this, confirming the authorization and executing the transaction:</p> <pre>\nEnumerating objects: 5, done.\nCounting objects: 100% (5/5), done.\nWriting objects: 100% (3/3), 270 bytes | 270.00 KiB/s, done.\nTotal 3 (delta 0), reused 0 (delta 0), pack-reused 0\nTo https://github.com/iao2122/hack-2-shell.git\n   5827f76..608da6e  main -&gt; main\n</pre> <p>Alert</p> <p>Remember: The process of authenticating with your username and PAT only ever needs to be done once per cloned github repo, so you won't have to do this over and over again, but you will have to do it again when you clone a new repository, so it's good to know how it works.</p>"},{"location":"tutorials/3.0-git-init/#essential-git-commands","title":"Essential git commands","text":""},{"location":"tutorials/3.0-git-init/#git-status","title":"git status","text":"<p>In addition to the three core <code>git</code> commands above, you will  also want to know the essential command <code>git status</code>. This  will tell you at any given time which of the three commands above you  should call given the changes that have been made to your files. Since we just pushed our changes, there should be no differences between our local repo and the remote. Thus, when we call  <code>git status</code> we should see the following:</p> <pre><code>git status\n</code></pre> <pre>\nOn branch main \nYour branch is up to date with 'origin/main'.\n\nnothing to commit, working tree clean\n</pre> <p>So what does this mean?  First, it is telling us which branch we are on (main).  Here, we did not create a separate branch on which to make our  changes, instead we are still currently on the main branch. As I mentioned in class, this is not the \"best practice\"  when working on a collaborative project, but when you are  working alone it usually fine, and it is a much simpler framework for initially learning git. </p> <p>Next, it says that our branch is up to date with 'origin/main'. Here the name 'origin' is referring to the remote copy of this repository, the  one that is on GitHub. This is easy to remember if you think of  'origin' as referring to the place where the repo was first created.</p> <p>Finally, it says there is nothing to commit. This makes sense, since we just pushed our changes to the remote, so they are already synced. Below we'll make some changes to files and see how this message changes.</p>"},{"location":"tutorials/3.0-git-init/#git-add","title":"git add","text":"<p>The command <code>git add</code> is the first in our series of three commands.  It is used to tell <code>git</code> that a file has been updated or added to the list of files to be tracked. It the git lingo this is means the file  has been \"staged for commit\". </p> <p>Before we learn more, let's create  three new files that we will use throughout the next few sections to demonstrate what it looks like for files to be at different  stages along the three-step process of syncing.</p> <pre><code># create three new file in this directory\necho \"hello world\" &gt; ./file-1.md\necho \"hello world\" &gt; ./file-2.md\necho \"hello world\" &gt; ./file-3.md\n</code></pre> <p>OK, we've created three new files inside of our git repo folder, each with a different name and containing the text \"hello world\". Does this mean that these files are now being tracked by <code>git</code>? The answer is no. You can have files in a git repo folder that are not added to it, and thus are not going to be synced  between machines. These are termed untracked files. Let's check <code>git status</code> to see this.</p> <pre><code># git status will now show something different.\ngit status\n</code></pre> <pre>\nOn branch main\nYour branch is up to date with 'origin/main'.\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n    file-1.md\n    file-2.md\n    file-3.md\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n</pre> <p>You can see the output has now changed, there is a new section  called \"Untracked files\" that shows the name of the three files  that are not being tracked. We could leave these files as untracked  if we wanted, but let's imagine we want some of these files to be  part of our git repo. Reading the comment under the Untracked files section above we can see that it is giving us instructions for  how to start tracking these files. It says to use <code>git add</code>.  Let's do this for two of the files, file-1.md and file-2.md. </p> <p><pre><code># add two files to the local git repo\ngit add file-1.md\ngit add file-2.md\n</code></pre> Now we'll call <code>git status</code> again to see what has changed.</p> <pre><code>git status\n</code></pre> <pre>\nOn branch main\nYour branch is up to date with 'origin/main'.\n\nChanges to be committed:\n  (use \"git restore --staged &lt;file&gt;...\" to unstage)\n    new file:   file-1.md\n    new file:   file-2.md\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n    file-3.md\n</pre> <p>Looking at the first few lines of this message,  you might ask \"why does it say that my branch is up to date with  origin/main if I just made changes to this repo? Shouldn't that mean that they are out of sync?\". The answer is: not yet. Although  we've edited some files in this repo, we haven't yet committed those changes, and so the changes are considered temporary for now.</p> <p>You can also see that a new category has appeared in the status report, in addition to Untracked files we now also see a list of files  under Changes to be committed. This means that  <code>git</code> is now tracking these files -- it knows they are different (or new). The name of this new section hints at what we should do next. These have changes that need to be committed. So let's commit them. </p>"},{"location":"tutorials/3.0-git-init/#git-commit","title":"git commit","text":"<p>You can think of a commit as a timestamp. To the extent <code>git</code> works like a time machine, we are saving a point in time that you might  later want to rewind to. A commit at this stage will save the changes that have been made to all files listed in the to be committed category (i.e., we don't need to call commit separately for every call of add). It should be accompanied by a short but informative message about  what the commit includes, by using the <code>-m</code> option:</p> <pre><code># commit changes with a message about what it entails\ngit commit -m \"added files 1 and 2.\"\n</code></pre> <p>Congratulations, you've made your first commit using <code>git</code>.  Your local repo now has a time-stamped version of this new state. Let's take a look at the status again to see what this looks like.</p> <pre><code>git status\n</code></pre> <pre>\nOn branch main\nYour branch is ahead of 'origin/main' by 1 commit.\n  (use \"git push\" to publish your local commits)\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n    file-3.md\n\nnothing added to commit but untracked files present (use \"git add\" to track)\n</pre> <p>There is now a new status near the top of the message, telling us that our branch is ahead of origin/main by 1 commit. And once again it tells us what to do about it: use git push to publish our local commits.</p>"},{"location":"tutorials/3.0-git-init/#git-push","title":"git push","text":"<p>This final command is used to push our commits to the remote repo. After this step the new files and changes that we've made will appear on GitHub when we visit the repo online. Given our current setup,  it will ask you to enter your GitHub username and password to  authenticate that you have permission to push these changes to the remote repo. We will learn later how to enable password-less  authentication. If we had created a separate branch we could  specify the name of the branch that we want to push here as well. By default it will push to origin main. The output that it writes below is not very interesting.</p> <pre><code># we could write `git push origin main` to be more explicit.\ngit push\n</code></pre> <pre>\nUsername for 'https://github.com': hackers-test\nPassword for 'https://hackers-test@github.com': \nEnumerating objects: 4, done.\nCounting objects: 100% (4/4), done.\nDelta compression using up to 8 threads\nCompressing objects: 100% (2/2), done.\nWriting objects: 100% (3/3), 320 bytes | 320.00 KiB/s, done.\nTotal 3 (delta 0), reused 0 (delta 0)\nTo https://github.com/hackers-test/hack-2-shell\n   90cdd7d..4a1782a  main -&gt; main\n</pre> <p>At this stage you can call <code>git status</code> again and you will see that our branch is once again 'up to date' with origin/main. This is  true even though file-3.md exists as an untracked file in your  local repo directory. It is fine to have some files that you keep locally that you do not want to sync, in fact it is very common. </p>"},{"location":"tutorials/3.1-markdown/","title":"Using Markdown","text":""},{"location":"tutorials/3.1-markdown/#markdown","title":"Markdown","text":"<p>Markdown is a simple markup language. It used to write formatted text in HTML, the language of the web,  but without the need to learn all of the tags involved in HTML. For example, to create large bold font  like in the header above, followed by an italic word, and then a normally formatted sentence, we could  write it in HTML like the following:</p> <p><pre><code>&lt;h2&gt;Markdown&lt;/h2&gt;\n&lt;i&gt;Markdown&lt;/i&gt; is a simple programming language.\n</code></pre> Or, we could write the same thing more easily using Markdown:</p> <p><pre><code>## Markdown \n*Markdown* is a simple programming language.\n</code></pre> The Markdown example is easier to read and write, and describes the  same rendered result as if we had written HTML. </p>"},{"location":"tutorials/3.1-markdown/#learning-objectives","title":"Learning objectives","text":"<p>This tutorial is intended to refresh your memory about the usage of Markdown --  which we briefly introduced previously within a jupyter notebook --  and to provide links to further instructions that you can easily search when you need to use Markdown. </p>"},{"location":"tutorials/3.1-markdown/#why-use-markdown","title":"Why use markdown?","text":"<p>There are several other languages similar to markdown, such  as restructuredText (rst), but markdown is generally the most popular and easy to use. Markdown is particularly useful for writing documentation, or notes about  code on GitHub, since GitHub automatically renders markdown documents  into rendered (formatted) text. For this reason, the README file that is  standard on every GitHub repo is usually written in Markdown.</p>"},{"location":"tutorials/3.1-markdown/#readme-files","title":"README files","text":"<p>Remember, your first GitHub tutorial (hello-world) had you create a new branch to edit the README file, and then merge that branch with your main. The README file can be used for a variety of purposes. Generally, it is  meant as a place for introducing the repo -- telling visitors what the code is for, and how to use it. But you can also use it as a place to write  yourself notes, or really for any purpose you want. </p>"},{"location":"tutorials/3.1-markdown/#learning-markdown","title":"Learning Markdown","text":"<p>Start by reading a tutorial, and then get your hands dirty and start writing. There are many online tools where markdown text is instantly rendered side-by-side with your code, which is great for testing. Try out the following app https://stackedit.io/app. You can even use Markdown inside our course chatroom (gitter). You can learn more at the following two links:</p> <ul> <li>Markdown cheat sheet</li> <li>Markdown self test</li> </ul>"},{"location":"tutorials/3.1-markdown/#formatting-code-block-with-markdown","title":"Formatting code block with markdown:","text":"<p>You can format a code block in Markdown -- meaning that it will apply specific styling to the font and color of text to look nice for a computer language -- by writing the code inside of blocks delimited with three backticks (ignore the forward slashes below).</p> <pre><code>```python\nx = 3\nprint(x)\n```\n</code></pre> <p>See here for more details.  Try it out in the scratchpad link above. Notice how if you change the name of the language the \"syntax highlighting\" can change slightly. Try the following code in the stackedit app and notice the difference when you change \"language\" to python, r, perl, or bash.</p> <pre><code>x = 3\ny = \"string\"\nprint(x)\nprint(y)\n</code></pre> <p>You have now completed this tutorial. No assessment is required. Proceed to the next tutorial.</p>"},{"location":"tutorials/3.2-git-branching/","title":"Using branches with the <code>git</code> command line tool","text":""},{"location":"tutorials/3.2-git-branching/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this tutorial you should be familiar with  the git branching workflow using the command line git program, and  you will get more practice with basic git commands for adding, committing, and pushing changes to a git repository. This tutorial will likely take 15-30 minutes to complete. </p>"},{"location":"tutorials/3.2-git-branching/#branching","title":"Branching","text":"<p>So what is the deal with branching? Branches are used to make changes to a repo on a separate version that can exist alongside the main  branch. This way you can test out new features while leaving the main branch in working order. Imagine you are developing a complex new  feature of a computer program, this might involve dozens or hundreds  of commits, one for each time you make a substantial change to the code. You can slowly develop this feature on a separate branch that will  accumulate all of these commits. Meanwhile, maybe you also make some completely separate changes on the main branch. Later, when the feature branch is finished and has been tested you can merge it into the main branch, at which point all of the commits on the feature branch will be committed to main. The end product is exactly the same as if you had never created the separate branch. Branching is only a convenience that developers use for collaboration, or to work on multiple versions of the code at the same time.</p> <p>So, as I've said, you may not actually need to use branching for quite some time. But let's walk through a quick example anyways just so you  are familiar with it. Let's create a new branch called \"feature\".  Try the following code, in order, and call <code>git status</code> at several  points throughout to check in on what is happening with the files or branch names being worked on.</p> <pre><code># create a new branch called 'feature' and \ngit branch feature\n\n# switch to the new branch\ngit checkout branch\n\n# make a change to an existing file.\necho \"new text appended here.\" &gt;&gt; ./file-1.md\n\n# stage the changes to this file\ngit add file-1.md\n\n# commit the changes (this branch will be 1 commit ahead)\ngit commit -m \"added appended message.\"\n\n# we can now switch back to the main branch\ngit checkout main\n\n# and merge the 'feature' branch into 'main'\ngit merge feature\n\n# delete the feature branch (no longer needed)\ngit branch -d feature\n\n# push the new changes on main to the remote (origin)\ngit push origin main\n</code></pre>"},{"location":"tutorials/3.2-git-branching/#review-and-assessment","title":"Review and assessment","text":"<p>You've now seen two ways in which you can make changes to your  local repo and push those changes to the remote on GitHub. The first involves committing changes directly to your main branch,  and overall just ignoring the branching process. This involves only the three steps add, commit, and push. The second alternative approach involves these same commands, but performs them on a separately created branch that must be merged back into the main branch.</p> <p>In addition to these there are in fact many other  ways in which you can use <code>git</code> to call these three steps.  However, until you become very comfortable  with this simple workflow I do not recommend trying to use any other type of shortcut. Make sure you've committed to memory the workflow: add, commit, push. </p>"},{"location":"tutorials/3.2-git-branching/#the-github-learning-lab","title":"The GitHub Learning Lab","text":"<p>There are many great resources for learning git and its integration with services like GitHub. One that I recommend is https://github.com/apps/github-learning-lab. Feel free to explore some of the free  interactive courses that they offer for further training.</p>"},{"location":"tutorials/3.2-git-branching/#alternatives-to-the-git-command-line-tool","title":"Alternatives to the git command-line tool","text":"<p>Because learning the git command line tool is difficult,  several alternatives have also been developed that incorporate a graphical user interface, so that you do not need to use a  shell or text editor at all. My belief is that you should  first learn the command line framework to really understand  how these commands work before you move to a more abstract  form, otherwise you are likely to encounter problems, such as  conflicts, and have a much harder time figuring out how to  resolve them. </p>"},{"location":"tutorials/3.2-git-branching/#assessment","title":"Assessment","text":"<p>Try to complete the following action by figuring out the appropriate code to do so. This may be challenging, but all of the answers you  need to complete the task are described above.  Remember, git works like a time machine, so it is unlikely  that you will mess anything up that cannot be  undone. If you get a strange or unexpected message, try to google it to find how to resolve it. And if you are still stuck, come visit the course chatroom.</p> <p>Alert</p> <p>Action: Complete the following steps.</p> <ol> <li>Create a new file called <code>file-4.md</code> in your hack-2-shell/ directory and write one of the following two messages in it about how you feel about learning git: 'crazy confusing' or 'easy peazy'</li> <li>call git add on <code>file-4.md</code> to add it to your staging area for commit.</li> <li>call git commit to commit your changes with an informative message (-m ...).</li> <li>call git push to push your changes to origin main.</li> <li>Look on GitHub to make sure your changes have appeared.</li> </ol> <p>For your grade we will look for this file with the appropriate contents in your hack-2-shell repo on GitHub.</p>"},{"location":"tutorials/3.3-github-pages/","title":"GitHub Pages","text":""},{"location":"tutorials/3.3-github-pages/#hosting-static-websites-with-github-pages","title":"Hosting static websites with GitHub pages","text":""},{"location":"tutorials/3.3-github-pages/#learning-objectives","title":"Learning objectives","text":"<p>This tutorial will walk you through the steps of creating  a personal website hosted on GitHub at a URL specified by your username: <code>http://{github_username}.github.io</code>.  By the end of this tutorial you will know how to create  this website, and others, from your GitHub account. This  tutorial will probably take 15-45 minutes to complete.</p>"},{"location":"tutorials/3.3-github-pages/#github-pages_1","title":"GitHub pages","text":"<p>In addition to its many other uses, GitHub serves a similar  role as LinkedIn for the tech industry, as a public social network for sharing code and demonstrating your coding  experience, and this extends similarly to fields in  biology like bioinformatics and biotech. In fact, your GitHub profile can be an important resource  when applying for jobs to show concrete examples of your work.</p> <p>GitHub has embraced this status by providing tools and services  that make it easier to share the contents of your GitHub repos  not only using the standard GitHub interface, but also by serving  those contents through customized webpages hosted by GitHub. This  framework is generally referred to as GitHub pages.</p>"},{"location":"tutorials/3.3-github-pages/#static-websites","title":"Static websites","text":"<p>More generally, github-pages is an example of a broader category of websites called static websites. This generally means that these sites are very simple, composed of only HTML,  CSS, and JavaScript, with no back-end database and server framework (e.g., PHP or Python). Thus, these sites do not  offer as much user interaction options as more complicated websites; but, as a trade-off, they are much easier to develop,  and also faster and more secure. </p> <p>For these reasons static websites have become very popular as a form of personal or lab website in Academia. There is  a large community of developers who have created  open-source web design themes and frameworks for easily styling  static websites by cloning existing GitHub repos  and simply substituting your details in place of the  existing ones. Thus, you can create beautiful websites without having to know any HTML or CSS at all. This sounds a bit like  squarespace, right? Well, it pretty much is, except free.</p> <p>GitHub has taken this approach one step further to make it even easier to create static webpages. Any GitHub repo can be made into  a static website simple by flipping a switch on GitHub.  In its most basic form the Markdown content in the README file will serve as content for the website and a default CSS theme  will be applied, unless you add further styling yourself.</p>"},{"location":"tutorials/3.3-github-pages/#examples","title":"Examples","text":"<p>As an example, my lab website (https://eaton-lab.org) was created as a github-pages site using a popular template available online that I cloned from a GitHub repo.  Similarly, our course website (https://eaton-lab.org/hack-the-planet) is an example of a static site I created using a mkdocs-material design framework. Both websites are simply a collection of files and folders hosted in a repo on GitHub. (I went an extra step to pay for the domain name eaton-lab.org,  but otherwise the basename of the site would be eaton-lab.github.io.) You can view the GitHub repos associated with these two websites at the  following links:</p> <ul> <li>https://github.com/eaton-lab/eaton-lab.github.io</li> <li>https://github.com/eaton-lab/hack-the-planet</li> </ul>"},{"location":"tutorials/3.3-github-pages/#_1","title":"github-pages","text":""},{"location":"tutorials/3.3-github-pages/#steps-to-creating-a-github-pages-site","title":"Steps to creating a Github pages site","text":"<ol> <li> <p>Go to Github.com, select <code>Repositories</code> and then click <code>New</code> from the upper right corner. Name the repository {username}.github.io, replacing {username} with your GitHub username (and no curly brackets). Make the repository public and add a README file.</p> </li> <li> <p>On the repositories webpage click on the Settings tab in the upper right corner (if your browser window is not expanded it may appear under  a collapsable button appearing as \"...\"). You can set many options for specific repositories under its Settings. Scroll down until you find the section labeled Pages.</p> </li> <li> <p>Click on the button under Source and select your main branch.  It will then list an option for a folder name, set it to the  default option (root). </p> </li> <li> <p>Select a Theme if you wish, or leave it as the default. This will create a commit to your repository adding a file called <code>_config.yml</code> which tells GitHub the theme to apply.</p> </li> <li> <p>That's it. It may take 5-10 minutes for your website to first appear.  Try visiting http://{username}.github.io (with your username)  until you see it appear. Better yet, choose the Actions tab and you can watch your new site build and deploy and then you'll know when it's ready when the green check mark appears.</p> </li> </ol>"},{"location":"tutorials/3.3-github-pages/#editing-your-static-website","title":"Editing your static website","text":"<p>By default this site will serve the contents of your README.md file as the source of your website. In other words, you can  fill the content of your website by writing in Markdown. Even  though the Markdown language is very simple, you can actually  create pretty nice looking websites using just this simple method,  along with the pre-built themes. If you are familiar with HTML, or want to learn it,  you can actually combine HTML and Markdown into the same  document. HTML and CSS will allow you to add a lot more styling.</p> <p>To see an example visit the website of our example student Phylo here: http://hackers-test.github.io and check out their GitHub repo for an example of what the  raw files look like: https://github.com/hackers-test/hackers-test.github.io.  You can see in this example that all of the content of site  is just a few lines in the README file.</p>"},{"location":"tutorials/3.3-github-pages/#howwhy-this-works","title":"How/why this works","text":"<p>GitHub builds these sites using a web framework called Jekyll. If you get very interested in this topic  then I recommend reading through the jekyll documentation and  learning more about how to develop these sites from scratch. In  our example above, GitHub is doing most of the hard work for us. But you can actually use GitHub in either way, having it run jekyll behind the scenes, or by running jekyll yourself and uploading  the contents to the repo. To see an example of the later see the repo for our course website in the docs/ folder at  https://github.com/eaton-lab/hack-the-planet.</p> <p>The basename {username}.github.io will be reserved for you  only for this specific reposotory that has this name. But,  you can create webpages for other repositories by visiting their  settings and enabling github-pages. For example, if you did this for your hack-2-shell repo then it would become available at the address https://{username}.github.io/hack-2-shell. </p>"},{"location":"tutorials/3.3-github-pages/#academic-websites","title":"Academic websites","text":"<p>In some ways, this tutorial is just a fun exercise for learning about git and GitHub, but on a more serious note, developing a  professional academic website is an essential resource as part of  your career development as a graduate student.  It is a simple way to put your name, interests, papers, talks,  etc. online, so that you have a google-searchable presence as  a scientist. This website doesn't necessarily need to be the  one you use, but it provides a simple way to make a site that  not only serves this purpose, but for those who are in the  know, also signals to them that you are tech-savvy enough to  have created it.</p>"},{"location":"tutorials/3.3-github-pages/#assessment","title":"Assessment","text":"<p>Your assessment for this tutorial is intended to combine three  elements that you have learned: (1) using Markdown;  (2) using <code>git</code>; and (3) hosting sites on Github.  You are meant to complete the following tasks using command  line tools in your terminal.</p> <p>Alert</p> <p>Action: Edit the content of your personal website on    GitHub to represent yourself (or your Github profile persona    if you are uncomfortable with sharing personal info). Make it professional, with a photo (of you or some topic) and a    description of your research or academic interests.    Spend some time on it, but it doesn't need to be exhaustive    for now, you can return and add more content to it at any    time later. </p> <p>Your grade for this assignment will be based on the following:</p>"},{"location":"tutorials/3.3-github-pages/#part-i","title":"Part I:","text":"<ul> <li>Edit the settings of a repo called <code>{username}.github.io</code> to make it into a Github-pages   website (you likely already did this above).</li> <li>Clone the repo to your local computer at ~/hacks/{username}.github.io</li> <li>cd into the repo.</li> <li>Edit the README content using Markdown (and or HTML) to include  at least some text and an image. Revisit the Markdown resources  if you need help with this, and look at code in the examples linked above.</li> <li>add, commit, and push to origin main to view the changes at {username}.github.io.</li> </ul>"},{"location":"tutorials/3.3-github-pages/#part-ii","title":"Part II:","text":"<ul> <li>using <code>mkdir</code> create a new directory called data/ in the repo.</li> <li>use <code>wget</code> to download a CSV file from https://eaton-lab.org/data/iris-data-dirty.csv to your repo.</li> <li>move this file into the data/ folder if not there already.</li> <li>use <code>git add</code> to stage the folder and file <code>data/iris-data-dirty.csv</code> for commit.</li> <li>use <code>git commit</code> to commit these changes.</li> <li>use <code>git push</code> to push these changes to your origin main.</li> <li>wait a few minutes and then visit {username}.github.io/data/iris-data-dirty.csv. You should be able to see or download the CSV  file (depending on your browser).</li> </ul> <p>Congratulations, you've created a personal website, and now you've  also created a subfolder within it where you can store data files that will be easily accessible from this web address.  If the last step worked then you were successful. If not, there must have  been an error somewhere. Keep trying. If you get stuck, visit the course chatroom. </p>"},{"location":"tutorials/4.0-conda/","title":"On Conda and Sand Mandalas","text":""},{"location":"tutorials/4.0-conda/#what-is-conda","title":"What is conda?","text":"<p>Conda is an open-source software management  tool for installing software packages, as well as their dependencies, and  creating sandboxed environments for executing code. Using the <code>conda</code> command line tool you can use simple commands to search for software packages, select  specific versions, and install them locally on your machine. This automated process makes installing and removing software simple and reproducible which makes it easier to design, distribute and use working software.</p>"},{"location":"tutorials/4.0-conda/#why-use-conda","title":"Why use conda?","text":"<p>The many advantages of using conda include:</p> <ul> <li> <p>command-line convenience: the conda command line program allows you to  search for and install tools with simple commands that can even be written as scripts for automation. This makes it easy to replicate the set of software tools installed on one computer onto another machine. </p> </li> <li> <p>finding dependencies: Almost every software program builds on and requires other software packages as dependencies. Rather than telling a user to go  find and install each of these dependencies on their own (a sure sign of  a poorly developed tool by today's standards) a software package manager can instead fetch and install of the dependencies for them. This might even include different dependencies or versions depending on their specific operating system. This is a very complex task and something conda does very well.</p> </li> <li> <p>sandboxed directory: conda installs software into a sandboxed location  on your computer (usually a directory within HOME), which is done purposefully to keep your conda software completely separate and isolated from your  system-wide software (which is usually in /bin or /usr/bin).  This gives you peace of mind to install, update, and remove packages as much as you want inside of your conda directory without having to worry that it  might ever impact your system programs. </p> </li> <li> <p>environments: In addition to allowing you to install software programs into a sandboxed location, conda also allows you to keep many separate environments, where you can keep different sets of software or versions of them. This makes it easy  to test software tools across different version of dependencies, or to keep  software separate that uses different conflicting dependencies. </p> </li> </ul>"},{"location":"tutorials/4.0-conda/#install-conda-miniconda3","title":"Install conda (miniconda3)","text":"<p>There are two main flavors of conda that you can install: Anaconda and  Miniconda. Both include a version of Python and the conda program  (which is written in Python) as well as a few dependencies of conda for fetching information about packages online. However, the two flavors differ in terms of which other tools come pre-loaded with these base resources. Anaconda comes fully loaded with dozens of commonly used Python packages,  whereas Miniconda in totally minimal, and doesn't come with anything extra at all. I always recommend installing Miniconda, and then adding to it any software that you want to install. </p> <p>To install Miniconda you can google search 'Miniconda install' and it will point you to the following miniconda install page. Here you will see installation instructions different versions of Miniconda. First,  there is a version for different operating systems (Window, MacOSX, Linux).  If you are on a Mac then select from the Mac section, if you are on Linux or Windows Subsystem for Linux then select the Linux version. Do not install the Windows version. We can download and install conda directly from the command line following these steps (be sure to choose the instructions for your OS):</p> Linux/WSL2MacOSX <pre><code># cd to your HOME directory\ncd ~\n\n# download Miniconda installer\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n\n# call bash to install conda from the .sh install script in 'batch' (auto) mode\nbash Miniconda3-latest-Linux-x86_64.sh -b\n\n# check that the miniconda3 folder now appears in HOME\nls -l ~\n</code></pre> <pre><code># cd to your HOME directory\ncd ~\n\n# download Miniconda installer (if you have an older intel mac you will need\n# to use a different link by replacing `arm64` with `x86_64`)\ncurl -O https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-arm64.sh\n\n# call bash to install conda from the .sh install script in 'batch' (auto) mode\nbash Miniconda3-latest-MacOSX-x86_64.sh -b\n\n# check that the miniconda3 folder now appears in HOME\nls -l ~\n</code></pre> <p>When you execute the <code>bash</code> command above it will start running the installer script. By default, this will select <code>~/miniconda3</code> as the location to install conda and its associated folders. That's good. It should take a minute or less to finish.</p>"},{"location":"tutorials/4.0-conda/#adding-conda-to-your-path","title":"Adding <code>conda</code> to your PATH","text":"<p>At this point we have now created a new folder containing conda, but it is not yet added to our PATH, meaning that we can't easily use this software yet. Our goal here will be set the miniconda3/ directory at the front of our PATH variable. This means that our shell will look here first for any software, and only look in the other folders in the PATH for software if it was not already found here. One specific reason this is useful is that your shell will find this new version of Python (3.8) in Miniconda and use it instead of some stodgy old system-wide version that is likely lurking  deep in your computer somewhere. Before we proceed let's look at both the PATH environment variable (to see where programs are being searched for), and alsowhich  version of Python is currently set as your default (i.e., at the front  of you PATH).</p> <pre><code># Print the PATH environment variable\necho $PATH\n\n# IF one is in your path this will show it.\nwhich python\n\n# this will show all versions of Python on your system\nwhereis python\n</code></pre> <p>Let's now add conda to your PATH by editing the dotfile (e.g., .bashrc) in your HOME directory. While we could do this by hand, conda has  developed a convenient script that can do it for us, and do it in kind of a fancy way. So let's use this tool called <code>conda init</code>. To use it we will need to provide the full path to the binary file since it is not yet in our PATH. Run the command below and you should see an example output similar to below.</p> <pre><code>~/miniconda3/condabin/conda init $SHELL\n</code></pre> <pre>\nno change     /home/deren/miniconda3/condabin/conda\nno change     /home/deren/miniconda3/bin/conda\nno change     /home/deren/miniconda3/bin/conda-env\nno change     /home/deren/miniconda3/bin/activate\nno change     /home/deren/miniconda3/bin/deactivate\nno change     /home/deren/miniconda3/etc/profile.d/conda.sh\nno change     /home/deren/miniconda3/etc/fish/conf.d/conda.fish\nno change     /home/deren/miniconda3/shell/condabin/Conda.psm1\nno change     /home/deren/miniconda3/shell/condabin/conda-hook.ps1\nno change     /home/deren/miniconda3/lib/python3.8/site-packages/xontrib/conda.xsh\nno change     /home/deren/miniconda3/etc/profile.d/conda.csh\nmodified     /home/deren/.bashrc\n\n==&gt; For changes to take effect, close and re-open your current shell &lt;==\n</pre> <p>You can see that this edited the dotfile in my home directory. Remember,  this is the file that is run every time you open a terminal which loads a bunch of variables including the PATH where software is found and  to set the style and colors of the prompt. When you run <code>conda init $SHELL</code> it writes a new block at the end of the dotfile for your specific shell  telling it to make your terminal aware of conda whenever it starts up.   If you wanted to stop it from doing this you would only need to remove that block of text  from the dotfile. The code in this block does two things:  (1) it tells your prompt to show the name of the conda environment;  and (2) it adds the filepath of your miniconda3 directory to the front of your PATH variable so that you can find all of the  tools there. For this to go into effect close and reopen your terminal.</p> <p>First let's check that the PATH has actually been modified, which should show something like this:</p> <pre><code>echo $PATH\n</code></pre> <pre>\n/home/jovyan/miniconda3/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n</pre> <p>You can further test whether the <code>conda</code> command line tool is in your PATH by typing the following command, which will print info about your conda directory.</p> <pre><code>conda info\n</code></pre> <pre>\n     active environment : base\n    active env location : /home/deren/miniconda3\n            shell level : 1\n       user config file : /home/deren/.condarc\n populated config files : \n          conda version : 4.9.2\n    conda-build version : not installed\n         python version : 3.8.5.final.0\n       virtual packages : __glibc=2.31=0\n                          __unix=0=0\n                          __archspec=1=x86_64\n       base environment : /home/deren/miniconda3  (writable)\n           channel URLs : https://repo.anaconda.com/pkgs/main/linux-64\n                          https://repo.anaconda.com/pkgs/main/noarch\n                          https://repo.anaconda.com/pkgs/r/linux-64\n                          https://repo.anaconda.com/pkgs/r/noarch\n          package cache : /home/deren/miniconda3/pkgs\n                          /home/deren/.conda/pkgs\n       envs directories : /home/deren/miniconda3/envs\n                          /home/deren/.conda/envs\n               platform : linux-64\n             user-agent : conda/4.9.2 requests/2.25.1 CPython/3.8.5 Linux/5.8.0-38-generic ubuntu/20.04.1 glibc/2.31\n                UID:GID : 1000:1000\n             netrc file : None\n           offline mode : False\n</pre> <p>Let's also look again for where Python is installed on our system. We should see a version of Python located in our miniconda3 directory at the front of  the PATH:</p> <pre><code># this should show the miniconda Python path\nwhich python\n</code></pre> <pre>\n/home/deren/miniconda3/bin/python\n</pre> <p>Info</p> <p>Take note of this result. This is the path to the version of Python  that we will be using extensively throughout this course. It is located inside of your miniconda3/ directory, and then inside of a directory called bin/. This latter subdirectory is where all binaries (executable callable programs) installed by conda will be located.</p>"},{"location":"tutorials/4.0-conda/#using-conda","title":"Using conda","text":"<p>The command line tool is called <code>conda</code>. This is a binary  (executable program) written in Python and installed in your miniconda directory. Because this directory is in your PATH the  <code>conda</code> binary is also in your PATH. This is why you can call it  from your terminal without needing to write the full path to the  location of the binary. Let's try installing some other binaries using conda. The syntax for installing a program with conda is <code>conda {program_name} -c {channel_name}</code>. Try the example below:</p> <pre><code>conda install cowpy -c conda-forge\n</code></pre> <p>This installed a goofy Python program called cowsay that can be used to make funny ASCII drawings in your terminal. Under the hood it installed a Python package, and also a binary command line tool that ships with this Python library. The Python library is installed into <code>miniconda3/pkgs/</code> and the binary is installed into <code>miniconda3/bin/</code> Let's try out the cowpy binary by writing some text in the terminal  with <code>echo</code> and piping it to the <code>cowpy</code> program. For more details on the cowpy program you can find it on GitHub</p> <pre><code>echo \"hello world\" | cowpy\n</code></pre>"},{"location":"tutorials/4.0-conda/#conda-channels","title":"Conda channels","text":"<p>Different software packages are found on different channels on conda.  Channels are just big online folders where conda recipes are stored.  Most software is available on one of three channels: \"default\", \"conda-forge\", and \"bioconda\". The bioconda channel includes many bioinformatics specific tools. The conda-forge channel contains the cutting-edge versions of almost all software, and is very actively community  maintained. The default channel is maintained by the anaconda organization, and  tends to be a little out of date, and has the least software. You can find out  which channel a software package is available on by googling <code>conda {software_name}</code>, or by using the <code>anaconda-client</code> package to search all available channels. Let's practice installing packages by installing <code>anaconda-client</code>. </p> <pre><code>conda install -c conda-forge anaconda-client\n</code></pre> <p>Let's test it out by searching for <code>vcftools</code>, a commonly used tool for manipulating VCF files (\"variant call format\") which are used primarily for SNP data.</p> <pre><code># `anaconda` is the tool we can use for searching channels for software\nanaconda search vcftools\n</code></pre> <pre>\nanaconda search vcftools                                                                                                     \nUsing Anaconda API: https://api.anaconda.org                                                                                                               \nPackages:                                                                                                                                                  \n     Name                             |  Version | Package Types     | Platforms       | Builds                                                            \n     -------------------------------- |   ------ | ----------------- | --------------- | ----------                                                        \n     BioBuilds/vcftools               |   0.1.15 | Conda             | linux-64, osx-64, linux-ppc64le | pl522h7632db0_0, pl522h49bf30a_0, pl522hf9702e9_0, pl5.22.0_0                                                                                                                                                \n     bioconda/gvcftools               |   0.17.0 | Conda             | linux-64, osx-64 | boost1.60_0, pl5.22.0_2, he941832_3, pl5.22.0_1                  \n     bioconda/perl-vcftools-vcf       |   0.1.16 | Conda             | linux-64, osx-64, noarch | pl526_1, pl5321hdfd78af_4, pl526_2, pl526_0, 2, pl5.22.0_1, pl5.22.0_0, 3                                                                                                                                           \n                                          : cpanm ready distribution of VCFtools Perl libraries                                                            \n     bioconda/vcftools                |   0.1.16 | Conda             | linux-64, osx-64, linux-aarch64, osx-arm64 | 5, pl5321h1e84f2d_12, pl5321h6057758_11, pl5321h66d0458_8, pl5321hdcf5f25_11, h9a82719_5, h87af4ef_5, he860b03_3, 4, 0, pl526h8b12597_1, pl5321hdcf5f25_8, pl5321h7f4e536_11, pl5.22.0_2, 2, pl5321hd03093a_8, pl5321hda5e58c_12, he941832_2, pl526hdbcaa40_0, pl5321h6151dfb_7, pl5321h077b44d_12, pl5321hdcf5f25_10, pl5321hdcf5f25_9, he513fc3_4, pl5262hfd59bb5_2, ha92aebf_2, pl526hd174df1_1, h7475705_4, pl5321h447d7a5_11, pl5.22.0_1, pl5321hdf58011_9, pl526hd9629dc_0, pl5321h7f4e536_10, 1, pl5262h2e03b76_2, pl5321h87af4ef_6, pl5321hdf58011_10, pl5321hd03093a_7, pl5321h2ec61ea_12, pl5321h9a82719_6, pl5.22.0_0, pl5321h2e03b76_3, 3, h5c9b4e4_3                  \n                                          : A set of tools written in Perl and C++ for working with VCF files. This package only contains the C++ libraries whereas the package perl-vcftools-vcf contains the perl libraries\n     brown-data-science/vcftools      |   0.1.15 | Conda             | linux-64        | 1         \n     compbiocore/perl-vcftools-vcf    |    0.840 | Conda             | linux-64        | pl526_1   \n                                          : cpanm ready distribution of VCFtools Perl libraries\n     compbiocore/vcftools             |   0.1.15 | Conda             | linux-64        | h1d3419f_0, 1\n     pstey/vcftools                   |   0.1.15 | Conda             | linux-64        | 1         \nFound 8 packages\n\nRun 'anaconda show ' to get installation details\n\n\n<p>Specifying <code>-c conda-forge</code> when we installed <code>anaconda-client</code> tells conda to search\nfor the package in this channel (rather than others). After years of using conda \nI strongly recommend setting the conda-forge channel as your default channel. Rather \nthan typing in <code>conda install -c conda-forge &lt;package&gt;</code> every time (which is tedious), you can\nset conda-forge as the default using <code>conda config</code>. This means that it will \nalways look here first for a requested package or any of its dependencies, and \nonly look at other channels after first looking here. This is a good thing. </p>\n<pre><code>conda config --add channels conda-forge\n</code></pre>\n<p>Here we are setting a configuration preference. So how do you think that \nwas done? That's right, it wrote it to a dotfile. In this case it simply\nadded the preferred conda channel order to a file called <code>~/.condarc</code>. \nLet's test this out by installing another package. Now we no longer \nneed to tell it <code>-c conda-forge</code> since it will look there by default.\n(Personally, I still usually write it anyways just out of habit, so \nyou may see it in future instructions).</p>\n<pre><code># install the Python 'requests' packages\nconda install requests\n</code></pre>\n<p>And you can see that the order of channels to search through as been modified by our\nchange of the conda configuration.</p>\n<pre>\nChannels:\n - conda-forge\n - defaults\nPlatform: linux-64\n</pre>"},{"location":"tutorials/4.0-conda/#conda-environments","title":"Conda environments","text":"<p>In this class we will probably mostly use only the 'base' conda environment. \nHowever, you can create and load many separate conda environments, where each\ncontains a different isolated set of software. Let's go ahead and install\nvcftools in a new, clean conda environment.</p>\n<pre><code># create a new Python environment names 'vcftools' and activate it\nconda create -n vcftools\nconda activate vcftools\n</code></pre>\n<p>Notice that when you activate a new environment conda by default will change your \ncommand line prompt to indicate that you are now in the (vcftools) environment.\nThis is useful!</p>\n<p>Now install vcftools in this new environment, remembering that when we searched\nfor vcftools earlier that we found it in the <code>bioconda</code> channel.</p>\n<pre><code># Add -y to the command line to skip the prompt of whether to proceed with the install\nconda install -c bioconda vcftools -y\n</code></pre>\n<p>After the install completes you can test to verify that vcftools is installed.</p>\n<pre><code>vcftools --version\n</code></pre>\n<pre>\nVCFtools (0.1.16)\n</pre>\n\n<p>Also, take a look at your PATH environment variable. Conda is manipulating this behind\nthe scenes to isolate installed packages within the environments you specify.</p>\n<pre><code>echo $PATH\n</code></pre>\n<pre>\n/home/jovyan/miniconda3/envs/vcftools/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n</pre>\n\n<p>Notice that the first element of the PATH is now <code>~/miniconda3/envs/vcftools/bin</code>.</p>\n<p>Switch back to the base conda environment.\n<pre><code>conda activate base\n\n#Another alternative is to 'deactivate' the current environment, which will\n#fall back to the previous environment by default.\nconda deactivate\n</code></pre></p>\n<p>When you switch back to <code>base</code> two things happen: 1) The prompt changes again to reflect\nthat you are back in the (base) environment; and 2) your PATH also changes, which you can\nverify:</p>\n<pre><code>echo $PATH\n</code></pre>\n<pre>\n/home/jovyan/miniconda3/bin:/opt/conda/condabin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n</pre>\n\n<p>Verify that vcftools is indeed no longer available in the base environment:\n<pre><code>which vcftools\n</code></pre></p>\n<p>Right now you only have two environments, so it's not hard to remember which is which,\nbut if you are doing lots of data science you might have numerous environments for all the\ndifferent analytical tools in your toolkit. You can see which environments are available to you\nby asking conda to <code>list</code> them.</p>\n<pre><code>conda env list\n</code></pre>\n<pre>\nbase                  *  /home/deren/miniconda3\nvcftools                      /home/deren/miniconda3/envs/vcftools\n</pre>\n\n<p>On my machine I have lots of conda environments, so my output looks like this:</p>\n<pre>\n# conda environments:\n#\nbase                     /Users/isaac/miniconda3\nPTA                      /Users/isaac/miniconda3/envs/PTA\nbart                     /Users/isaac/miniconda3/envs/bart\nbci                      /Users/isaac/miniconda3/envs/bci\nee                    *  /Users/isaac/miniconda3/envs/ee\nipyrad                   /Users/isaac/miniconda3/envs/ipyrad\nmess                     /Users/isaac/miniconda3/envs/mess\ntmp                      /Users/isaac/miniconda3/envs/tmp\n</pre>"},{"location":"tutorials/4.0-conda/#the-purposeful-impermanence-of-conda","title":"The purposeful impermanence of conda","text":"<p>In Tibetan Buddhism there is a tradition involving the creation of \nlarge complex mosaic mandalas\ncarefully constructed from colored sand, often involving many weeks of work. \nUpon completion of the artwork it is then destroyed. This meditative exercise \nis intended to make one reflect on the impermanence of life, and to experience\nthe act of letting go.</p>\n<p>The sand mandala tradition has a lot to teach us about our relationships\nwith our conda software directory. You may feel that after working with \nconda for several weeks that you have installed the perfect set of software\ntools that includes everything you will ever need. And you become very \nattached to it. But, you should feel free to let it go. </p>\n<p>Software becomes outdated quickly, and updating many many software packages to new\nversions can sometimes conflict with other programs in your environment to cause problems.\nUsually conda can fix these problems and find the right versions that work\ntogether. But in some cases it can't. It simply worked itself into a corner\nwhere it basically needs to uninstall and reinstall everything again. This is\nthe point when you should consider destroying it.</p>"},{"location":"tutorials/4.0-conda/#remove-a-conda-environment","title":"Remove a conda environment","text":"<p>You can remove a specific environment by name, if you are no longer using it.\n<pre><code>conda env remove -n vcftools\n</code></pre></p>\n<p>Check that this indeed removed your vcftools environment:\n<pre><code>conda env list\n</code></pre></p>\n<pre>\n# conda environments:\n#\nbase                 * /home/jovyan/miniconda3\n</pre>"},{"location":"tutorials/4.0-conda/#remove-the-entire-conda-directory","title":"Remove the entire conda directory","text":"<p>Or, you can also remove the entire conda directory altogether.\nRemember, we just installed it above, and took just a single command. It's very \nfast and easy. To remove the conda directory you can use the <code>rm</code> command along \nwith the options <code>-r</code> and <code>-f</code>. \nThe <code>-r</code> option tells it that the thing we want to remove is a \nfolder. The <code>-f</code> command means 'force'. This is a slightly dangerous command \nif you were to tell it to delete something that you shouldn't. So take care that\nthe file path after this command is the one that you actually want to remove\nand not something else (like your entire filesystem). </p>\n<pre><code># this command would remove your conda directory completely\n# rm -rf ~/miniconda3\n</code></pre>"},{"location":"tutorials/4.0-conda/#practice-creating-environments-and-installing-software","title":"Practice creating environments and installing software","text":"<p>For the next exercise you'll practice creating new environments, installing software,\nchanging environments, and removing environments.</p>\n<ul>\n<li>Create a new conda environment called <code>bedtools</code></li>\n<li>Change to this new environment and verify that your PATH has changed</li>\n<li>Install bedtools from the bioconda channel</li>\n<li>Verify that bedtools is installed: <code>bedtools --version</code></li>\n<li>Deactivate the bedtools environment</li>\n<li>Check that bedtools is no longer available</li>\n<li>Create a new environment called <code>msprime</code> and activate it</li>\n<li>Install msprime from the conda-forge channel</li>\n<li>Check that it is installed with <code>msp -V</code></li>\n<li>Activate the base environment</li>\n<li>Verify your current PATH and check that bedtools and msp are not available here</li>\n<li>Remove the <code>bedtools</code> and <code>msprime</code> environments</li>\n<li>Blow away your entire conda install with <code>rm -rf ~/miniconda3</code></li>\n<li>Reinstall miniconda following the directions above</li>\n<li>In the new clean conda base environment install anaconda-client</li>\n<li>Now you're ready for the next exercise</li>\n</ul>"},{"location":"tutorials/4.1-jupyter/","title":"jupyter","text":""},{"location":"tutorials/4.1-jupyter/#installing-and-using-jupyter-locally","title":"Installing and using jupyter locally","text":"<p>At this point you should already be familiar with  jupyter notebooks. We have previously connected to and executed code in jupyter using the cloud-based service Binder.  Binder involves a jupyter server running remotely (somewhere in the world)  that you connect to and interact with through your browser. In contrast to  this remote style of using notebooks, here we will learn to install and  use jupyter locally on your own machine.  In addition, we will dive a bit deeper into the format of jupyter notebooks, and best practices for sharing them using GitHub.</p>"},{"location":"tutorials/4.1-jupyter/#installing-jupyter-notebook","title":"Installing Jupyter notebook","text":"<p>Install jupyter from conda-forge using the following command. <pre><code>conda install notebook -c conda-forge\n</code></pre></p>"},{"location":"tutorials/4.1-jupyter/#configuring-your-local-notebook","title":"Configuring your local notebook","text":"<p>Although it is not required, we can run a one-time  configuration of jupyter before starting it to set some preferences that will make it easier to use. Call the command below to create a jupyter  configuration file which will be stored in the .jupyter/ dir in  your home directory.</p> <p><pre><code>jupyter-notebook --generate-config\n</code></pre> Then store a password by running the command below. This is just a measure that adds additional security.</p> <pre><code>jupyter-notebook password\n</code></pre> <p>Now we can start a jupyter notebook server with the following command. The  option <code>--no-browser</code> is not necessary for everyone. For WSL2 users it will hide a warning message that would otherwise pop up telling you that it cannot open a browser automatically from your WLS2 system. Either way, once the server is runnign we can open a browser on our own and connect to it by entering the  URL addresss. </p> <pre><code># move to your home directory, and start a notebook server from here.\ncd ~\njupyter lab --no-browser\n</code></pre> <p>If you entered the option above then it will not have automatically opened in  your default browser. You will see that some text is being printed in the terminal. We'll describe this in the next section. For now, open a new tab in the browser  of your choice and in the address bar enter <code>localhost:8888</code>.  You are telling it that there is a local server running on your computer, and  that it is sending information to port number 8888. This is the default port  number used by jupyter. If you have other running notebooks and the 8888 port is not available it will choose the next available port, and it will tell you this  in the status message, e.g.:</p> <pre>\n[I 2025-01-29 20:46:49.530 ServerApp] The port 8888 is already in use, trying another port.\n[I 2025-01-29 20:46:49.531 ServerApp] Serving notebooks from local directory: /Users/isaac/proj/hack-the-planet/old-docs/lectures/5.0\n[I 2025-01-29 20:46:49.531 ServerApp] Jupyter Server 2.15.0 is running at:\n[I 2025-01-29 20:46:49.531 ServerApp] http://localhost:8889/lab\n</pre>"},{"location":"tutorials/4.1-jupyter/#creating-a-new-jupyter-notebook","title":"Creating a new jupyter notebook","text":"<p>Navigate to your <code>hacks/hack-2-shell</code> directory (which is a github repository) using the filebrowser on the left. Create a new Notebook using the Python 3 button in the Launcher. In a new cell type <code>print(\"Hello world\")</code> and run this cell. Give the notebook a name by either clicking File-Save Notebook As... or by right-clicking on Untitled.ipynb in the leftnav and choosing Rename. Call the notebook 'MyFirstPython.ipynb'.</p>"},{"location":"tutorials/4.1-jupyter/#what-is-a-server","title":"What is a server?","text":"<p>A server is a computer program that sends and receives information over a network. Jupyter works as a server that runs a Python kernel (an open session of Python) in the background, which processes information that it receives, and sends outputs back. A web browser is the best way to interface with a server, since it can use all of the power of web design to make a nice interface for displaying outputs. This is the idea behind jupyter notebooks: A python backend that uses and web-interface frontend for users to interact with.</p>"},{"location":"tutorials/4.1-jupyter/#jupyter-filesystem-interface","title":"Jupyter filesystem interface","text":"<p>As you have seen before, the jupyter interface will show you a view of your  filesystem, including folder and files, from which you can either select an  existing file to open, or create a new one. Jupyter notebooks are saved in a  file format with the suffix <code>.ipynb</code>, and these will appear with little  notebook icons next to them. </p>"},{"location":"tutorials/4.1-jupyter/#stopping-the-server","title":"Stopping the server","text":"<p>When you start a jupyter server in a terminal, you can just minimize that terminal or stick it in a corner. The server will continue to function for as long as you  have this server running. When you are done using, and have saved your notebooks,  you can stop the server by closing it (or interrupt it by pressing ctrl-c). Try this now by clicking on the terminal running the server and interrupting it. You can also close the browser tabs that were open. You can start the notebook server again at any time following the same commands be used above.</p>"},{"location":"tutorials/4.1-jupyter/#assessment","title":"Assessment","text":"<p>To complete this assignment, open a 'Terminal' using the launcher and add/commit/push your new notebook back up to your github repository.</p>"},{"location":"tutorials/4.2-forking/","title":"github forking and python assessment","text":""},{"location":"tutorials/4.2-forking/#forking-on-github","title":"Forking on GitHub","text":"<p>Go to the following GitHub URL https://github.com/hackers-test/hack-5-python.git and click on Fork  button in the far upper right corner.  This will take a few seconds to create a copy and then a new repo will  be created under your profile that includes a clone of this repo.</p> <p>So what is a fork, and how is it different from a clone? Like cloning forking creates an identical copy of a repository, but the difference is  that the remote is located under your profile (your ownership permissions) rather than the person's who you forked it from. This means that you will have permission to push changes to the remote without needing that users permission. </p>"},{"location":"tutorials/4.2-forking/#when-should-i-clone-versus-fork","title":"When should I clone versus fork","text":"<p>If you do not plan on editing the code and contributing your changes  back to the remote, then you can simply clone a repo. This simply  downloads a copy of the source code onto your computer that you can use  or edit locally for testing. This is a common way to test out software that is on GitHub. But, if you want to make changes and propose these changes to the owner of the repo through a pull request, then you need to create a separate fork. Forking is a GitHub thing, having to do with permissions  for writing to a specific GitHub remote. </p>"},{"location":"tutorials/4.2-forking/#how-we-will-use-forking-for-class","title":"How we will use forking for class","text":"<p>In this class I will occasionally ask you to fork a repo so that you  will have your own copy of it in your GitHub account. You will then be asked to edit the repo -- for example, open the notebooks in the repo and complete them -- and will be graded on the changes that you make and push back to your remote repo on GitHub. </p>"},{"location":"tutorials/4.2-forking/#a-test-push","title":"A test push","text":"<p>Before you move on to your assignment, let's first do a test by pushing a change to your new forked repository. Let's make a change to the README file, then  use the simple git workflow to push these changes to the remote. From your version of hack-5-python on GitHub click on the clone button to get the link and run the command below to clone the repo to your local computer. <pre><code># clone your fork of the hack-5-python repo into your hacks folder\ncd ~/hacks/\ngit clone {paste the repo URL here}\n</code></pre></p> <pre><code># add some text to the README file\ncd ./hacks/hack-5-python\necho \"\\nThis repo contains several jupyter notebooks\" &gt; README.md\ngit add README.md\ngit commit -m \"added text to the readme\"\ngit push origin main\n</code></pre> <p>You can now go look at your fork on GitHub and see that your changes have  appeared.</p>"},{"location":"tutorials/4.2-forking/#assessment","title":"Assessment","text":"<p>Success</p> <p>You will be graded based on completion of the instructions below, where the final product will be found on your GitHub profile.</p> <ol> <li> <p>Fork the hack-5-python repo above (you already did this above).</p> </li> <li> <p>Clone your copy of hack-5-python (you already did this above).</p> </li> <li> <p>Start a jupyter notebook server from your home folder</p> </li> <li> <p>Open your browser to localhost:8888 and look in the hacks/hack-5-python/notebooks directory. Here you will find several notebooks. Complete them in order by  following the instructions inside each notebook. Be sure to save the notebooks when you are done (it auto-saves also, BTW), by pressing the save button in the menu bar.</p> </li> <li> <p>Stop your notebook server. </p> </li> <li> <p>From your terminal sync the changes you've made to these notebook using the <code>git</code>  command line tool following the add, commit, push, workflow that you learned in the last session. Be sure to <code>cd</code> into the hack-5-python directory to do this.</p> </li> </ol>"},{"location":"tutorials/5.0-python-part1/","title":"Python part I - More practice with variables, lists, and for loops","text":""},{"location":"tutorials/5.0-python-part1/#assignment-instructions","title":"Assignment instructions:","text":"<p>The assignment this week lives inside a new jupyter notebook that has been added to the hackers-test/hack-5-python repository  which you forked on github and cloned to your local machine for last weeks homework.  Because we 'forked' this repository, the question arises, How do we get this new code  into our own personal fork?</p>"},{"location":"tutorials/5.0-python-part1/#a-note-on-git-forks","title":"A note on git forks","text":"<p>When you create a 'fork' of a repository you are creating an exact copy of the original, and then disconnecting your fork from it from that point on (it's like a 'fork in the road').  In other words, the fork and the forked repo will almost certiainly begin to  diverge as commits accumulate in one and not the other. Sometimes it is useful  to 're-join' or pull in the commits from the upstream repository (the original  forked repo), and this is what we will do here.</p>"},{"location":"tutorials/5.0-python-part1/#syncing-a-fork-to-an-upstream-repository","title":"Syncing a fork to an upstream repository","text":"<p>Because the new homework lives in the repository that you originally forked from you must sync your repository to the original remote repo.</p> <p>1 - Change directory to your local copy of the fork of the <code>hack-5-python</code> repo</p> <p>2 -  Specify the original 'hack-5-python' repository as a new remote upstream for syncing</p> <pre><code># View the currently attached remotes\n$ git remote -v\norigin  https://github.com/iao2122/hack-5-python.git (fetch)\norigin  https://github.com/iao2122/hack-5-python.git (push)\n</code></pre> <pre><code># Add the upstream as a new remote\n$ git remote add upstream https://github.com/hackers-test/hack-5-python.git\n\n# Verify the new remote is set\n$ git remote -v\norigin  https://github.com/iao2122/hack-5-python.git (fetch)\norigin  https://github.com/iao2122/hack-5-python.git (push)\nupstream    https://github.com/hackers-test/hack-5-python.git (fetch)\nupstream    https://github.com/hackers-test/hack-5-python.git (push)\n</code></pre> <p>3 - Merge the changes from upstream to your local forked copy</p> <pre><code># Verify that you are on your local forks 'main' branch\n$ git branch  \n* main\n\n# If you are not on main you can switch to it like this:\n$ git checkout main\n</code></pre> <pre><code># Now merge the upstream 'main' and your local 'main'\ngit merge upstream/main\n\n# It may prompt you to include a message for the merge commit.\n</code></pre> <p>4 - Push the merge up to to the remote of your own fork <pre><code>$ git push\n</code></pre></p> <p>5 - Start a jupyter notebook server locally. 6 - Navigate to <code>~/hacks/hack-5-python/notebooks/</code> 7 - Complete the challenges in the new notebook <code>nb-5.3-seesion5-challenges.ipynb</code> 8 - Add, commit, and push changes back to your <code>origin main</code> copy of the repo.</p>"},{"location":"tutorials/5.0-python-part1/#resources","title":"Resources","text":"<ul> <li>Check in on the chatroom if you run into any problems.</li> <li>You can view a read-only version of the notebook assignments on nbviewer</li> </ul>"},{"location":"tutorials/6.0-python-part2/","title":"Python part II - Dictionaries, if/else, functions","text":""},{"location":"tutorials/6.0-python-part2/#assignment-instructions","title":"Assignment instructions:","text":"<ol> <li>Fork the repo https://github.com/hackers-test/hack-6-python</li> <li>Clone your copy of the repo to <code>~/hacks/</code></li> <li>Start a jupyter notebook server locally.</li> <li>Navigate to <code>~/hacks/hack-6-python/notebooks/</code></li> <li>Complete instructions in the 4 jupyter notebooks.</li> <li>Add, commit, and push changes back to your <code>origin main</code> copy of the repo.</li> </ol>"},{"location":"tutorials/6.0-python-part2/#resources","title":"Resources","text":"<ul> <li>Check in on the chatroom if you run into any problems.</li> <li>You can view a read-only version of the notebook assignments on nbviewer</li> </ul>"},{"location":"tutorials/6.1-microproject-wf/","title":"Microproject - The Wright-Fisher Model of genetic drift","text":""},{"location":"tutorials/6.1-microproject-wf/#a-simple-wright-fisher-simulator","title":"A simple Wright-Fisher simulator","text":"<p>The Wright-Fisher (WF) model is a simple model that describes the change in allele frequencies in populations through time. WF is a cornerstone of population genetics, yet it is simple enough that we can already implement a version of it in python using the tools that we know. First, to see an example of the behavior of genetic drift under the WF model, open this link in a new window:</p> <p>An online WF simulator from phytools.org</p> <p>In our model we will observe the following contstraints:</p> <ul> <li>The population size (N) is fixed and unchanging for the duration of the simulation</li> <li>Generations are non-overlapping (all individuals die and are replaced once per generation)</li> <li>All individuals have an equal probability of producing offspring</li> <li>Within this population we model a single bi-allelic locus</li> <li>There is no selection, e.g. ancestral (A) and derived (a) alleles have equal fitness</li> </ul>"},{"location":"tutorials/6.1-microproject-wf/#assignment-instructions","title":"Assignment instructions:","text":"<ol> <li>Launch a jupyter server on your local computer</li> <li>Navigate to <code>~/hack-5-python/notebooks</code> directory and create a new jupyter notebook called <code>wf-sim.ipynb</code></li> <li>For each section of this tutorial you may create several code blocks for testing, but the goal will be to have one code block that contains both a function definition and a represetative function call, e.g.: <pre><code>def my_cool_function(arg1, arg2):\n    arg1 += 'bar'\n    arg2 += 'buzz'\n    return arg1 + arg2\n\nmy_cool_function('foo', 'fizz')\n</code></pre></li> </ol>"},{"location":"tutorials/6.1-microproject-wf/#define-a-function-to-initialize-the-population","title":"Define a function to initialize the population","text":"<p>In a new code cell define a function called <code>init</code> which takes 2 arguments. The first argument should be the size of the population in number of haploid individuals (N), and the second argument should be the frequency of derived alleles (f).</p> <p>We will model our population as a list of 0s and 1s, with 0 representing (A) and 1 representing (a). Therefore, the <code>init</code> function should return a list of length N composed of 0s and 1s (in any order), with the proportion of 1s approximately equal to f</p> <p><pre><code># Example call and desired result\ninit(N=10, f=0.5)\n</code></pre> <pre><code>[0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n</code></pre></p> Hint for init  You might use the fact that lists can be 'multiplied' to compose your population, and then use list concatenation (`+`) to join ancestral and derived groups.  <pre><code>[0] * 5\n</code></pre> <pre><code>[0, 0, 0, 0, 0]\n</code></pre>  You will also almost certainly need to use the `round` function from the standard library, to convert fractional numbers to integers.  <pre><code>f = 10/3\nprint(f)\nround(f)\n</code></pre> <pre><code>3.333333333\n3\n</code></pre>"},{"location":"tutorials/6.1-microproject-wf/#define-a-function-to-perform-one-wf-generation","title":"Define a function to perform one WF generation","text":"<p>In a new code cell define a function called <code>step</code>, which takes 1 argument. This argument (which we will call the ancestral population) should be a 'WF population' as we have defined it above (a list of length N of 0s and 1s).</p> <p>This function should return a new population of N individuals (the descendant population) with frequencies of 0s and 1s determined probabailisticly by the frequency of 0s and 1s in the ancestral pop.</p> <ul> <li>The order of individuals in the population doesn't matter (i.e. this model is 'spatially implicit'), so don't worry at all about preserving order.</li> <li>This is a stochastic process so you should use at least one fuction from the <code>random</code> module in the standard library.</li> </ul> <p><pre><code># Example call and desired result\npop = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\nstep(pop=pop)\n</code></pre> <pre><code>[1, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n</code></pre></p> Hint for step()  A very simple way to do this is using `random.choices` from the standard library. Look at the  [random.choices() documentation](https://docs.python.org/3/library/random.html#random.choices)."},{"location":"tutorials/6.1-microproject-wf/#define-a-wf-function-to-bring-it-all-together","title":"Define a wf() function to bring it all together","text":"<p>Now we will create a full WF simulation by combining the init() and step() functions from above. In a new code cell define a function called <code>wf</code> which takes 3 arguments. The first argument is N (population size), the second argument is f (derived allele frequency), and the third argument is # of generations to run.</p> <p>The result should print to the screen the number of generations run and the final frequency of the drived allele. <pre><code># Example call and desired result\nwf(N=100, f=0.2, ngens=10)\n</code></pre> <pre><code>generations: 10; freq(a): 0.4565\n</code></pre></p> Hint for wf()  Inside your function call `init` with the N and f arguments and save the result to a new variable called 'pop'. Create a new for loop using `range()` to determine the number of iterations (number of wf generations), and inside the for loop call the `step` function.  * To calculate the frequency of the derived allele you will need to count the number of derived alleles. Consider using the `sum()` function from the standard library. * After the for loop use the print function and a format string to return the results (e.g. `print(f\"steps{nsteps}\")`)"},{"location":"tutorials/6.1-microproject-wf/#further-challenges-if-time-remains","title":"Further challenges if time remains","text":"<ol> <li>Modify your <code>wf()</code> function to test for fixation or loss of allele 1. If allele 1 is fixed or lost, <code>break</code> the for loop early and modify the print statement to indicate this result in some way.</li> <li>Track allele frequency through time. Create a new list inside the wf() function and use this list to accumulate allele frequency after each call to <code>step()</code> inside the for loop.</li> <li>Advanced: Wrap the <code>wf()</code> call inside an <code>iterate_wf()</code> function that calls <code>wf</code> many times. The goal is to test the expectation that the probability of fixation of the derived allele in WF equals the initial allele frequency (e.g. run <code>wf(N=100, f=0.2, gens=1000)</code> 100 times and record how many times  allele 1 is fixed, then divide by 100. It should be ~0.2 in this example).</li> </ol>"},{"location":"tutorials/6.1-microproject-wf/#wrap-up","title":"Wrap-up","text":"<ul> <li>Add, commit, and push changes back to your <code>origin main</code> copy of the repo.</li> </ul>"},{"location":"tutorials/7.0-subprocess/","title":"subprocess","text":""},{"location":"tutorials/7.0-subprocess/#python-subprocess","title":"Python subprocess","text":"<p>Assignment instructions:</p> <ol> <li>Fork the repo https://github.com/hackers-test/hack-7-python</li> <li>Clone your copy of the repo to <code>~/hacks/</code></li> <li>Start a jupyter notebook server locally.</li> <li>Navigate to <code>~/hacks/hack-7-scripting/notebooks/</code></li> <li>Complete all notebooks in the <code>notebooks/</code> dir.</li> <li>Add, commit, and push changes back to your <code>origin main</code> copy of the repo.</li> </ol>"},{"location":"tutorials/7.0-subprocess/#resources","title":"Resources","text":"<ul> <li>Check in on the chatroom if you run into any problems.</li> <li>You can view a read-only version of the notebook assignments on nbviewer</li> </ul>"},{"location":"tutorials/7.1-think/","title":"thinking-functionally","text":""},{"location":"tutorials/7.1-think/#learning-to-think-functionally","title":"Learning to think functionally","text":"<p>As with any language, there are often many possible ways in which to  communicate the same information by using different words, or modifying  their order, and one way is not necessarily better than another.  In programming, our goal is provide a set of logical statements  to accomplish a defined task. This can usually be done with different  types of objects or routines in your code. We could evaluate different  approaches based on their speed, reliability, and readability, but in  the end we are usually most interested in the question of whether or not it works.</p> <p>Now that you have learned the basic building blocks of the Python  programming language you can begin to write useful functions for  accomplishing tasks. But how does one learn how to think functionally? In other words, how do you train your brain to think in terms of  how to solve problems by writing Python functions?</p>"},{"location":"tutorials/7.1-think/#kludge","title":"Kludge","text":"<p>The term kludge refers to  an assemblage of parts that together are sufficient to accomplish a task,  even if the solution is far from perfect. Kludging your way through computing problems is a common way to learn to code. Step 1 is to get a working  solution, and step 2 is to find ways to improve it. While this approach will eventually help you to improve, it is not necessarily the fastest way to learn. Instead, you can now take advantage of the tremendous resources that are available to you through the internet to find and learn from  existing examples of code. In the context of learning to speak a language,  you are now ready to study abroad; to learn through practice and observation of how others use the language.</p>"},{"location":"tutorials/7.1-think/#copying-code","title":"Copying code","text":"<p>So how do we learn to improve code? Use your social network. Copy code from  examples on the internet. The best places to find solutions are usually  either stackoverflow or GitHub. The former is a discussion board where people post questions and others respond and vote on the best answers. Reading these posts is a great way to learn why some coding examples are better than others. </p> <p>To find solutions in this way try googling terms such as  \"{my question} Python stack overflow\". For example,  here is a page I found by searching \"n choose k Python stack overflow\". One user asks what is the fastest way to find the number of ways to sample n combinations from  a list of k items. The responses include custom code, standard library functions,  and 3rd party libraries (e.g., scipy). You can choose among these ideas for the one that works best for your purposes. </p> <p>GitHub is not quite as easily searchable in terms of finding code snippets that will be accompanied by an explanation, but it is a great place to find examples of code being used in practice. Find a library that you really enjoy using and explore its repository on GitHub. Try to understand how it is organized, and how the main classes and functions work. We will go through some examples for this in class in the following weeks.</p>"},{"location":"tutorials/7.1-think/#thinking-atomically","title":"Thinking atomically","text":"<p>As we've discussed several times, it is a better practice to break up  operations in your code into many small functions, rather than one large function. This will allow you to more easily debug your code when it contains errors, and it to write cleaner and more readable code. Writing functions in this way can also help you to conceptualize problems, by breaking them into many smaller parts for which you can write simpler  solutions.</p>"},{"location":"tutorials/7.1-think/#thinking-functionally","title":"Thinking functionally","text":"<p>As an example, let's imagine our coding task is to search a database of biomedical publications in PDF format and to count all mentions  or references of any gene names that exist in a Human Genome database.  Before you even begin this task you should start by creating an outline of  the atomized tasks involved. For example, we could break this problem into  a number of functions where each accomplishes one of the following tasks:</p> <ul> <li>extract gene names from a biomedical database into a dict object mapping names to integer 0.</li> <li>check for special formatting of gene names and attempt to standardize (e.g., make all uppercase).</li> <li>extract text from PDFs into a dictionary mapping article name to contents.</li> <li>parse article text into list of words and format to match gene names (e.g., all uppercase).</li> <li>iterate over articles counting occurrence of all gene names among word lists in each.</li> <li>format the count results dictionary into a table and print to a file or stdout.</li> </ul> <p>Now that we have identified the main tasks involved, you can begin to  develop these in order, testing each one individually to identify that it is working properly, and then testing them in combination where the output of one can serve as input to another. As you will learn in  tutorial 7.4, the object-oriented design of Python, and in particular,  the use of <code>Class</code> objects, can help with developing code in this style.</p> <p>Proceed to the next tutorial.</p>"},{"location":"tutorials/7.2-scripting/","title":"moving to scripting","text":""},{"location":"tutorials/7.2-scripting/#getting-started-with-scripting-in-python","title":"Getting started with scripting in Python","text":""},{"location":"tutorials/7.2-scripting/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this tutorial you should: - Understand when and why to use notebooks. - Understand when and why to write Python scripts or modules.</p>"},{"location":"tutorials/7.2-scripting/#when-to-use-notebooks-versus-scripts","title":"When to use notebooks versus scripts","text":"<p>Jupyter notebooks are a fantastic tool for sharing and demonstrating code,  but they are also often misused in ways that limits their effectiveness. As you begin to work on larger projects you will likely encounter this problem, where you eventually reach a stage at which your notebook becomes cluttered  with many cell blocks containing functions definitions, but very few cells  in the notebook are actually being used to call and explore those functions.  Thus, your notebook is serving more as a script than as an interactive document.  This is not the intended use for notebooks.</p> <p>Instead, notebooks are best used as either (1) a scratchpad in which to test code and write functions; or (2) an interactive document for sharing demonstrations of code. The former should be considered a sort of temporary document, something  that you use only until the functions have been well tested, at which point you often want to export them to scripts. The second usage is your end product: a publishable interactive tutorial. The best way to reconcile these two forms of usage is to move your polished code (e.g., your many <code>def</code>  functions) into a separate set of scripts (a module), which can then be imported into the jupyter notebook. </p> <p>This is a first step on the way to developing a full-fledged software package in Python.</p>"},{"location":"tutorials/7.2-scripting/#what-is-a-script","title":"What is a script?","text":"<p>A script is just a text file that contains computer code. The file can have any name, but will usually end with a suffix that corresponds to the type of code contained within it; for example, Python files should end with <code>.py</code>. Most languages also have a  number of additional conventions about how files should be organized into folders, and/or other content in the files that indicates the type of code that is inside of them. These are usually not mandatory, but are good practice. </p> <p>Python scripts are generally used in two ways: as an executable, meaning  that it is meant to be run from the command line; or as an importable module,  meaning that it contains code that is meant to be imported and used by another  file. A single script can actually serve both of these purposes.</p>"},{"location":"tutorials/7.2-scripting/#the-format-of-a-python-script","title":"The format of a Python script","text":"<p>Below is an example Python script. It includes the following:</p> <ol> <li> <p>shebang: this is the text on the first line of the file. This tells your shell what language the script is written in. It is mostly an older convention, and will have no effect given the way we will write and execute modern Python code.</p> </li> <li> <p>A module level docstring. This is a string at the top of the file that describes the content. This could list the classes or functions that are available to be imported and used from the module, or how to  use it as an executable.</p> </li> <li> <p>import statements.</p> </li> <li> <p>The code itself. Here you put class and function definitions.</p> </li> <li> <p><code>__main__</code>: This is a special section at the bottom of a script where you put executable code. It is optional, not all scripts are meant to be executable. You can put code here that will only be run when the script is called as an executable (see example below), but it will not be run  when the file is imported (when the class and functions are loaded by  another Python script).</p> </li> </ol> <pre><code>#!/usr/bin/env python\n\"\"\"\nA description of what this script contains.\n\"\"\"\n\nimport builtins\n\n# this is where the module-type code goes\nclass Example:\n    \"This is where classes should go\"\n    def __init__(self):\n        pass\n\ndef example_func():\n    \"This is where stand-alone functions should go\"\n    pass\n\n# this is where executable-type code goes, this code is not \n# executed if this script is only imported.\nif __name__ == \"__main__\":\n    print(\"this code is not run when this file is imported.\")\n</code></pre>"},{"location":"tutorials/7.2-scripting/#running-a-python-script-as-an-executable","title":"Running a Python script as an executable","text":"<p>There are several ways to execute a Python script. The simplest is to  call the <code>python</code> program from your terminal with the script as the target. (Side note, your version of <code>python</code> will usually also have an alias called <code>python3</code> to make it clear that it is not the older <code>python2</code>). Copy the  code above into a script and call it <code>example_script.py</code>. Then execute it in your terminal like below. You can see from this example that the code we wrote in the section called <code>__main__</code> printed text to stdout, as intended.</p> <pre><code>python example_script.py\n</code></pre> <p>Do not be intimidated by the double underscores in this final section.  In Python special variable are often named in this way, and are referred to as dunders. The naming convention is strange, but you get used to it.</p> <p>Continue to the next tutorial.</p>"},{"location":"tutorials/7.3-imports/","title":"importing","text":""},{"location":"tutorials/7.3-imports/#understanding-imports-and-modules","title":"Understanding imports and modules","text":""},{"location":"tutorials/7.3-imports/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this tutorial you should:  </p> <ul> <li>Understand that Python packages are just folders full of Python scripts.  </li> <li>Understand that <code>sys.path</code> lists the locations of importable packages.  </li> <li>Be able to import custom Python packages.  </li> <li>Be familiar with how to organize Python scripts into a package.  </li> </ul>"},{"location":"tutorials/7.3-imports/#the-import-statement","title":"The <code>import</code> statement","text":"<p>The <code>import</code> statement is one of the first things located in  any Python script. It is used to load Python code from other  files located on your system. But what is it actually importing?  What do those files and folders look like?</p> <p>In your last tutorial you learned how to write a single  Python script that contains code that can be imported. This  is often referred to as a module. Here we will learn about writing  a collection of modules together in a folder, which is called a  package. Both modules and packages are very similar in the  way that <code>import</code> statements are used to access code from  Python files to make it accessible in other places.</p>"},{"location":"tutorials/7.3-imports/#organizing-a-package","title":"Organizing a package","text":"<p>Python packages are only useful when they are organized in a way  that makes it easy to understand how they should be used. Because  GitHub has become a standard place to store code, we will discuss  the organization of our code more broadly in terms of how it should be organized in a git repository. It is useful to follow a similar set of conventions whether the repo is intended as a Python software package, or if it is simply an archive of a research project.</p> <p>In either case, we will usually have the following:   </p> <ul> <li>a README file in the top level directory describing the project.  </li> <li>a code directory (that can take different names) containing Python code.  </li> <li>a notebooks directory containing demonstrations/analyses of the code.  </li> <li>a data directory containing example data to be analyzed in the notebooks.  </li> </ul> <p>Here we will focus on the structure of your code directory.  You have already cloned the repo <code>hack-7-python</code> which currently contains only a README file and notebooks directory. Let's create an additional folder to contain our scripts, called <code>mypackage</code>, and add an empty file  to this folder called <code>mymodule.py</code>. You can do this from your terminal by following the code block below.</p> <pre><code># make sure we are located in the repo dir\ncd ~/hacks/hack-7-python\n\n# make a new subdirectory \nmkdir -p mypackage/\n\n# make an empty file \ntouch ./mypackage/mymodule.py\n</code></pre>"},{"location":"tutorials/7.3-imports/#file-trees","title":"File trees","text":"<p>As an aside, let's install and use an interesting tool for visualizing the  filestructure of our repository. This will make it easier to keep track of  and understand how our files are organized, especially as we continue to  make more complex modules with many files. Use conda from your terminal to install the program <code>tree</code>:</p> <pre><code>conda install tree -c conda-forge\n</code></pre> <p>We can now use the <code>tree</code> command from within our repo to view the  file structure in a nicely formatted \"file tree\" design. In the  next sections our goal will be to put Python code into the mymodule.py file located in the mypackage folder, and to be able to import that code into a notebook located in the notebooks directory.</p> <pre><code>tree .\n</code></pre> <pre>\n.\n\u251c\u2500\u2500 mypackage\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 mymodule.py\n\u251c\u2500\u2500 notebooks\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 nb-7.0-subprocess.ipynb\n\u2514\u2500\u2500 README.md\n\n2 directories, 7 files\n</pre>"},{"location":"tutorials/7.3-imports/#tldr-a-video-demonstration","title":"TLDR; a video demonstration","text":"Watch the video below for a visual demonstration of what we plan to accomplish,  and then follow along with the rest of the tutorial for a slower paced  explanation. Click to make video larger.           Sorry, your browser doesn't support embedded videos."},{"location":"tutorials/7.3-imports/#write-a-python-module","title":"Write a Python module","text":"<p>Let's add a simple function to the mymodule.py file. In the video example  above I wrote a short py script. Here you can just copy the code below and paste it into the file using <code>nano</code> or another text editor.</p> <p><pre><code># open the myscript.py file in the nano text editor\nnano ./mypackage/mymodule.py\n</code></pre> Copy and paste the code below into the myscript.py file and save and close it.</p> <pre><code>#!/usr/bin/env python\n\"magic eight ball function to tell your future.\"\n\nimport random\n\ndef magic_eight_ball():\n    \"\"\"\n    Returns a random statement from a magic eight ball containing\n    a 10 sided die (I was too lazy to write all 20 typical answers)\n    https://en.wikipedia.org/wiki/Magic_8-Ball\n    \"\"\"\n    RESPONSES = {\n        0: \"It is certain.\",\n        1: \"It is decidedly so.\",\n        2: \"Without a doubt.\",\n        3: \"Yes \u2013 definitely.\",\n        4: \"You may rely on it.\",\n        5: \"Reply hazy, try again.\",\n        6: \"Better not tell you now.\",\n        7: \"Cannot predict now.\",\n        8: \"My reply is no\",\n        9: \"Outlook not so good\",\n        10: \"Very doubtful\",\n    }\n    return RESPONSES[random.choice(range(10))]\n</code></pre>"},{"location":"tutorials/7.3-imports/#importing-design","title":"Importing design","text":"<p>So far you have learned how to use the <code>import</code> statement to import code from Python packages and/or modules that are part of the standard library.  These are a collection of Python scripts organized into folders, similar to what you will be creating here. As an example, we learned about the <code>os.path</code> module in an earlier tutorial, which is used to format file path strings. This module is part of the <code>os</code> package. The functions located in the <code>path</code> module can be accessed in several ways from the <code>os</code> package:</p> <p><pre><code>import os\nos.path.join\n</code></pre> <pre><code>from os import path\npath.join\n</code></pre> <pre><code>from os import *\npath.join\n</code></pre> <pre><code>from os.path import join\njoin\n</code></pre></p> <p>Our goal here will be to design our package in the same way, so that you can import the function <code>magic_eight_ball()</code> from <code>mypackage.mymodule</code>  in all of these same ways. </p>"},{"location":"tutorials/7.3-imports/#packages-and-modules","title":"Packages and modules","text":"<p>A module is a script that can be imported. A package is a folder full of modules. The dot format in the example above, where the file or  function names are nested within another name, is meant to recapitulate the file structure in which these files or functions are written.</p> <p>So far we have a folder (package) and a file (module) and within it a function. Does this mean that we can now import this code from any other Python file? No. We need to do a few more steps to make it possible for Python to know that this package can be imported. For this, we need to learn about <code>sys.path</code>: the location where Python looks for modules. This is simply a list of filepaths  represented as strings. </p> <code>import</code> can only import packages or modules from folders  listed in <code>sys.path</code>. By default this will include only the location of standard library packages in <code>~/miniconda3/python3.8/</code>, of other installed packages (e.g., by conda or pip) in <code>~/miniconda3/python3.8/site-packages</code>, as well as your current directory  (<code>./</code>).      Here we will learn how to add additional paths to the  <code>sys.path</code> variable so that we an import any code. This is particularly useful (1) during code development; or (2) for importing a small number of scripts that do not compose a  full library.      Later we will learn to design packages that are installable, meaning that they will be copied into the  (<code>~/miniconda3/python3.8/site-packages</code>) dir where other packages are located.  <p>Open a new notebook from in the notebooks dir and rename it <code>import-test</code>  and follow along. From inside the notebook import the <code>sys</code> package from  the standard library and examine the <code>sys.path</code> variable. (see the video tutorial above to make sure you are following as intended.)</p> <pre><code># import sys from the standard lib\nimport sys\nprint(sys.path)\n</code></pre> <p>To add new locations for Python to find packages you can append a new string to the <code>sys.path</code> list. This new string should point to the parent directory of  your package (the directory containing the package directory). The path can be written as either a full path or relative path. Because we are currently located within a notebook in the <code>notebooks/</code> dir, the <code>mypackage</code> dir is located up one directory (in the parent directory of our current dir). See the <code>tree</code> output above to  confirm this. Therefore we can add our current parent dir to the <code>sys.path</code>  to make the <code>mypackage/</code> folder importable. (Using a relative path as opposed to a full path here is actually preferred, since if someone else cloned our repo and ran the code in this notebook, it would be able to find and import the code from the parent dir (<code>..</code>) without requiring them to change the path, which they otherwise would need to do if writing a fullpath.)</p> <pre><code>import sys\n\n# append your current parent dir to the sys.path list\nsys.path.append(\"../\")\n\n# show the updated sys.path \nprint(sys.path)\n</code></pre> <pre>\n['/home/deren/miniconda3/envs/dev/bin',\n '/home/deren/miniconda3/envs/dev/lib/python38.zip',\n '/home/deren/miniconda3/envs/dev/lib/python3.8',\n '/home/deren/miniconda3/envs/dev/lib/python3.8/lib-dynload',\n '/home/deren/miniconda3/envs/dev/lib/python3.8/site-packages',\n '/home/deren/miniconda3/envs/dev/lib/python3.8/site-packages/IPython/extensions',\n '/home/deren/.ipython',\n '..']\n</pre>"},{"location":"tutorials/7.3-imports/#why-does-this-make-mypackage-importable","title":"Why does this make <code>mypackage</code> importable?","text":"<p>Any folder that is located inside of one of the folders listed above can be imported. The <code>mypackage</code> folder is located in the filepath that we  appended to the end of the list (<code>../</code>). This will make the following <code>import</code> statements available to us that will allow us to access the  <code>magic_eight_ball()</code> function in the <code>mymodule</code> script. You can test this from your notebook, and you can also explore what is accessible to import from each object by using tab-completion.</p> <p><pre><code>import mypackage.mymodule\nmypackage.mymodule.magic_eight_ball()\n</code></pre> <pre><code>from mypackage import mymodule\nmymodule.magic_eight_ball()\n</code></pre> <pre><code>from mypackage.mymodule import magic_eight_ball\nmagic_eight_ball()\n</code></pre></p> <p>The only method that is not yet supported is to be able to import the  package name alone and access all objects nested within it. This is slightly  different from the first example above, and would look like this:</p> <p><pre><code># this workflow is not yet supported\nimport mypackage\nmypackage.mymodule.magic_eight_ball()\n</code></pre> This last method is particularly convenient, since it allows the user to  explore the entire package themselves to find any objects that might be  useful. So how do we support this last method?</p>"},{"location":"tutorials/7.3-imports/#the-__init__py-script","title":"The <code>__init__.py</code> script","text":"<p>To support this last mode for <code>import</code> we need to learn about a special file called <code>__init__.py</code>. You can tell it is special because it uses the dunder naming convention. An init file is a file that is  automatically run when a package is imported. It is placed inside of  a folder and used to <code>import</code> other files or folders that are nested within this folder. By using an <code>__init__.py</code> file to only select some of the subfolders or files in a folder you can limit or expand  the scope of what the user will see when using tab-completion to search  for possible importable modules. This is a useful design feature that  can be used to organize your code so that all of the most useful class and function objects are accessible from the top level package name, or from particular modules. Let's create an init file and edit its contents:</p> <pre><code># add an __init__.py file to the mypackage dir\ncd ~/hacks/hack-7-python/\ntouch mypackage/__init__.py\nnano mypackage/__init__.py\n</code></pre> <p>In the <code>__init__.py</code> file we will add a shebang and docstring, and then add an import statement. In this case the import is making it so that the package will automatically import the module. In other words, <code>mypackage.mymodule</code> will be automatically imported. Here we use the convention <code>from .</code> to tell it where to the mymodule module is located, where <code>.</code> means the current directory.</p> <pre><code>#!/usr/bin/env python\n\"\"\"\nThe mypackage package is used to learn about package filestructure.\n\"\"\"\nfrom . import mymodule\n</code></pre> <p>Now if we restart the notebook and update our <code>sys.path</code> variable as before, we should be able to access all contents of the mypackage  folder from the top level name. In addition, we can view a docstring  for the package which we defined in the init file.</p> <pre><code># add our local package scope to sys.path\nimport sys\nsys.path.append(\"..\")\n\n# access our module function from the package-level import\nimport mypackage\nmypackage.mymodule.magic_eight_ball()\n\n# show the package-level docstring\nmypackage?\n</code></pre>"},{"location":"tutorials/7.3-imports/#summary","title":"Summary","text":"<ul> <li>modules are Python scripts located inside folders.</li> <li>packages are folders containing one or more modules. </li> <li>Both of these things can be imported, allowing you to access folders, files, or code objects within them.</li> <li>An <code>__init__.py</code> file can be used to make objects nested within a package (modules or their contents) accessible from the higher-level imported  object (package).</li> <li>Packages or modules can be imported if they are in your <code>sys.path</code> variable.</li> <li>You can edit <code>sys.path</code> to add new paths to it to make your code importable.</li> <li>We will learn later how to make packages 'installable', such that they will  automatically be added to your <code>sys.path</code>.</li> </ul>"},{"location":"tutorials/7.3-imports/#assessment","title":"Assessment","text":"Ensure that your code is working and can successfully import and run the code in the block above. If it is working then save and close your notebook. Use git to add, commit, and push your mypackage/ dir and  your test notebook to your forked git repo for grading."},{"location":"tutorials/8.0-wf-class/","title":"Implementing the Wright-Fisher Model as a Class","text":""},{"location":"tutorials/8.0-wf-class/#wrapping-our-wright-fisher-simulator-in-a-class","title":"Wrapping our Wright-Fisher simulator in a Class","text":"<p>In previous sessions we implemented the Wright-Fisher (WF) model  using a few simple python functions. This works great for running a few simulations by hand, but for projects of even modest complexity this 'flat' structure of unorganized function calls can quickly become very difficult to understand or operate. In this session we will convert the WF model into a python 'Class' which is a structured way to organize data and code.</p>"},{"location":"tutorials/8.0-wf-class/#a-word-about-object-oriented-programming","title":"A word about Object Oriented programming","text":"<p>Object Oriented programming (OOP) is based on the idea that we can structure our computer programs in a more natural way that aligns with how we interact with everyday 'things'. In OOP we define 'Classes' of objects, and these classes encapsulate attributes and functions that define how we interact with them. Here is a cartoon example of how Classes can usefully encapsulate functions and help us organize our interactions.</p> <p>Let us assume that we are interested in \"dressing\" things, so we will define a function called <code>dress()</code>. If we make a salad it's easy to see how we could define a procedure to <code>dress(salad)</code>, you just pour it on. However, after you eat the salad and your baby wakes up from a nap, it's time to <code>dress()</code> the  baby. We probably would want an entirely different procedure for this! Without OOP we would need to do  something like this:</p> <p><pre><code>def dress(thing_to_dress):\n    if thing_to_dress == \"Caesar\":\n        # Pour the dressing on\n    elif thing_to_dress == \"Cupie\": # &lt;- The baby's name\n        # Put on the bonnet and onesie\n    else:\n        print(\"I don't know how to dress that.\")\n</code></pre> Hopefully it is obvious that as the number of things you want to dress increases, the size of this function will grow, and also the logic for how to interact with these very different things will get all tangled up.</p> <p>With OOP we can encapsulate the logic of how to <code>dress()</code> something inside a 'class method'. This has numerous benefits, most importantly that you won't accidentally cover your baby with ranch.</p> <p>Alert</p> <p>For now ignore the <code>self</code> argument to the <code>dress()</code> methods. This is a formal requirement of python class methods that we will explain in a moment.</p> <p><pre><code>class Baby:\n    def dress(self):\n        print(\"Dress the baby\")\n\nclass Salad:\n    def dress(self):\n        print(\"Dress the salad\")\n\nb = Baby()\nb.dress()\n</code></pre> <pre><code>Dress the baby\n</code></pre></p>"},{"location":"tutorials/8.0-wf-class/#assignment-instructions","title":"Assignment instructions","text":"<ol> <li>Launch a jupyter server on your local computer</li> <li>Navigate to <code>~/hacks/hack-5-python/notebooks</code> directory and open your <code>wf-sim.ipynb</code> notebook</li> <li>At the top of your notebook make sure that you have a cell that calls <code>import random</code>, we will need this for the future.</li> <li>In this exercise we will define a new class to implement the WF simulation using the functions we defined previously.</li> </ol>"},{"location":"tutorials/8.0-wf-class/#class-definition-and-the-class-keyword","title":"Class definition and the <code>class</code> keyword","text":"<p>The <code>class</code> keyword indicates to python your intention to define a new class. Choosing the name of classes is important for reducing the cognitive burden of understanding and manipulating your code. It might be tempting to call our new class <code>WF</code> because this is the name of the model, but this conflates the 'object' that we want to manipulate (which is the population), with the process that we want to implement (the discrete time, birth/death process with non-overlapping generations). Let's call our class 'Population' because this more precisely captures the object-ness of the concept we want to represent.</p> <p><pre><code>class Population:\n    pass\n</code></pre> That's it, you have defined your first python class. You can instantiate a new <code>Population</code> object, but it doesn't do much yet because <code>pass</code> is a python keyword that means \"don't do anything\". </p> <pre><code>p = Population()\n</code></pre>"},{"location":"tutorials/8.0-wf-class/#initializing-class-attributes-with-the-__init__-method","title":"Initializing class attributes with the <code>__init__()</code> method","text":"<p>Recall that when we defined the <code>init()</code> function for our WF model we specified two required arguments: <code>N</code> as the size of the population in number of individuals, and <code>f</code> as the frequency of the derived allele. Let's maintain this requirement in our <code>Population</code> class, and we can do this by defining the <code>__init__()</code> method, which is a special class method called upon class instantiation (when you create an instance of a new class).</p> <p><pre><code>class Population:\n    def __init__(self, N, f):\n        self.N = N\n        self.f = f\n\n        derived_count = round(N*f)\n        self.pop = [0] * (N - derived_count) + [1] * derived_count\n</code></pre> Like all class methods (functions that reside within and operate on classes), the <code>__init__()</code> method  is declared with an explicit first argument representing the object which is canonically and universally called <code>self</code>. This argument is provided implicitly by the call to a given class method. It is confusing at first, but you will get the hang of it.</p> <p>In this <code>__init__()</code> method we do a few things. First we define the <code>self.N</code> and <code>self.f</code> attributes and set them equal to the passed in values. Then we copy in the code from our previous <code>init()</code> function and define another class attribute called <code>self.pop</code> to contain our list of ancestral (0) and derived (1) alleles.</p> <p>What happens when you try to instantiate a new instance of this <code>Population()</code> class without passing arguments? In this case you do get a helpful error message:</p> <p><pre><code>p = Population()\n</code></pre> <pre><code>---------------------------------------------------------------------------\nTypeError                                 Traceback (most recent call last)\nCell In[10], line 5\n      3         self.N = N\n      4         self.f = f\n----&gt; 5 p = Population()\n\nTypeError: Population.__init__() missing 2 required positional arguments: 'N' and 'f'\n</code></pre></p> <p>Because we specified two arguments without defaults to the <code>__init__()</code> method, the <code>Population</code> class knows that these are required and forbids creating new instances without passing these arguments. We have two options here: 1) Pass in values for <code>N</code> and <code>f</code>; or 2) Set 'reasonable' default values. Reasonable default values are helpful in many cases, so let's do it that way.</p> <p><pre><code>class Population:\n    def __init__(self, N=10, f=0.2):\n        self.N = N\n        self.f = f\n\n        derived_count = round(N*f)\n        self.pop = [0] * (N - derived_count) + [1] * derived_count\n\np = Population()\nprint(f\"N={p.N} f={p.f}\")\n</code></pre> <pre><code>N=10 f=0.2\n</code></pre></p> <p>Now we can create a new <code>Population</code> instance without passing arguments, and it will  take the default values, if we don't specify alternate values.</p>"},{"location":"tutorials/8.0-wf-class/#creating-printable-representations-of-an-object-with-__repr__","title":"Creating printable representations of an object with <code>__repr__()</code>","text":"<p>It's often useful (and good practice) to allow objects to be printed to the screen in a meaningful way. In the previous code we had to format our own string representation of the <code>Population</code> object (which we assigned to the variable <code>p</code>) and  this is annoying if you have to do it many times. Python classes have another special  method called <code>__repr__()</code> which you may define to provide functionality to print objects  in a human readable way. If you define <code>__repr__()</code> then this method is invoked when an  object is evaluated or when it is passed to <code>print()</code>.</p> <p><pre><code>class Population:\n    def __init__(self, N=10, f=0.2):\n        self.N = N\n        self.f = f\n\n        derived_count = round(N*f)\n        self.pop = [0] * (N - derived_count) + [1] * derived_count\n\n    def __repr__(self):\n        return f\"Population(N={self.N}, f={self.f})\"\n\np = Population()\np\n</code></pre> <pre><code>Population(N=10, f=0.2)\n</code></pre></p>"},{"location":"tutorials/8.0-wf-class/#defining-a-class-method-to-implement-the-wf-step-function","title":"Defining a class method to implement the WF <code>step()</code> function","text":"<p>Recall that our previous implementation of the WF function took several arguments in the form of <code>wf(N, f, ngens)</code> and that it internally called the <code>init()</code> and <code>step()</code> functions. Because our <code>Population</code> class is aware of <code>N</code> and <code>f</code> we can simplify things by condensing the argument list for the <code>Population.step()</code> method to include only the <code>ngens</code> parameter. Notice that we gain additional benefits of simplification here because of the encapsulation of the <code>N</code>, <code>f</code>, and <code>pop</code> member attributes of the <code>Population</code> object.</p> <pre><code>class Population:\n    def __init__(self, N=10, f=0.2):\n        self.N = N\n        self.f = f\n\n        derived_count = round(N*f)\n        self.pop = [0] * (N - derived_count) + [1] * derived_count\n\n    def __repr__(self):\n        return f\"Population(N={self.N}, f={self.f})\"\n\n    def step(self, ngens=1):\n        for i in range(ngens):\n            self.pop = random.choices(self.pop, k=len(self.pop))\n</code></pre> <p>Now with our <code>Population</code> class defined, we can access all the code that we had previously called using many different functions in a very simple way: <pre><code>p = Population()\np.step(ngens=10)\np.pop\n</code></pre> <pre><code>[0, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n</code></pre></p>"},{"location":"tutorials/8.0-wf-class/#searching-for-efficiencies-in-code","title":"Searching for efficiencies in code","text":"<p>When we originally defined the <code>step()</code> function we only passed in the <code>pop</code> argument which was the list of ancestral and derived alleles. Because our original <code>step()</code> function didn't know anything about this pop we had to calculate <code>len(pop)</code> to set the value for the <code>k</code> argument for <code>random.choices()</code>. This is wildly inefficient, as we know the size of the population is fixed and constant for a given simulation, so we are needlessly recalculating <code>len(self.pop)</code> over and over again. We can take advantage of the <code>N</code> attribute of the <code>Population</code> object to release ourselves from having to do this pointless recalculation.</p> <pre><code>class Population:\n    def __init__(self, N=10, f=0.2):\n        self.N = N\n        self.f = f\n\n        derived_count = round(N*f)\n        self.pop = [0] * (N - derived_count) + [1] * derived_count\n\n    def __repr__(self):\n        return f\"Population(N={self.N}, f={self.f})\"\n\n    def step(self, ngens=1):\n        for i in range(ngens):\n            self.pop = random.choices(self.pop, k=self.N)\n</code></pre> <p>And we can use a special jupyter 'magic' command to time the difference between class attribute access (<code>p.N</code>) and the length calculation (<code>len(p.pop)</code>). The <code>%%timeit</code> magic command is placed at the beginning of a jupyter notebook cell to evaluate performance of the code inside a cell. By default it will run several iterations of the code to calculate runtime (but this can be modified by including information about how many iterations you want to run, e.g. <code>%%timeit -n 2</code>).</p> <pre><code># Make the population large to evaluate performance for large populations\np = Population(1000000000)\n</code></pre> <p><pre><code>%%timeit\np.N\n</code></pre> <pre><code>27.9 ns \u00b1 0.0758 ns per loop (mean \u00b1 std. dev. of 7 runs, 10,000,000 loops each)\n</code></pre></p> <p><pre><code>%%timeit\nlen(p.pop)\n</code></pre> <pre><code>60.7 ns \u00b1 1.32 ns per loop (mean \u00b1 std. dev. of 7 runs, 10,000,000 loops each)\n</code></pre></p> <p>More than twice as fast with this small modification!</p>"},{"location":"tutorials/8.0-wf-class/#further-challenges-if-time-remains","title":"Further challenges if time remains","text":"<ol> <li>Create a new <code>isMonomorphic()</code> method for your <code>Population()</code> class to test whether the population is fixed for either the ancestral or derived state. This method should return <code>True</code> if the population is monomorphic for either the ancestral or derived state, and <code>False</code> otherwise.</li> <li>Modify your <code>step()</code> method to test for fixation with the <code>isMonomorphic()</code> method and terminate further execution if the test passes. You will need to use conditional branching and the <code>break</code> keyword in the case that fixation has happened. </li> <li>Track allele frequencies through time. Create a new attribute of the <code>Population</code> class called <code>freqs</code> inside the <code>__init__()</code> method. This attribute should be an empty list to begin with (e.g. <code>[]</code>), and it should be updated within the for loop of the <code>step()</code> method to append the current frequency of the derived allele.</li> </ol>"},{"location":"tutorials/8.0-wf-class/#wrap-up","title":"Wrap-up","text":"<ul> <li>Add, commit, and push changes back to your <code>origin main</code> copy of the repo.</li> </ul>"},{"location":"tutorials/8.1-data-science/","title":"data science","text":""},{"location":"tutorials/8.1-data-science/#python-data-science","title":"Python Data Science","text":""},{"location":"tutorials/8.1-data-science/#numpy-and-pandas","title":"Numpy and Pandas","text":"<p>The <code>numpy</code> and <code>pandas</code> libraries are the core of data science in Python. The numpy <code>ndarray</code> and pandas <code>DataFrame</code> class objects are custom classes that can be used to store, visualize, and operate on structured data.  Here we will explore how you can use these custom classes within your own code to leverage the power of these modules to improve efficiency and add power and flexibility.</p>"},{"location":"tutorials/8.1-data-science/#recap","title":"Recap","text":"<p>The past few sessions you have been developing a micro-project in the <code>wf.ipynb</code> notebook. The goal of this was to create simple functions to implement the Wright-Fisher process of genetic drift, and then to wrap these functions in a class. At the end of the in-class exercise we saw a bit about performance evaluation, and how small changes can have big effects on runtime. Here</p>"},{"location":"tutorials/8.1-data-science/#numpy-challenge-add-data-science-to-your-micro-project","title":"Numpy Challenge: Add data science to your micro-project","text":"<p>Your challenge today is to return to your program and re-implement the  internal data structures and code to use numpy arrays and vectorized functions, instead of python native lists and standard library functions. You will then do some performance evaluation to see how large a difference this makes.</p> <p>To complete this assignment you will need to do the following:</p> <ul> <li>Add a new parameter to your <code>__init__</code> method called <code>with_np</code> and set the default to False. Store this value as a class attribute.</li> <li>Add a new conditional branch inside <code>__init__</code> to test for this flag, and if True you will implement the <code>self.pop</code> attribute using numpy arrays.</li> <li>Modify your <code>step()</code> method to test the <code>with_np</code> attribute, and if True use numpy vectorized functions to replace <code>random.choice()</code>.</li> <li>In a new cell and instantiate two new objects of type <code>Population</code>, one called <code>pop</code> and the other <code>pop_np</code>, set the population size to 100 and set the <code>with_np</code> flag appropriately given the name of these objects.</li> <li>Now you will create two new cells to use <code>%%timeit</code> to test the performance of each of these. In each cell you will have one call to <code>step()</code> initially setting <code>ngens=1000</code>, with one cell for <code>pop</code> and the other for <code>pop_np</code>.</li> <li>Evaluate the performance of the numpy code across a range of population sizes and numbers of generations. In a new cell use markdown to record and document your findings. What did you find and what do you conclude from this?</li> </ul>"},{"location":"tutorials/8.1-data-science/#pandas-challenge-revisiting-the-iris-data-exploration","title":"Pandas Challenge: Revisiting the Iris data exploration","text":"<p>Now we will revisit the Iris data again, whereas before we used bash, and then pure python to manipulate this data, now we will use pandas and the <code>DataFrame</code> class.</p> <ul> <li>Create a new notebook called <code>iris_pd.ipynb</code> in the same directory as  <code>wf.ipynb</code> (it should be in <code>hack-5-python/notebooks</code>).</li> <li>Import any modules you man need in a new cell at the top of this notebook.</li> <li>Fetch the iris data using  the <code>requests</code> module.</li> <li>Load the iris data into a pandas DataFrame. This version of the data does not have a 'header' to indicate the meanings of the columns, so you will need to know that the 5 columns in the dataset are sepal length and width, petal length and width, and species ID. (Hint: use the <code>names</code> parameter of <code>pd.read_csv</code>).</li> <li>First, again fix the rows with the misspelled species IDs and remove the rows with <code>NA</code>.</li> <li>Use the <code>describe()</code> method to show summary statistics over the numerical valued columns. This is cool, but maybe not very intereting because it doesn't show us anything about differences among species.</li> <li>We can split the dataframe into 'groups' based on shared column values using the <code>groupby</code> method. <code>groupby</code> returns an iterable over tuples in the form of (group label, group data). Combine <code>groupby</code> and <code>describe</code> to print summary stats for each of the three species. (Hint: There are many ways to do this, you might use a <code>for</code> loop and unpack the tuples with indexing inside the loop).</li> <li>What conclusions do you draw from an informal inspection of these values?</li> <li>Challenge: Perform formal tests for differences in group means using <code>ttest_ind</code> from the <code>scipy.stats</code> module (you may need to <code>conda install -c conda-forge scipy</code> first. Hint: You can access the data for a specific group using the <code>get_group()</code> method of the groupby object, e.g. if I called my groupby object <code>gb</code> I could say `gb.get_group(\"Iris-setosa\") and it would return a DataFrame for the data for only these samples).</li> </ul>"},{"location":"tutorials/8.1-data-science/#assignment","title":"Assignment","text":"Commit and push updates to your repo before Monday."},{"location":"tutorials/9.0-scripting/","title":"moving to scripting","text":""},{"location":"tutorials/9.0-scripting/#getting-started-with-scripting-in-python","title":"Getting started with scripting in Python","text":""},{"location":"tutorials/9.0-scripting/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this tutorial you should:</p> <ul> <li>Understand the basic building-blocks of a python script</li> <li>Understand how the <code>__main__</code> keyword defines the behavior of the script</li> <li>Be able to use <code>argparse</code> to allow scripts to accept arguments of different kinds.</li> <li>Use <code>print</code> statements for simple debugging</li> </ul>"},{"location":"tutorials/9.0-scripting/#what-is-a-script","title":"What is a script?","text":"<p>A script is just a text file that contains computer code. Python scripts should end  with <code>.py</code>. Python scripts are executable at the command line, and this makes them very useful for developing bioinformatics tools. Let's see how scripts are developed.</p>"},{"location":"tutorials/9.0-scripting/#hello-world-the-simplest-example-script","title":"Hello world, the simplest example script","text":"<p>Here is the simplest executable python script (which I will call <code>myFirstScript.py</code>). <pre><code>#!/usr/bin/env python\n\nif __name__ == \"__main__\":\n    print(\"Hello world\")\n</code></pre></p> <p>You can probably guess what this script does, but you can try running it yourself on the command line: <code>python myFirstScript.py</code>.</p> <p>What makes this script executable is the funny looking <code>if __name__ == \"__main__\"</code> conditional test. Everything inside this if statement is run when the code is executed at the command line.</p>"},{"location":"tutorials/9.0-scripting/#adding-imports-and-functions","title":"Adding imports and functions","text":"<p>Lets add a bit of functionality to generate a random password of a given length. We'll need the <code>string</code> and <code>random</code> from the standard library, so we'll import those at the top (as usual).</p> <p>Now we write a new function inside our script called <code>random_password</code> which accepts 1 argument, being the length of the password, and we call this function from inside the <code>__main__</code> block. <pre><code>#!/usr/bin/env python\n\nimport random\nimport string\n\ndef random_password(length=10):\n    # Define the set of available characters to sample from\n    chars = string.ascii_letters + string.digits + string.punctuation\n\n    # Generate a sample from this list\n    password = random.choices(chars, k=length)\n\n    # password is a list of characters here so `join` them together into\n    # a string\n    return \"\".join(password)\n\nif __name__ == \"__main__\":\n    print(random_password())\n</code></pre></p>"},{"location":"tutorials/9.0-scripting/#adding-flexibility-with-arguments","title":"Adding flexibility with arguments","text":"<p>This is great because the passwords look strong, but what if you want to generate passwords of different lengths? The <code>argparse</code> module gives you a powerful way of adding command line arguments to your python scripts. Let's import it at the top of the file (Note: <code>imports</code> are normally sorted alphabetically, unless you have a good reason not to).</p> <pre><code>#!/usr/bin/env python\n\nimport argparse\nimport random\nimport string\n\ndef random_password(length=10):\n    chars = string.ascii_letters + string.digits + string.punctuation\n    password = random.choices(chars, k=length)\n    return \"\".join(password)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-l\", help=\"Password length in characters\", \n                        dest='length', type=int, default=10)\n    args = parser.parse_args()\n\n    print(random_password(length=args.length))\n</code></pre> <p>There are 3 things happening here, most of the action is in the second part (adding new arguments to the parser):</p> <ul> <li>You create the <code>parser</code> object</li> <li>You add arguments to the <code>parser</code>, which themselves can take many different arguments</li> <li>You call <code>parse_args()</code> to return a dictionary-like object containing data for the arguments specified.</li> </ul> <p>When declaring arguments there can be few or many argument parameters. In the above example these were:</p> <ul> <li><code>-l</code>: The command line flag to identify this argument</li> <li><code>help</code>: The help message to print for argument usage</li> <li><code>dest</code>: The destination variable for the value of this argument (notice that we access the value as <code>args.length</code>)</li> <li><code>type</code>: The <code>int</code> type directs argparse to cast the value to an integer</li> <li><code>default</code>: Set the default value, in the case no value is passed in for this argument. If no default is set then the command line will complain about missing required values.</li> </ul> <p>Here's another nice thing argparse does for you. It automatically generates a helpful  help message when <code>-h</code> is passed in at the command line, e.g.:</p> <pre><code>$ python myFirstScript.py -h\nusage: myFirstScript.py [-h] [-l L]\n\noptions:\n  -h, --help  show this help message and exit\n  -l L        Password length in characters\n</code></pre>"},{"location":"tutorials/9.0-scripting/#providing-helpful-information-with-verbose","title":"Providing helpful information with <code>verbose</code>","text":"<p>It's very common for command line programs to have a flag for increasing the verbosity (printing more progress messages). This can also be very helpful for debugging programs, as it allows you to toggle how much or how little your program is communicating to you (which, if it is working fine you probably want it to communicate very little besides the target output).</p> <pre><code>#!/usr/bin/env python\n\nimport argparse\nimport random\nimport string\n\ndef random_password(length=10, verbose=False):\n    if args.verbose:\n        print(f\"Generating password length: {length}\")\n    chars = string.ascii_letters + string.digits + string.punctuation\n    password = random.choices(chars, k=length)\n    return \"\".join(password)\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"-l\", help=\"Password length in characters\", \n                        dest='length', type=int, default=10)\n    parser.add_argument(\"-v\", \"--verbose\", help=\"increase output verbosity\",\n                    action=\"store_true\")\n    args = parser.parse_args()\n\n    if args.verbose:\n        print(args)\n\n    print(random_password(length=args.length, verbose=args.verbose))\n</code></pre> <p>Above we added one more argument now called <code>verbose</code>. Here we are doing a couple things different: We specify that it can be invoked either as <code>-v</code> or as <code>--verbose</code>, and we now tell it to <code>action=\"store_true\"</code>. The <code>store_true</code> action sets the value of <code>verbose</code> to True if it is invoked, and False otherwise.</p> <p>The other thing we did is to propagate the <code>verbose</code> argument into the <code>random_password</code> function, so that we can also toggle verbosity inside this function. This is a very common practice in python scripts.</p> <p>Check the help message of the new function: <pre><code>$ python myFirstScript.py -h\nusage: myFirstScript.py [-h] [-l LENGTH] [-v]\n\noptions:\n  -h, --help     show this help message and exit\n  -l LENGTH      Password length in characters\n  -v, --verbose  increase output verbosity\n</code></pre></p> <p>And check the output with the new arguments: <pre><code>$ python myFirstScript.py -v -l 30\nNamespace(length=30, verbose=True)\nGenerating password length: 30\n;GCM5y20&gt;s+^zOF~QG,M@A+80N[6;#\n</code></pre></p>"},{"location":"tutorials/9.1-wf-script/","title":"Implementing the WF model in a script","text":""},{"location":"tutorials/9.1-wf-script/#getting-started-with-scripting-in-python","title":"Getting started with scripting in Python","text":""},{"location":"tutorials/9.1-wf-script/#learning-objectives","title":"Learning objectives","text":"<p>By the end of this tutorial you should:</p> <ul> <li>Understand when and why to use notebooks.</li> <li>Understand when and why to write Python scripts or modules.</li> </ul>"},{"location":"tutorials/9.1-wf-script/#when-to-use-notebooks-versus-scripts","title":"When to use notebooks versus scripts","text":"<p>Jupyter notebooks are a fantastic tool for sharing and demonstrating code,  but they are also often misused in ways that limits their effectiveness. As you begin to work on larger projects you will likely encounter this problem, where you eventually reach a stage at which your notebook becomes cluttered  with many cell blocks containing functions definitions, but very few cells  in the notebook are actually being used to call and explore those functions.  Thus, your notebook is serving more as a script than as an interactive document.  This is not the intended use for notebooks.</p> <p>Instead, notebooks are best used as either (1) a scratchpad in which to test code and write functions; or (2) an interactive document for sharing demonstrations of code. The former should be considered a sort of temporary document, something  that you use only until the functions have been well tested, at which point you often want to export them to scripts. The second usage is your end product: a publishable interactive tutorial. The best way to reconcile these two forms of usage is to move your polished code (e.g., your many <code>def</code>  functions) into a separate set of scripts (a module), which can then be imported into the jupyter notebook. </p> <p>This is a first step on the way to developing a full-fledged software package in Python.</p>"},{"location":"tutorials/9.1-wf-script/#what-is-a-script","title":"What is a script?","text":"<p>A script is just a text file that contains computer code. The file can have any name, but will usually end with a suffix that corresponds to the type of code contained within it; for example, Python files should end with <code>.py</code>. Most languages also have a  number of additional conventions about how files should be organized into folders, and/or other content in the files that indicates the type of code that is inside of them. These are usually not mandatory, but are good practice. </p> <p>Python scripts are generally used in two ways: as an executable, meaning  that it is meant to be run from the command line; or as an importable module,  meaning that it contains code that is meant to be imported and used by another  file. A single script can actually serve both of these purposes.</p>"},{"location":"tutorials/9.1-wf-script/#the-format-of-a-python-script","title":"The format of a Python script","text":"<p>Below is an example Python script. It includes the following:</p> <ol> <li> <p><code>#!</code> (say 'hash bang'): this is the text on the first line of the file. This tells your shell what language the script is written in. It is mostly an older convention, and will have no effect given the way we will write and execute modern Python code.</p> </li> <li> <p>A module level docstring. This is a string at the top of the file that describes the content. This could list the classes or functions that are available to be imported and used from the module, or how to  use it as an executable.</p> </li> <li> <p>import statements.</p> </li> <li> <p>The code itself. Here you put class and function definitions.</p> </li> <li> <p><code>__main__</code>: This is a special section at the bottom of a script where you put executable code. It is optional, not all scripts are meant to be executable. You can put code here that will only be run when the script is called as an executable (see example below), but it will not be run  when the file is imported (when the class and functions are loaded by  another Python script).</p> </li> </ol> <pre><code>#!/usr/bin/env python\n\"\"\"\nA description of what this script contains.\n\"\"\"\n\nimport builtins\n\n# this is where the module-type code goes\nclass Example:\n    \"This is where classes should go\"\n    def __init__(self):\n        pass\n\ndef example_func():\n    \"This is where stand-alone functions should go\"\n    pass\n\n# this is where executable-type code goes, this code is not \n# executed if this script is only imported.\nif __name__ == \"__main__\":\n    print(\"this code is not run when this file is imported.\")\n</code></pre>"},{"location":"tutorials/9.1-wf-script/#running-a-python-script-as-an-executable","title":"Running a Python script as an executable","text":"<p>There are several ways to execute a Python script. The simplest is to  call the <code>python</code> program from your terminal with the script as the target. (Side note, your version of <code>python</code> will usually also have an alias called <code>python3</code> to make it clear that it is not the older <code>python2</code>). Copy the  code above into a script and call it <code>example_script.py</code>. Then execute it like below. You can see from this example that the code we wrote in the section called <code>__main__</code> printed text to stdout, as intended.</p> <pre><code>python example_script.py\n</code></pre> <p>Do not be intimidated by the double underscores in this final section.  In Python special variable are often named in this way, and are referred to as dunders. The naming convention is strange, but you get used to it.</p>"},{"location":"tutorials/9.1-wf-script/#challenge-assignment-wf-as-a-cli-script","title":"Challenge assignment - WF as a CLI script","text":"<p>Implement your WF model code into a standalone executable python script.</p> <ul> <li>Make a new text file in your <code>hack-5-python</code> repo called <code>wf-sim.py</code></li> <li>Copy your WF code into this file and set an appropriate action in the <code>__main__</code> section.</li> <li>Use <code>argparse</code> to define the arguments you'll need to allow the user to set, and give these arguments reasonable defaults.</li> <li>One of your arguments should be <code>verbose</code> and you should test this argument inside your code to print key progress/debugging statements.</li> <li>Challenge: As a challenge question, add another argument called <code>outfile</code> and use this file to write out the community state at each given step. Consider what would be the most useful information to retain for a simulation and justify your decision.</li> </ul>"}]}